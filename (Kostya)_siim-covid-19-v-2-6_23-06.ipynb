{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T15:49:04.861912Z",
     "iopub.status.busy": "2021-06-16T15:49:04.861579Z",
     "iopub.status.idle": "2021-06-16T15:49:04.869769Z",
     "shell.execute_reply": "2021-06-16T15:49:04.868896Z",
     "shell.execute_reply.started": "2021-06-16T15:49:04.861880Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-f9xh7077 because the default path (/Image-1) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import ast\n",
    "import os\n",
    "os.environ['MPLCONFIGDIR'] = \"/Image-1\"\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OPTIONAL] Working with DICOM files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:06.894305Z",
     "iopub.status.busy": "2021-06-16T14:44:06.893961Z",
     "iopub.status.idle": "2021-06-16T14:44:06.903723Z",
     "shell.execute_reply": "2021-06-16T14:44:06.902944Z",
     "shell.execute_reply.started": "2021-06-16T14:44:06.894272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install libraries for DICOM files\n",
    "\n",
    "# #!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q\n",
    "# #!conda install 'gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n",
    "# !conda install -c conda-forge gdcm -y\n",
    "# !conda install -c conda-forge pydicom -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:06.906835Z",
     "iopub.status.busy": "2021-06-16T14:44:06.906501Z",
     "iopub.status.idle": "2021-06-16T14:44:06.912793Z",
     "shell.execute_reply": "2021-06-16T14:44:06.912015Z",
     "shell.execute_reply.started": "2021-06-16T14:44:06.906811Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pydicom\n",
    "# from pydicom.pixel_data_handlers.util import apply_voi_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:06.914041Z",
     "iopub.status.busy": "2021-06-16T14:44:06.913770Z",
     "iopub.status.idle": "2021-06-16T14:44:06.923450Z",
     "shell.execute_reply": "2021-06-16T14:44:06.922548Z",
     "shell.execute_reply.started": "2021-06-16T14:44:06.914018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# CONVERTING DICOM FILES TO NP ARRAYS PROPERLY\n",
    "# Ref : https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way\n",
    "\n",
    "# def dicom2arr(path, voi_lut = True, fix_monochrome = True):\n",
    "\n",
    "#     dicom = pydicom.read_file(path)\n",
    "    \n",
    "#     # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "#     # \"human-friendly\" view\n",
    "#     if voi_lut:\n",
    "#         arr = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "#     else:\n",
    "#         arr = dicom.pixel_array\n",
    "    \n",
    "#     # depending on this value, X-ray may look inverted - fix that:\n",
    "#     if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "#         arr = np.amax(arr) - arr\n",
    "        \n",
    "#     arr = arr - np.min(arr)\n",
    "#     arr = arr / np.max(arr)\n",
    "#     arr = (arr * 255).astype(np.uint8)\n",
    "        \n",
    "#     return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OPTIONAL] Convert dcm to jpg\n",
    "I did this for two reasons:\n",
    "1. Because TF OD API explicitly states so in their docs:\n",
    "\"Dataset Requirements\n",
    "For every example in your dataset, you should have the following information: An RGB image for the dataset **encoded as jpeg or png**.\n",
    "2. Because it's easier to work with jpg's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:06.925430Z",
     "iopub.status.busy": "2021-06-16T14:44:06.924922Z",
     "iopub.status.idle": "2021-06-16T14:44:06.933150Z",
     "shell.execute_reply": "2021-06-16T14:44:06.932262Z",
     "shell.execute_reply.started": "2021-06-16T14:44:06.925371Z"
    }
   },
   "outputs": [],
   "source": [
    "# def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "#     # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image\n",
    "#     im = Image.fromarray(array)\n",
    "    \n",
    "#     if keep_ratio:\n",
    "#         im.thumbnail((size, size), resample)\n",
    "#     else:\n",
    "#         im = im.resize((size, size), resample)\n",
    "    \n",
    "#     return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:07.012747Z",
     "iopub.status.busy": "2021-06-16T14:44:07.012128Z",
     "iopub.status.idle": "2021-06-16T14:44:07.017216Z",
     "shell.execute_reply": "2021-06-16T14:44:07.016274Z",
     "shell.execute_reply.started": "2021-06-16T14:44:07.012694Z"
    }
   },
   "outputs": [],
   "source": [
    "# image_id = []\n",
    "# dim0 = []\n",
    "# dim1 = []\n",
    "# splits = []\n",
    "\n",
    "# for split in ['test', 'train']:\n",
    "#     save_dir = f'/kaggle/tmp/{split}/'\n",
    "\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "#     for dirname, _, filenames in os.walk(f'../input/siim-covid19-detection/{split}'):\n",
    "#         for file in filenames:\n",
    "#             # set keep_ratio=True to have original aspect ratio\n",
    "#             xray = dicom2arr(os.path.join(dirname, file))\n",
    "#             im = resize(xray, size=256)  \n",
    "#             im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))\n",
    "\n",
    "#             image_id.append(file.replace('.dcm', ''))\n",
    "#             dim0.append(xray.shape[0])\n",
    "#             dim1.append(xray.shape[1])\n",
    "#             splits.append(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:07.019836Z",
     "iopub.status.busy": "2021-06-16T14:44:07.019150Z",
     "iopub.status.idle": "2021-06-16T14:44:07.029019Z",
     "shell.execute_reply": "2021-06-16T14:44:07.028096Z",
     "shell.execute_reply.started": "2021-06-16T14:44:07.019795Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# for dirname, _, filenames in os.walk('../input/siim-covid19-resized-to-256px-jpg/train'):\n",
    "#     for filename in filenames:\n",
    "#         #print(dirname, filename)\n",
    "#         path = os.path.join(dirname, filename)\n",
    "#         #print(path)\n",
    "#         img= Image.open(path)  \n",
    "#         image = np.array(img)\n",
    "#         print(image)\n",
    "#         print(image.shape)\n",
    "#         img_arr = dicom2arr(path)\n",
    "#         print(img_arr)\n",
    "#         print(np.max(img_arr))\n",
    "#         print(img_arr.shape)\n",
    "#         print(type(img_arr))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install TF Object detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone TF models repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:07.032551Z",
     "iopub.status.busy": "2021-06-16T14:44:07.031652Z",
     "iopub.status.idle": "2021-06-16T14:44:11.381532Z",
     "shell.execute_reply": "2021-06-16T14:44:11.380623Z",
     "shell.execute_reply.started": "2021-06-16T14:44:07.032468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/tf/Kostya_working_dir’: File exists\n",
      "/tf/Kostya_working_dir\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tf/Kostya_working_dir\n",
    "%cd /tf/Kostya_working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:07.032551Z",
     "iopub.status.busy": "2021-06-16T14:44:07.031652Z",
     "iopub.status.idle": "2021-06-16T14:44:11.381532Z",
     "shell.execute_reply": "2021-06-16T14:44:11.380623Z",
     "shell.execute_reply.started": "2021-06-16T14:44:07.032468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:11.383747Z",
     "iopub.status.busy": "2021-06-16T14:44:11.383428Z",
     "iopub.status.idle": "2021-06-16T14:44:14.137141Z",
     "shell.execute_reply": "2021-06-16T14:44:14.136068Z",
     "shell.execute_reply.started": "2021-06-16T14:44:11.383713Z"
    }
   },
   "outputs": [],
   "source": [
    "# !wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.17.2/protoc-3.17.2-linux-x86_64.zip -q\n",
    "# !unzip -o protobuf.zip\n",
    "# !rm protobuf.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:44:14.139031Z",
     "iopub.status.busy": "2021-06-16T14:44:14.138696Z",
     "iopub.status.idle": "2021-06-16T14:45:54.163830Z",
     "shell.execute_reply": "2021-06-16T14:45:54.162871Z",
     "shell.execute_reply.started": "2021-06-16T14:44:14.138990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir/models/research\n",
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Processing /tf/Kostya_working_dir/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Requirement already satisfied: avro-python3 in /.local/lib/python3.6/site-packages (from object-detection==0.1) (1.9.2.1)\n",
      "Requirement already satisfied: apache-beam in /.local/lib/python3.6/site-packages (from object-detection==0.1) (2.30.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (8.2.0)\n",
      "Requirement already satisfied: lxml in /.local/lib/python3.6/site-packages (from object-detection==0.1) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: Cython in /.local/lib/python3.6/site-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /.local/lib/python3.6/site-packages (from object-detection==0.1) (0.6.0.post1)\n",
      "Requirement already satisfied: tf-slim in /.local/lib/python3.6/site-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /.local/lib/python3.6/site-packages (from object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: lvis in /.local/lib/python3.6/site-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /.local/lib/python3.6/site-packages (from object-detection==0.1) (1.5.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.5)\n",
      "Requirement already satisfied: tf-models-official in /.local/lib/python3.6/site-packages (from object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.8)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.17.0)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /.local/lib/python3.6/site-packages (from apache-beam->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: docopt in /.local/lib/python3.6/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /usr/local/lib/python3.6/dist-packages (from httplib2<0.20.0,>=0.8->apache-beam->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /.local/lib/python3.6/site-packages (from lvis->object-detection==0.1) (4.5.2.54)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (56.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: opencv-python-headless in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (4.5.2.54)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (2.9.0)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (2.20.0)\n",
      "Requirement already satisfied: tensorflow-addons in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (0.13.0)\n",
      "Requirement already satisfied: gin-config in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: seqeval in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: sacrebleu in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (1.5.1)\n",
      "Requirement already satisfied: sentencepiece in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (5.8.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /.local/lib/python3.6/site-packages (from tf-models-official->object-detection==0.1) (4.3.0)\n",
      "Requirement already satisfied: google-auth<2dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /.local/lib/python3.6/site-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (20.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /.local/lib/python3.6/site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /.local/lib/python3.6/site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.7.0)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /.local/lib/python3.6/site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /.local/lib/python3.6/site-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.18.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /.local/lib/python3.6/site-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (2.20)\n",
      "Requirement already satisfied: python-slugify in /.local/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: tqdm in /.local/lib/python3.6/site-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.61.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0rc0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /.local/lib/python3.6/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /.local/lib/python3.6/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /.local/lib/python3.6/site-packages (from sacrebleu->tf-models-official->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /.local/lib/python3.6/site-packages (from seqeval->tf-models-official->object-detection==0.1) (0.24.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /.local/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /.local/lib/python3.6/site-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.12.1)\n",
      "Requirement already satisfied: importlib-resources in /.local/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.4)\n",
      "Requirement already satisfied: tensorflow-metadata in /.local/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.0.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: promise in /.local/lib/python3.6/site-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1654777 sha256=34b054938fd33abd4ca5944d397097d5bdd4b216a5b4d6a5ba76f28b4ae1a6dd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-inqa1672/wheels/98/6d/25/da48cbbcf5da0ba5abafbc85e34a70a8728e370ef0de225417\n",
      "Successfully built object-detection\n",
      "Installing collected packages: object-detection\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "Successfully installed object-detection-0.1\n"
     ]
    }
   ],
   "source": [
    "%cd models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "!cp object_detection/packages/tf2/setup.py .\n",
    "!python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PATH=/.local/:$PATH\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/.local/')\n",
    "\n",
    "# !pip install tf_slim\n",
    "\n",
    "# !echo $PATH\n",
    "\n",
    "# !whereis numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/.local/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tf_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !whereis numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model builder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:45:54.165764Z",
     "iopub.status.busy": "2021-06-16T14:45:54.165433Z",
     "iopub.status.idle": "2021-06-16T14:46:28.897288Z",
     "shell.execute_reply": "2021-06-16T14:46:28.896367Z",
     "shell.execute_reply.started": "2021-06-16T14:45:54.165722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-23 10:19:44.607127: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "Running tests under Python 3.6.9: /usr/local/bin/python\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2021-06-23 10:19:45.935822: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-23 10:19:45.978604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:45.978949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:19:45.978991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:45.979295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:19:45.979311: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 10:19:45.981013: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-23 10:19:45.981039: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-23 10:19:45.981557: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-23 10:19:45.981685: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-23 10:19:45.982201: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-06-23 10:19:45.982618: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-23 10:19:45.982706: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-23 10:19:45.982750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:45.983085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:45.983412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:45.983779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:45.984080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-06-23 10:19:45.984280: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-23 10:19:46.129145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.129453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:19:46.129513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.129787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:19:46.129826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.130120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.130414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.130708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.130975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-06-23 10:19:46.131001: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 10:19:46.627268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-23 10:19:46.627298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2021-06-23 10:19:46.627304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N \n",
      "2021-06-23 10:19:46.627307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N \n",
      "2021-06-23 10:19:46.627457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.627852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.628154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.628452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.628744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.629029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9653 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-06-23 10:19:46.629285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:19:46.629559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9609 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "/tf/Kostya_working_dir/models/research/object_detection/builders/model_builder.py:1088: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
      "W0623 10:19:46.884609 140055469000512 model_builder.py:1088] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.19s\n",
      "I0623 10:19:47.120948 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.34s\n",
      "I0623 10:19:47.463451 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.34s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.19s\n",
      "I0623 10:19:47.655053 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.19s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.18s\n",
      "I0623 10:19:47.831501 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.18s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "W0623 10:19:47.832833 140055469000512 mobilenet_v2.py:296] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.11s\n",
      "I0623 10:19:48.936963 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.11s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I0623 10:19:48.937573 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I0623 10:19:48.961496 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I0623 10:19:48.971963 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "I0623 10:19:48.982872 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "I0623 10:19:49.053160 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "I0623 10:19:49.117823 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.07s\n",
      "I0623 10:19:49.186400 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "I0623 10:19:49.253778 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.07s\n",
      "I0623 10:19:49.320322 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.07s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "I0623 10:19:49.341725 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I0623 10:19:49.466753 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0623 10:19:49.466824 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0623 10:19:49.466866 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
      "I0623 10:19:49.468917 140055469000512 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:19:49.479243 140055469000512 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:19:49.479304 140055469000512 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:19:49.512298 140055469000512 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:19:49.512360 140055469000512 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:19:49.597352 140055469000512 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:19:49.597423 140055469000512 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0623 10:19:49.682758 140055469000512 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0623 10:19:49.682836 140055469000512 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0623 10:19:49.810377 140055469000512 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0623 10:19:49.810454 140055469000512 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0623 10:19:49.938231 140055469000512 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0623 10:19:49.938310 140055469000512 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0623 10:19:50.109383 140055469000512 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0623 10:19:50.109462 140055469000512 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0623 10:19:50.150630 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0623 10:19:50.167303 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:50.277103 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I0623 10:19:50.277201 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
      "I0623 10:19:50.277247 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
      "I0623 10:19:50.278477 140055469000512 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:19:50.287877 140055469000512 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:19:50.287934 140055469000512 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:19:50.355928 140055469000512 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:19:50.356001 140055469000512 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:19:50.483539 140055469000512 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:19:50.483622 140055469000512 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0623 10:19:50.611643 140055469000512 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0623 10:19:50.611725 140055469000512 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0623 10:19:50.782034 140055469000512 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0623 10:19:50.782123 140055469000512 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0623 10:19:50.952954 140055469000512 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0623 10:19:50.953034 140055469000512 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0623 10:19:51.166321 140055469000512 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0623 10:19:51.166401 140055469000512 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0623 10:19:51.250770 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0623 10:19:51.266615 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:51.310600 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0623 10:19:51.310678 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0623 10:19:51.310722 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
      "I0623 10:19:51.311865 140055469000512 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:19:51.320595 140055469000512 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:19:51.320651 140055469000512 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:19:51.387739 140055469000512 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:19:51.387807 140055469000512 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:19:51.515293 140055469000512 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:19:51.515370 140055469000512 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 10:19:51.642802 140055469000512 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 10:19:51.642880 140055469000512 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0623 10:19:51.814265 140055469000512 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0623 10:19:51.814346 140055469000512 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0623 10:19:51.984720 140055469000512 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0623 10:19:51.984804 140055469000512 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0623 10:19:52.270954 140055469000512 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0623 10:19:52.271044 140055469000512 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0623 10:19:52.356309 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0623 10:19:52.372228 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:52.416532 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I0623 10:19:52.416612 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
      "I0623 10:19:52.416655 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
      "I0623 10:19:52.417786 140055469000512 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0623 10:19:52.426659 140055469000512 efficientnet_model.py:147] round_filter input=32 output=40\n",
      "I0623 10:19:52.426714 140055469000512 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0623 10:19:52.494901 140055469000512 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0623 10:19:52.494975 140055469000512 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0623 10:19:52.622508 140055469000512 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0623 10:19:52.622588 140055469000512 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 10:19:52.749831 140055469000512 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 10:19:52.749909 140055469000512 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0623 10:19:52.963346 140055469000512 efficientnet_model.py:147] round_filter input=80 output=96\n",
      "I0623 10:19:52.963426 140055469000512 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0623 10:19:53.177351 140055469000512 efficientnet_model.py:147] round_filter input=112 output=136\n",
      "I0623 10:19:53.177433 140055469000512 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0623 10:19:53.433989 140055469000512 efficientnet_model.py:147] round_filter input=192 output=232\n",
      "I0623 10:19:53.434073 140055469000512 efficientnet_model.py:147] round_filter input=320 output=384\n",
      "I0623 10:19:53.519003 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
      "I0623 10:19:53.534831 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:53.582675 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I0623 10:19:53.582756 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
      "I0623 10:19:53.582799 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
      "I0623 10:19:53.583942 140055469000512 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0623 10:19:53.592832 140055469000512 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0623 10:19:53.592888 140055469000512 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0623 10:19:53.659924 140055469000512 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0623 10:19:53.659994 140055469000512 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0623 10:19:53.831328 140055469000512 efficientnet_model.py:147] round_filter input=24 output=32\n",
      "I0623 10:19:53.831409 140055469000512 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0623 10:19:54.001540 140055469000512 efficientnet_model.py:147] round_filter input=40 output=56\n",
      "I0623 10:19:54.001618 140055469000512 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0623 10:19:54.356839 140055469000512 efficientnet_model.py:147] round_filter input=80 output=112\n",
      "I0623 10:19:54.356935 140055469000512 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0623 10:19:54.615652 140055469000512 efficientnet_model.py:147] round_filter input=112 output=160\n",
      "I0623 10:19:54.615743 140055469000512 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0623 10:19:54.960541 140055469000512 efficientnet_model.py:147] round_filter input=192 output=272\n",
      "I0623 10:19:54.960633 140055469000512 efficientnet_model.py:147] round_filter input=320 output=448\n",
      "I0623 10:19:55.045963 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
      "I0623 10:19:55.061791 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:55.117016 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I0623 10:19:55.117099 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
      "I0623 10:19:55.117143 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
      "I0623 10:19:55.118281 140055469000512 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0623 10:19:55.127496 140055469000512 efficientnet_model.py:147] round_filter input=32 output=48\n",
      "I0623 10:19:55.127552 140055469000512 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0623 10:19:55.230167 140055469000512 efficientnet_model.py:147] round_filter input=16 output=24\n",
      "I0623 10:19:55.230244 140055469000512 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0623 10:19:55.443853 140055469000512 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0623 10:19:55.443935 140055469000512 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0623 10:19:55.657952 140055469000512 efficientnet_model.py:147] round_filter input=40 output=64\n",
      "I0623 10:19:55.658039 140055469000512 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0623 10:19:55.956011 140055469000512 efficientnet_model.py:147] round_filter input=80 output=128\n",
      "I0623 10:19:55.956098 140055469000512 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0623 10:19:56.254708 140055469000512 efficientnet_model.py:147] round_filter input=112 output=176\n",
      "I0623 10:19:56.254794 140055469000512 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0623 10:19:56.730431 140055469000512 efficientnet_model.py:147] round_filter input=192 output=304\n",
      "I0623 10:19:56.730525 140055469000512 efficientnet_model.py:147] round_filter input=320 output=512\n",
      "I0623 10:19:56.860168 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
      "I0623 10:19:56.876350 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:56.939574 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I0623 10:19:56.939661 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0623 10:19:56.939704 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
      "I0623 10:19:56.940849 140055469000512 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0623 10:19:56.949822 140055469000512 efficientnet_model.py:147] round_filter input=32 output=56\n",
      "I0623 10:19:56.949878 140055469000512 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0623 10:19:57.052934 140055469000512 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0623 10:19:57.053014 140055469000512 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0623 10:19:57.310633 140055469000512 efficientnet_model.py:147] round_filter input=24 output=40\n",
      "I0623 10:19:57.310718 140055469000512 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0623 10:19:57.568546 140055469000512 efficientnet_model.py:147] round_filter input=40 output=72\n",
      "I0623 10:19:57.568634 140055469000512 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0623 10:19:57.910386 140055469000512 efficientnet_model.py:147] round_filter input=80 output=144\n",
      "I0623 10:19:57.910476 140055469000512 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0623 10:19:58.253794 140055469000512 efficientnet_model.py:147] round_filter input=112 output=200\n",
      "I0623 10:19:58.253882 140055469000512 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0623 10:19:58.726256 140055469000512 efficientnet_model.py:147] round_filter input=192 output=344\n",
      "I0623 10:19:58.726345 140055469000512 efficientnet_model.py:147] round_filter input=320 output=576\n",
      "I0623 10:19:58.854173 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
      "I0623 10:19:58.869907 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I0623 10:19:59.043904 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I0623 10:19:59.043997 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
      "I0623 10:19:59.044042 140055469000512 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
      "I0623 10:19:59.045203 140055469000512 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0623 10:19:59.054561 140055469000512 efficientnet_model.py:147] round_filter input=32 output=64\n",
      "I0623 10:19:59.054618 140055469000512 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0623 10:19:59.193376 140055469000512 efficientnet_model.py:147] round_filter input=16 output=32\n",
      "I0623 10:19:59.193463 140055469000512 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0623 10:19:59.495922 140055469000512 efficientnet_model.py:147] round_filter input=24 output=48\n",
      "I0623 10:19:59.496011 140055469000512 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0623 10:19:59.796937 140055469000512 efficientnet_model.py:147] round_filter input=40 output=80\n",
      "I0623 10:19:59.797028 140055469000512 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0623 10:20:00.226697 140055469000512 efficientnet_model.py:147] round_filter input=80 output=160\n",
      "I0623 10:20:00.226788 140055469000512 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0623 10:20:00.658627 140055469000512 efficientnet_model.py:147] round_filter input=112 output=224\n",
      "I0623 10:20:00.658718 140055469000512 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0623 10:20:01.217014 140055469000512 efficientnet_model.py:147] round_filter input=192 output=384\n",
      "I0623 10:20:01.217102 140055469000512 efficientnet_model.py:147] round_filter input=320 output=640\n",
      "I0623 10:20:01.387648 140055469000512 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
      "I0623 10:20:01.403541 140055469000512 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 12.26s\n",
      "I0623 10:20:01.603414 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 12.26s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I0623 10:20:01.609128 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I0623 10:20:01.610326 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I0623 10:20:01.610587 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I0623 10:20:01.611670 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I0623 10:20:01.612658 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I0623 10:20:01.612887 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I0623 10:20:01.613621 140055469000512 test_util.py:2103] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 15.681s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "!python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:28.900836Z",
     "iopub.status.busy": "2021-06-16T14:46:28.900565Z",
     "iopub.status.idle": "2021-06-16T14:46:30.663312Z",
     "shell.execute_reply": "2021-06-16T14:46:30.662442Z",
     "shell.execute_reply.started": "2021-06-16T14:46:28.900805Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# The following two imports are for creating TFRecord files\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.dataset_tools import tf_record_creation_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:30.664814Z",
     "iopub.status.busy": "2021-06-16T14:46:30.664485Z",
     "iopub.status.idle": "2021-06-16T14:46:31.310763Z",
     "shell.execute_reply": "2021-06-16T14:46:31.309796Z",
     "shell.execute_reply.started": "2021-06-16T14:46:30.664780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir\n",
      "mkdir: cannot create directory ‘Annotations’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "%cd /tf/Kostya_working_dir\n",
    "!mkdir Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:31.314411Z",
     "iopub.status.busy": "2021-06-16T14:46:31.314142Z",
     "iopub.status.idle": "2021-06-16T14:46:31.320713Z",
     "shell.execute_reply": "2021-06-16T14:46:31.319674Z",
     "shell.execute_reply.started": "2021-06-16T14:46:31.314381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Annotations/label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile Annotations/label_map.pbtxt\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'negative'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 2\n",
    "    name: 'typical'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 3\n",
    "    name: 'indeterminate'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 4\n",
    "    name: 'atypical'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join and create final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load both train dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:31.323697Z",
     "iopub.status.busy": "2021-06-16T14:46:31.323015Z",
     "iopub.status.idle": "2021-06-16T14:46:32.021913Z",
     "shell.execute_reply": "2021-06-16T14:46:32.020989Z",
     "shell.execute_reply.started": "2021-06-16T14:46:31.323658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "path_dcm = '/tf/data/DCM/'\n",
    "train_image = pd.read_csv(path_dcm + 'train_image_level.csv')\n",
    "train_study = pd.read_csv(path_dcm + 'train_study_level.csv')\n",
    "sample_submission = pd.read_csv(path_dcm + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.023708Z",
     "iopub.status.busy": "2021-06-16T14:46:32.023360Z",
     "iopub.status.idle": "2021-06-16T14:46:32.028079Z",
     "shell.execute_reply": "2021-06-16T14:46:32.027247Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.023668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6334\n",
      "6054\n"
     ]
    }
   ],
   "source": [
    "print(len(train_image))\n",
    "print(len(train_study))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES: \n",
    "* Some of the values in the **StudyInstanceUID** column in **train_image** are related (point) to several images - therefore there are 6334 images but only 6054 StudyInstanceUID's. (Does it mean that multiple images have identical bboxes and labels and this was done just to save time and space for identical boxes/labels?)\n",
    "* **StudyInstanceUID** column in **train_image** are identical to the **id** column in **train_study** (but without the _study suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.029900Z",
     "iopub.status.busy": "2021-06-16T14:46:32.029356Z",
     "iopub.status.idle": "2021-06-16T14:46:32.064605Z",
     "shell.execute_reply": "2021-06-16T14:46:32.063818Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.029865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00086460a852_study</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c9c05fd14_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00292f8c37bd_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005057b3f880_study</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0051d9b12e72_study</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  Negative for Pneumonia  Typical Appearance  \\\n",
       "0  00086460a852_study                       0                   1   \n",
       "1  000c9c05fd14_study                       0                   0   \n",
       "2  00292f8c37bd_study                       1                   0   \n",
       "3  005057b3f880_study                       1                   0   \n",
       "4  0051d9b12e72_study                       0                   0   \n",
       "\n",
       "   Indeterminate Appearance  Atypical Appearance  \n",
       "0                         0                    0  \n",
       "1                         0                    1  \n",
       "2                         0                    0  \n",
       "3                         0                    0  \n",
       "4                         0                    1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_study.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.066394Z",
     "iopub.status.busy": "2021-06-16T14:46:32.065905Z",
     "iopub.status.idle": "2021-06-16T14:46:32.077796Z",
     "shell.execute_reply": "2021-06-16T14:46:32.076980Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.066358Z"
    }
   },
   "outputs": [],
   "source": [
    "train_study['id'] = train_study['id'].str.replace('_study', '')\n",
    "\n",
    "train_study.rename(columns={'id': 'StudyInstanceUID'}, inplace=True)\n",
    "\n",
    "train_result = train_image.merge(train_study, on='StudyInstanceUID', how='left')\n",
    "\n",
    "train_result['id'] = train_result['id'].str.replace('_image', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add original dimensions (for scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.066394Z",
     "iopub.status.busy": "2021-06-16T14:46:32.065905Z",
     "iopub.status.idle": "2021-06-16T14:46:32.077796Z",
     "shell.execute_reply": "2021-06-16T14:46:32.076980Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.066358Z"
    }
   },
   "outputs": [],
   "source": [
    "path_jpg = '/tf/data/JPEG/'\n",
    "original_dims = pd.read_csv(path_jpg + 'meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.240962Z",
     "iopub.status.busy": "2021-06-16T14:46:32.240636Z",
     "iopub.status.idle": "2021-06-16T14:46:32.250801Z",
     "shell.execute_reply": "2021-06-16T14:46:32.250023Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.240928Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a29c5a68b07b</td>\n",
       "      <td>2320</td>\n",
       "      <td>2828</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9850b5470fd6</td>\n",
       "      <td>2330</td>\n",
       "      <td>2382</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8d6dea06a032</td>\n",
       "      <td>2422</td>\n",
       "      <td>3344</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dfc5c09a50bc</td>\n",
       "      <td>1140</td>\n",
       "      <td>1387</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7230234e120a</td>\n",
       "      <td>2318</td>\n",
       "      <td>2383</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id  dim0  dim1 split\n",
       "0  a29c5a68b07b  2320  2828  test\n",
       "1  9850b5470fd6  2330  2382  test\n",
       "2  8d6dea06a032  2422  3344  test\n",
       "3  dfc5c09a50bc  1140  1387  test\n",
       "4  7230234e120a  2318  2383  test"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.253010Z",
     "iopub.status.busy": "2021-06-16T14:46:32.252321Z",
     "iopub.status.idle": "2021-06-16T14:46:32.259216Z",
     "shell.execute_reply": "2021-06-16T14:46:32.258437Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.252852Z"
    }
   },
   "outputs": [],
   "source": [
    "original_dims.rename(columns={'image_id': 'id'}, inplace=True)\n",
    "\n",
    "train_result_final = train_result.merge(original_dims, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.276984Z",
     "iopub.status.busy": "2021-06-16T14:46:32.276560Z",
     "iopub.status.idle": "2021-06-16T14:46:32.291760Z",
     "shell.execute_reply": "2021-06-16T14:46:32.290854Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.276948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f                                                NaN   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "   Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                       0                   1                         0   \n",
       "1                       1                   0                         0   \n",
       "2                       0                   1                         0   \n",
       "3                       0                   0                         0   \n",
       "4                       0                   1                         0   \n",
       "\n",
       "   Atypical Appearance  dim0  dim1  split  \n",
       "0                    0  3488  4256  train  \n",
       "1                    0  2320  2832  train  \n",
       "2                    0  2544  3056  train  \n",
       "3                    1  3520  4280  train  \n",
       "4                    0  2800  3408  train  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale bboxes proportionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.296147Z",
     "iopub.status.busy": "2021-06-16T14:46:32.295890Z",
     "iopub.status.idle": "2021-06-16T14:46:32.301983Z",
     "shell.execute_reply": "2021-06-16T14:46:32.300989Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.296123Z"
    }
   },
   "outputs": [],
   "source": [
    "train_result_final[\"boxes\"] = train_result_final[\"boxes\"].fillna(\"[{'x':0, 'y':0, 'width':1, 'height':1}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.304606Z",
     "iopub.status.busy": "2021-06-16T14:46:32.304245Z",
     "iopub.status.idle": "2021-06-16T14:46:32.497259Z",
     "shell.execute_reply": "2021-06-16T14:46:32.496454Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.304570Z"
    }
   },
   "outputs": [],
   "source": [
    "train_result_final[\"boxes\"] = train_result_final[\"boxes\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.498776Z",
     "iopub.status.busy": "2021-06-16T14:46:32.498437Z",
     "iopub.status.idle": "2021-06-16T14:46:32.515769Z",
     "shell.execute_reply": "2021-06-16T14:46:32.514999Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.498741Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>[{'x': 0, 'y': 0, 'width': 1, 'height': 1}]</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f        [{'x': 0, 'y': 0, 'width': 1, 'height': 1}]   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "   Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                       0                   1                         0   \n",
       "1                       1                   0                         0   \n",
       "2                       0                   1                         0   \n",
       "3                       0                   0                         0   \n",
       "4                       0                   1                         0   \n",
       "\n",
       "   Atypical Appearance  dim0  dim1  split  \n",
       "0                    0  3488  4256  train  \n",
       "1                    0  2320  2832  train  \n",
       "2                    0  2544  3056  train  \n",
       "3                    1  3520  4280  train  \n",
       "4                    0  2800  3408  train  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert bboxes coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.517535Z",
     "iopub.status.busy": "2021-06-16T14:46:32.516999Z",
     "iopub.status.idle": "2021-06-16T14:46:32.526104Z",
     "shell.execute_reply": "2021-06-16T14:46:32.525353Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.517498Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpack_bboxes(df):\n",
    "    \"\"\" go from xmin,ymin,width,height --> xmin,ymin,xmax,ymax \"\"\"\n",
    "    for dictionary in df[\"boxes\"]:\n",
    "        df[\"xmin\"] = dictionary[\"x\"]\n",
    "        df[\"ymin\"] = dictionary[\"y\"]\n",
    "        df[\"xmax\"] = dictionary[\"x\"] + dictionary[\"width\"]\n",
    "        df[\"ymax\"] = dictionary[\"y\"] + dictionary[\"height\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.529125Z",
     "iopub.status.busy": "2021-06-16T14:46:32.528791Z",
     "iopub.status.idle": "2021-06-16T14:46:32.536007Z",
     "shell.execute_reply": "2021-06-16T14:46:32.535192Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.529088Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_bbox_coor(df):\n",
    "    if df['xmin'] != 0:\n",
    "        df['xmin'] *= (256 / df['dim1'])\n",
    "        df['xmax'] *= (256 / df['dim1'])\n",
    "        df['ymin'] *= (256 / df['dim0'])\n",
    "        df['ymax'] *= (256 / df['dim0'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:32.537624Z",
     "iopub.status.busy": "2021-06-16T14:46:32.537220Z",
     "iopub.status.idle": "2021-06-16T14:46:49.280907Z",
     "shell.execute_reply": "2021-06-16T14:46:49.279991Z",
     "shell.execute_reply.started": "2021-06-16T14:46:32.537590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacking bboxes into separate columns. This will take ~20 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpacking bboxes into separate columns. This will take ~20 secs\")\n",
    "train_result_final = train_result_final.apply(unpack_bboxes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:49.282608Z",
     "iopub.status.busy": "2021-06-16T14:46:49.282268Z",
     "iopub.status.idle": "2021-06-16T14:46:50.135534Z",
     "shell.execute_reply": "2021-06-16T14:46:50.134656Z",
     "shell.execute_reply.started": "2021-06-16T14:46:49.282571Z"
    }
   },
   "outputs": [],
   "source": [
    "train_result_final = train_result_final.apply(scale_bbox_coor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:50.137002Z",
     "iopub.status.busy": "2021-06-16T14:46:50.136732Z",
     "iopub.status.idle": "2021-06-16T14:46:50.161866Z",
     "shell.execute_reply": "2021-06-16T14:46:50.161039Z",
     "shell.execute_reply.started": "2021-06-16T14:46:50.136975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "      <td>135.092456</td>\n",
       "      <td>43.391213</td>\n",
       "      <td>200.936764</td>\n",
       "      <td>172.679246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>[{'x': 0, 'y': 0, 'width': 1, 'height': 1}]</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "      <td>150.173038</td>\n",
       "      <td>40.508428</td>\n",
       "      <td>201.861192</td>\n",
       "      <td>161.701686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "      <td>train</td>\n",
       "      <td>163.229907</td>\n",
       "      <td>158.642423</td>\n",
       "      <td>219.932717</td>\n",
       "      <td>202.569695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "      <td>train</td>\n",
       "      <td>193.695144</td>\n",
       "      <td>91.306667</td>\n",
       "      <td>243.472922</td>\n",
       "      <td>193.706667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f        [{'x': 0, 'y': 0, 'width': 1, 'height': 1}]   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "   Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                       0                   1                         0   \n",
       "1                       1                   0                         0   \n",
       "2                       0                   1                         0   \n",
       "3                       0                   0                         0   \n",
       "4                       0                   1                         0   \n",
       "\n",
       "   Atypical Appearance  dim0  dim1  split        xmin        ymin        xmax  \\\n",
       "0                    0  3488  4256  train  135.092456   43.391213  200.936764   \n",
       "1                    0  2320  2832  train    0.000000    0.000000    1.000000   \n",
       "2                    0  2544  3056  train  150.173038   40.508428  201.861192   \n",
       "3                    1  3520  4280  train  163.229907  158.642423  219.932717   \n",
       "4                    0  2800  3408  train  193.695144   91.306667  243.472922   \n",
       "\n",
       "         ymax  \n",
       "0  172.679246  \n",
       "1    1.000000  \n",
       "2  161.701686  \n",
       "3  202.569695  \n",
       "4  193.706667  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add classes (str and num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:50.163122Z",
     "iopub.status.busy": "2021-06-16T14:46:50.162864Z",
     "iopub.status.idle": "2021-06-16T14:46:50.167419Z",
     "shell.execute_reply": "2021-06-16T14:46:50.166285Z",
     "shell.execute_reply.started": "2021-06-16T14:46:50.163095Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_dict = {'Negative for Pneumonia': [\"negative\", 1], 'Typical Appearance': [\"typical\", 2], 'Indeterminate Appearance': [\"indeterminate\", 3], 'Atypical Appearance': [\"atypical\", 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:50.169399Z",
     "iopub.status.busy": "2021-06-16T14:46:50.168970Z",
     "iopub.status.idle": "2021-06-16T14:46:50.178171Z",
     "shell.execute_reply": "2021-06-16T14:46:50.177421Z",
     "shell.execute_reply.started": "2021-06-16T14:46:50.169356Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_and_combine_classes(df):\n",
    "    for lbl in labels_dict:\n",
    "        if df[lbl]:\n",
    "            df['class'] = labels_dict[lbl][0]\n",
    "            df['class_num'] = labels_dict[lbl][1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:50.179783Z",
     "iopub.status.busy": "2021-06-16T14:46:50.179420Z",
     "iopub.status.idle": "2021-06-16T14:46:59.105548Z",
     "shell.execute_reply": "2021-06-16T14:46:59.104664Z",
     "shell.execute_reply.started": "2021-06-16T14:46:50.179746Z"
    }
   },
   "outputs": [],
   "source": [
    "train_result_final = train_result_final.apply(convert_and_combine_classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.107120Z",
     "iopub.status.busy": "2021-06-16T14:46:59.106764Z",
     "iopub.status.idle": "2021-06-16T14:46:59.133847Z",
     "shell.execute_reply": "2021-06-16T14:46:59.132774Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.107076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Negative for Pneumonia</th>\n",
       "      <th>Typical Appearance</th>\n",
       "      <th>Indeterminate Appearance</th>\n",
       "      <th>Atypical Appearance</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "      <td>135.092456</td>\n",
       "      <td>43.391213</td>\n",
       "      <td>200.936764</td>\n",
       "      <td>172.679246</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>[{'x': 0, 'y': 0, 'width': 1, 'height': 1}]</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "      <td>150.173038</td>\n",
       "      <td>40.508428</td>\n",
       "      <td>201.861192</td>\n",
       "      <td>161.701686</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001398f4ff4f</td>\n",
       "      <td>[{'x': 2729, 'y': 2181.33331, 'width': 948.000...</td>\n",
       "      <td>opacity 1 2729 2181.33331 3677.00012 2785.33331</td>\n",
       "      <td>28dddc8559b2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3520</td>\n",
       "      <td>4280</td>\n",
       "      <td>train</td>\n",
       "      <td>163.229907</td>\n",
       "      <td>158.642423</td>\n",
       "      <td>219.932717</td>\n",
       "      <td>202.569695</td>\n",
       "      <td>atypical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001bd15d1891</td>\n",
       "      <td>[{'x': 623.23328, 'y': 1050, 'width': 714, 'he...</td>\n",
       "      <td>opacity 1 623.23328 1050 1337.23328 2156 opaci...</td>\n",
       "      <td>dfd9fdd85a3e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2800</td>\n",
       "      <td>3408</td>\n",
       "      <td>train</td>\n",
       "      <td>193.695144</td>\n",
       "      <td>91.306667</td>\n",
       "      <td>243.472922</td>\n",
       "      <td>193.706667</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              boxes  \\\n",
       "0  000a312787f2  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f        [{'x': 0, 'y': 0, 'width': 1, 'height': 1}]   \n",
       "2  0012ff7358bc  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "3  001398f4ff4f  [{'x': 2729, 'y': 2181.33331, 'width': 948.000...   \n",
       "4  001bd15d1891  [{'x': 623.23328, 'y': 1050, 'width': 714, 'he...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "3    opacity 1 2729 2181.33331 3677.00012 2785.33331     28dddc8559b2   \n",
       "4  opacity 1 623.23328 1050 1337.23328 2156 opaci...     dfd9fdd85a3e   \n",
       "\n",
       "   Negative for Pneumonia  Typical Appearance  Indeterminate Appearance  \\\n",
       "0                       0                   1                         0   \n",
       "1                       1                   0                         0   \n",
       "2                       0                   1                         0   \n",
       "3                       0                   0                         0   \n",
       "4                       0                   1                         0   \n",
       "\n",
       "   Atypical Appearance  dim0  dim1  split        xmin        ymin        xmax  \\\n",
       "0                    0  3488  4256  train  135.092456   43.391213  200.936764   \n",
       "1                    0  2320  2832  train    0.000000    0.000000    1.000000   \n",
       "2                    0  2544  3056  train  150.173038   40.508428  201.861192   \n",
       "3                    1  3520  4280  train  163.229907  158.642423  219.932717   \n",
       "4                    0  2800  3408  train  193.695144   91.306667  243.472922   \n",
       "\n",
       "         ymax     class  class_num  \n",
       "0  172.679246   typical          2  \n",
       "1    1.000000  negative          1  \n",
       "2  161.701686   typical          2  \n",
       "3  202.569695  atypical          4  \n",
       "4  193.706667   typical          2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train images into train/validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.136978Z",
     "iopub.status.busy": "2021-06-16T14:46:59.136703Z",
     "iopub.status.idle": "2021-06-16T14:46:59.161403Z",
     "shell.execute_reply": "2021-06-16T14:46:59.160680Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.136952Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(train_result_final, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.162917Z",
     "iopub.status.busy": "2021-06-16T14:46:59.162567Z",
     "iopub.status.idle": "2021-06-16T14:46:59.170005Z",
     "shell.execute_reply": "2021-06-16T14:46:59.168957Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.162882Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.filter(['id','class', 'class_num', 'xmin', 'ymin', 'xmax', 'ymax'], axis=1)\n",
    "val_df = val_df.filter(['id','class', 'class_num', 'xmin', 'ymin', 'xmax', 'ymax'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.171662Z",
     "iopub.status.busy": "2021-06-16T14:46:59.171216Z",
     "iopub.status.idle": "2021-06-16T14:46:59.189559Z",
     "shell.execute_reply": "2021-06-16T14:46:59.188501Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.171626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>6d0230e7bc33</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "      <td>177.544251</td>\n",
       "      <td>106.549888</td>\n",
       "      <td>215.542853</td>\n",
       "      <td>201.278803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>82436fda2f12</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "      <td>78.079997</td>\n",
       "      <td>79.949683</td>\n",
       "      <td>123.306666</td>\n",
       "      <td>173.231362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>f9729a4e5c44</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>3</td>\n",
       "      <td>11.888050</td>\n",
       "      <td>129.814326</td>\n",
       "      <td>48.372065</td>\n",
       "      <td>202.202412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>895ee33c70a1</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "      <td>123.568732</td>\n",
       "      <td>49.284490</td>\n",
       "      <td>190.259884</td>\n",
       "      <td>168.205766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>9d0c91bd716b</td>\n",
       "      <td>typical</td>\n",
       "      <td>2</td>\n",
       "      <td>137.884332</td>\n",
       "      <td>123.894233</td>\n",
       "      <td>198.182969</td>\n",
       "      <td>211.593487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id          class  class_num        xmin        ymin  \\\n",
       "2679  6d0230e7bc33        typical          2  177.544251  106.549888   \n",
       "3216  82436fda2f12        typical          2   78.079997   79.949683   \n",
       "6164  f9729a4e5c44  indeterminate          3   11.888050  129.814326   \n",
       "3371  895ee33c70a1        typical          2  123.568732   49.284490   \n",
       "3859  9d0c91bd716b        typical          2  137.884332  123.894233   \n",
       "\n",
       "            xmax        ymax  \n",
       "2679  215.542853  201.278803  \n",
       "3216  123.306666  173.231362  \n",
       "6164   48.372065  202.202412  \n",
       "3371  190.259884  168.205766  \n",
       "3859  198.182969  211.593487  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.192153Z",
     "iopub.status.busy": "2021-06-16T14:46:59.191758Z",
     "iopub.status.idle": "2021-06-16T14:46:59.208992Z",
     "shell.execute_reply": "2021-06-16T14:46:59.208009Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.192114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>class_num</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>139a8476e9de</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>58d616c1a4d4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>fd86888c63e2</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>7125a29cfb98</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>3</td>\n",
       "      <td>89.377191</td>\n",
       "      <td>92.144065</td>\n",
       "      <td>116.324557</td>\n",
       "      <td>139.692153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>815328f2379c</td>\n",
       "      <td>indeterminate</td>\n",
       "      <td>3</td>\n",
       "      <td>49.826721</td>\n",
       "      <td>131.154343</td>\n",
       "      <td>110.280595</td>\n",
       "      <td>189.230067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id          class  class_num       xmin        ymin  \\\n",
       "510   139a8476e9de       negative          1   0.000000    0.000000   \n",
       "2188  58d616c1a4d4       negative          1   0.000000    0.000000   \n",
       "6268  fd86888c63e2       negative          1   0.000000    0.000000   \n",
       "2782  7125a29cfb98  indeterminate          3  89.377191   92.144065   \n",
       "3196  815328f2379c  indeterminate          3  49.826721  131.154343   \n",
       "\n",
       "            xmax        ymax  \n",
       "510     1.000000    1.000000  \n",
       "2188    1.000000    1.000000  \n",
       "6268    1.000000    1.000000  \n",
       "2782  116.324557  139.692153  \n",
       "3196  110.280595  189.230067  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy train/validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.211040Z",
     "iopub.status.busy": "2021-06-16T14:46:59.210637Z",
     "iopub.status.idle": "2021-06-16T14:47:01.180950Z",
     "shell.execute_reply": "2021-06-16T14:47:01.179908Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.211002Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -rf /tf/Kostya_working_dir/JPEG/train\n",
    "!rm -rf /tf/Kostya_working_dir/JPEG/validation\n",
    "!mkdir -p /tf/Kostya_working_dir/JPEG/train\n",
    "!mkdir -p /tf/Kostya_working_dir/JPEG/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p /tf/data/JPEG/entire_dataset\n",
    "# %cd /tf/data/JPEG/\n",
    "# !tar xvf train.tar.gz -C entire_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:46:59.211040Z",
     "iopub.status.busy": "2021-06-16T14:46:59.210637Z",
     "iopub.status.idle": "2021-06-16T14:47:01.180950Z",
     "shell.execute_reply": "2021-06-16T14:47:01.179908Z",
     "shell.execute_reply.started": "2021-06-16T14:46:59.211002Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "original_dataset_path = '/tf/data/JPEG/entire_dataset'\n",
    "\n",
    "def copy_split_dataset(df, split):\n",
    "    for _, row in df.iterrows():\n",
    "        source_file_path = os.path.join(original_dataset_path, (row['id'] + '.jpg'))\n",
    "        dest_file_path = os.path.join('/tf/Kostya_working_dir/JPEG/' + split, (row['id'] +'.jpg'))\n",
    "        shutil.copy(source_file_path, dest_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:01.184496Z",
     "iopub.status.busy": "2021-06-16T14:47:01.184223Z",
     "iopub.status.idle": "2021-06-16T14:47:24.481020Z",
     "shell.execute_reply": "2021-06-16T14:47:24.480153Z",
     "shell.execute_reply.started": "2021-06-16T14:47:01.184467Z"
    }
   },
   "outputs": [],
   "source": [
    "copy_split_dataset(train_df, 'train')\n",
    "copy_split_dataset(val_df, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:24.482732Z",
     "iopub.status.busy": "2021-06-16T14:47:24.482386Z",
     "iopub.status.idle": "2021-06-16T14:47:24.492715Z",
     "shell.execute_reply": "2021-06-16T14:47:24.491625Z",
     "shell.execute_reply.started": "2021-06-16T14:47:24.482694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6334\n",
      "5067\n",
      "1267\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('/tf/data/JPEG/entire_dataset')))\n",
    "print(len(os.listdir('/tf/Kostya_working_dir/JPEG/train/')))\n",
    "print(len(os.listdir('/tf/Kostya_working_dir/JPEG/validation/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create csv files from train/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:24.494643Z",
     "iopub.status.busy": "2021-06-16T14:47:24.494034Z",
     "iopub.status.idle": "2021-06-16T14:47:24.689028Z",
     "shell.execute_reply": "2021-06-16T14:47:24.688259Z",
     "shell.execute_reply.started": "2021-06-16T14:47:24.494605Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv', encoding='utf-8')\n",
    "val_df.to_csv('val_df.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:24.690772Z",
     "iopub.status.busy": "2021-06-16T14:47:24.690249Z",
     "iopub.status.idle": "2021-06-16T14:47:24.696261Z",
     "shell.execute_reply": "2021-06-16T14:47:24.695159Z",
     "shell.execute_reply.started": "2021-06-16T14:47:24.690732Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from collections import namedtuple\n",
    "\n",
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:24.698270Z",
     "iopub.status.busy": "2021-06-16T14:47:24.697733Z",
     "iopub.status.idle": "2021-06-16T14:47:24.710206Z",
     "shell.execute_reply": "2021-06-16T14:47:24.709161Z",
     "shell.execute_reply.started": "2021-06-16T14:47:24.698233Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_tf_example(group, path):\n",
    "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename + '.jpg')), 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "\n",
    "    filename = group.filename.encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for index, row in group.object.iterrows():\n",
    "        xmins.append(row['xmin'])\n",
    "        xmaxs.append(row['xmax'])\n",
    "        ymins.append(row['ymin'])\n",
    "        ymaxs.append(row['ymax'])\n",
    "        classes_text.append(row['class'].encode('utf8'))\n",
    "        classes.append(row['class_num'])\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        #'image/height': dataset_util.int64_feature(height),\n",
    "        #'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        #'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:24.712255Z",
     "iopub.status.busy": "2021-06-16T14:47:24.711771Z",
     "iopub.status.idle": "2021-06-16T14:47:29.547241Z",
     "shell.execute_reply": "2021-06-16T14:47:29.546342Z",
     "shell.execute_reply.started": "2021-06-16T14:47:24.712214Z"
    }
   },
   "outputs": [],
   "source": [
    "df_to_dirnames_dict = {'train': train_df, 'validation': val_df}\n",
    "\n",
    "dir_path = '/tf/Kostya_working_dir/JPEG/'\n",
    "for dirname in next(os.walk(dir_path))[1]:\n",
    "    if dirname in df_to_dirnames_dict:\n",
    "        writer = tf.io.TFRecordWriter(f'tfrecord_{dirname}.tfrec')\n",
    "        path = os.path.join(dir_path, dirname)\n",
    "        examples = df_to_dirnames_dict[dirname]\n",
    "        grouped = split(examples, 'id')\n",
    "        for group in grouped:\n",
    "            tf_example = create_tf_example(group, path)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained models from the zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf pre-trained-models\n",
    "!rm -rf models/my_ssd_resnet50_v1_fpn\n",
    "!rm -rf models/my_efficientdet_d2_coco17_tpu-32\n",
    "\n",
    "!mkdir pre-trained-models\n",
    "!mkdir models/my_ssd_resnet50_v1_fpn\n",
    "!mkdir models/my_efficientdet_d2_coco17_tpu-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:29.556256Z",
     "iopub.status.busy": "2021-06-16T14:47:29.555750Z",
     "iopub.status.idle": "2021-06-16T14:47:29.566097Z",
     "shell.execute_reply": "2021-06-16T14:47:29.565339Z",
     "shell.execute_reply.started": "2021-06-16T14:47:29.556216Z"
    }
   },
   "outputs": [],
   "source": [
    "##!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz  \n",
    "# !tar xvf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz --directory=pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientdet_d2_coco17_tpu-32/\n",
      "efficientdet_d2_coco17_tpu-32/checkpoint/\n",
      "efficientdet_d2_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
      "efficientdet_d2_coco17_tpu-32/checkpoint/checkpoint\n",
      "efficientdet_d2_coco17_tpu-32/checkpoint/ckpt-0.index\n",
      "efficientdet_d2_coco17_tpu-32/pipeline.config\n",
      "efficientdet_d2_coco17_tpu-32/saved_model/\n",
      "efficientdet_d2_coco17_tpu-32/saved_model/saved_model.pb\n",
      "efficientdet_d2_coco17_tpu-32/saved_model/assets/\n",
      "efficientdet_d2_coco17_tpu-32/saved_model/variables/\n",
      "efficientdet_d2_coco17_tpu-32/saved_model/variables/variables.data-00000-of-00001\n",
      "efficientdet_d2_coco17_tpu-32/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "#!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d2_coco17_tpu-32.tar.gz\n",
    "!tar xvf efficientdet_d2_coco17_tpu-32.tar.gz --directory=pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:29.556256Z",
     "iopub.status.busy": "2021-06-16T14:47:29.555750Z",
     "iopub.status.idle": "2021-06-16T14:47:29.566097Z",
     "shell.execute_reply": "2021-06-16T14:47:29.565339Z",
     "shell.execute_reply.started": "2021-06-16T14:47:29.556216Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# !cp pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config models/my_ssd_resnet50_v1_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:29.567849Z",
     "iopub.status.busy": "2021-06-16T14:47:29.567446Z",
     "iopub.status.idle": "2021-06-16T14:47:29.576510Z",
     "shell.execute_reply": "2021-06-16T14:47:29.575723Z",
     "shell.execute_reply.started": "2021-06-16T14:47:29.567813Z"
    }
   },
   "outputs": [],
   "source": [
    "# !cp pre-trained-models/efficientdet_d2_coco17_tpu-32/pipeline.config models/my_efficientdet_d2_coco17_tpu-32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At this point — go open and edit models/my_ssd_resnet50_v1_fpn/pipeline.config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use uploaded pipeline.config (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp Reserves/efficientdet_d2_coco17_tpu-32/pipeline.config models/my_efficientdet_d2_coco17_tpu-32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp models/research/object_detection/model_main_tf2.py .\n",
    "# !python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:29.567849Z",
     "iopub.status.busy": "2021-06-16T14:47:29.567446Z",
     "iopub.status.idle": "2021-06-16T14:47:29.576510Z",
     "shell.execute_reply": "2021-06-16T14:47:29.575723Z",
     "shell.execute_reply.started": "2021-06-16T14:47:29.567813Z"
    }
   },
   "outputs": [],
   "source": [
    "!cp models/research/object_detection/model_main_tf2.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T14:47:29.567849Z",
     "iopub.status.busy": "2021-06-16T14:47:29.567446Z",
     "iopub.status.idle": "2021-06-16T14:47:29.576510Z",
     "shell.execute_reply": "2021-06-16T14:47:29.575723Z",
     "shell.execute_reply.started": "2021-06-16T14:47:29.567813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-23 10:20:33.510635: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 10:20:35.063985: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-23 10:20:35.107149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.107559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:20:35.107605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.107916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:20:35.107931: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 10:20:35.109655: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-23 10:20:35.109685: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-23 10:20:35.110206: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-23 10:20:35.110338: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-23 10:20:35.110851: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-06-23 10:20:35.111274: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-23 10:20:35.111366: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-23 10:20:35.111414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.111793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.112128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.112465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.112772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-06-23 10:20:35.112983: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-23 10:20:35.271827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.272138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:20:35.272201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.272480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 10:20:35.272522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.272820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.273189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.273516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.273817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-06-23 10:20:35.273846: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 10:20:35.768156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-23 10:20:35.768189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2021-06-23 10:20:35.768194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N \n",
      "2021-06-23 10:20:35.768197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N \n",
      "2021-06-23 10:20:35.768356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.768716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.769022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.769323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.769622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.769907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9653 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-06-23 10:20:35.770151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 10:20:35.770431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9615 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0623 10:20:35.772382 139760059615040 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "I0623 10:20:35.921791 139760059615040 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Maybe overwriting train_steps: None\n",
      "I0623 10:20:35.924892 139760059615040 config_util.py:552] Maybe overwriting train_steps: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0623 10:20:35.924951 139760059615040 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I0623 10:20:35.937279 139760059615040 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0623 10:20:35.937345 139760059615040 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0623 10:20:35.937386 139760059615040 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
      "I0623 10:20:35.942829 139760059615040 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.961328 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.962565 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.964520 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.965117 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.968914 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.971492 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.975129 139760059615040 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 10:20:35.975185 139760059615040 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.985095 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.985702 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.987142 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:35.987704 139760059615040 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0623 10:20:36.098936 139760059615040 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 10:20:36.099011 139760059615040 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:20:36.340367 139760059615040 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 10:20:36.340449 139760059615040 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 10:20:36.582697 139760059615040 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 10:20:36.582789 139760059615040 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0623 10:20:36.906823 139760059615040 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0623 10:20:36.906914 139760059615040 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0623 10:20:37.231847 139760059615040 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0623 10:20:37.231935 139760059615040 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0623 10:20:37.641115 139760059615040 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0623 10:20:37.641209 139760059615040 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0623 10:20:37.806036 139760059615040 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0623 10:20:37.839378 139760059615040 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0623 10:20:37.890379 139760059615040 deprecation.py:336] From /.local/lib/python3.6/site-packages/object_detection/model_lib_v2.py:558: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['tfrecord_train.tfrec']\n",
      "I0623 10:20:37.892642 139760059615040 dataset_builder.py:163] Reading unweighted datasets: ['tfrecord_train.tfrec']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['tfrecord_train.tfrec']\n",
      "I0623 10:20:37.892727 139760059615040 dataset_builder.py:80] Reading record datasets for input file: ['tfrecord_train.tfrec']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0623 10:20:37.892772 139760059615040 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0623 10:20:37.892810 139760059615040 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0623 10:20:37.893958 139760059615040 deprecation.py:336] From /.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0623 10:20:37.908084 139760059615040 deprecation.py:336] From /.local/lib/python3.6/site-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W0623 10:20:42.830069 139760059615040 deprecation.py:336] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W0623 10:20:45.796969 139760059615040 deprecation.py:336] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2021-06-23 10:20:47.349744: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-06-23 10:20:47.371766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3600000000 Hz\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:435: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
      "2021-06-23 10:21:16.555507: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-23 10:21:16.861464: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-06-23 10:21:17.277273: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100\n",
      "2021-06-23 10:21:17.384222: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-23 10:21:17.822796: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W0623 10:21:23.045233 139728598836992 deprecation.py:534] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:21:29.089263 139728598836992 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:21:35.441922 139728607229696 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0623 10:21:35.484627 139760059615040 cross_device_ops.py:903] batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:21:47.818727 139728607229696 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:21:53.564797 139728598836992 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0623 10:21:53.606722 139760059615040 cross_device_ops.py:903] batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:22:05.019123 139728598836992 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:22:11.271345 139728607229696 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0623 10:22:11.313400 139760059615040 cross_device_ops.py:903] batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:22:23.872729 139728607229696 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "W0623 10:22:29.626367 139728598836992 utils.py:80] Gradients do not exist for variables ['stack_6/block_1/expand_bn/gamma:0', 'stack_6/block_1/expand_bn/beta:0', 'stack_6/block_1/depthwise_conv2d/depthwise_kernel:0', 'stack_6/block_1/depthwise_bn/gamma:0', 'stack_6/block_1/depthwise_bn/beta:0', 'stack_6/block_1/project_bn/gamma:0', 'stack_6/block_1/project_bn/beta:0', 'top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss.\n",
      "INFO:tensorflow:batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "I0623 10:22:29.668058 139760059615040 cross_device_ops.py:903] batch_all_reduce: 640 all-reduces with algorithm = nccl, num_packs = 1\n",
      "2021-06-23 10:22:48.854316: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:906] Skipping loop optimization for Merge node with control input: replica_1/train_input_images/write_summary/summary_cond/branch_executed/_3337\n",
      "INFO:tensorflow:Step 100 per-step time 1.208s\n",
      "I0623 10:23:23.584330 139760059615040 model_lib_v2.py:700] Step 100 per-step time 1.208s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.1773336,\n",
      " 'Loss/localization_loss': 0.031609915,\n",
      " 'Loss/regularization_loss': 0.034614842,\n",
      " 'Loss/total_loss': 1.2435583,\n",
      " 'learning_rate': 0.000416}\n",
      "I0623 10:23:23.584665 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 1.1773336,\n",
      " 'Loss/localization_loss': 0.031609915,\n",
      " 'Loss/regularization_loss': 0.034614842,\n",
      " 'Loss/total_loss': 1.2435583,\n",
      " 'learning_rate': 0.000416}\n",
      "INFO:tensorflow:Step 200 per-step time 0.146s\n",
      "I0623 10:23:38.149792 139760059615040 model_lib_v2.py:700] Step 200 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.1542194,\n",
      " 'Loss/localization_loss': 0.027768824,\n",
      " 'Loss/regularization_loss': 0.03461412,\n",
      " 'Loss/total_loss': 1.2166023,\n",
      " 'learning_rate': 0.000732}\n",
      "I0623 10:23:38.150028 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 1.1542194,\n",
      " 'Loss/localization_loss': 0.027768824,\n",
      " 'Loss/regularization_loss': 0.03461412,\n",
      " 'Loss/total_loss': 1.2166023,\n",
      " 'learning_rate': 0.000732}\n",
      "INFO:tensorflow:Step 300 per-step time 0.145s\n",
      "I0623 10:23:52.627580 139760059615040 model_lib_v2.py:700] Step 300 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 2.0306718,\n",
      " 'Loss/localization_loss': 0.013192321,\n",
      " 'Loss/regularization_loss': 0.03461427,\n",
      " 'Loss/total_loss': 2.0784783,\n",
      " 'learning_rate': 0.001048}\n",
      "I0623 10:23:52.627981 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 2.0306718,\n",
      " 'Loss/localization_loss': 0.013192321,\n",
      " 'Loss/regularization_loss': 0.03461427,\n",
      " 'Loss/total_loss': 2.0784783,\n",
      " 'learning_rate': 0.001048}\n",
      "INFO:tensorflow:Step 400 per-step time 0.147s\n",
      "I0623 10:24:07.286820 139760059615040 model_lib_v2.py:700] Step 400 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.0643412,\n",
      " 'Loss/localization_loss': 0.022111982,\n",
      " 'Loss/regularization_loss': 0.03462076,\n",
      " 'Loss/total_loss': 1.121074,\n",
      " 'learning_rate': 0.0013639999}\n",
      "I0623 10:24:07.287126 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 1.0643412,\n",
      " 'Loss/localization_loss': 0.022111982,\n",
      " 'Loss/regularization_loss': 0.03462076,\n",
      " 'Loss/total_loss': 1.121074,\n",
      " 'learning_rate': 0.0013639999}\n",
      "INFO:tensorflow:Step 500 per-step time 0.145s\n",
      "I0623 10:24:21.751726 139760059615040 model_lib_v2.py:700] Step 500 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.9069483,\n",
      " 'Loss/localization_loss': 0.00953269,\n",
      " 'Loss/regularization_loss': 0.034627896,\n",
      " 'Loss/total_loss': 0.95110893,\n",
      " 'learning_rate': 0.00168}\n",
      "I0623 10:24:21.752031 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.9069483,\n",
      " 'Loss/localization_loss': 0.00953269,\n",
      " 'Loss/regularization_loss': 0.034627896,\n",
      " 'Loss/total_loss': 0.95110893,\n",
      " 'learning_rate': 0.00168}\n",
      "INFO:tensorflow:Step 600 per-step time 0.146s\n",
      "I0623 10:24:36.386300 139760059615040 model_lib_v2.py:700] Step 600 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 2.0669017,\n",
      " 'Loss/localization_loss': 0.009492413,\n",
      " 'Loss/regularization_loss': 0.034713987,\n",
      " 'Loss/total_loss': 2.111108,\n",
      " 'learning_rate': 0.0019959998}\n",
      "I0623 10:24:36.386646 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 2.0669017,\n",
      " 'Loss/localization_loss': 0.009492413,\n",
      " 'Loss/regularization_loss': 0.034713987,\n",
      " 'Loss/total_loss': 2.111108,\n",
      " 'learning_rate': 0.0019959998}\n",
      "INFO:tensorflow:Step 700 per-step time 0.145s\n",
      "I0623 10:24:50.842631 139760059615040 model_lib_v2.py:700] Step 700 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.94267154,\n",
      " 'Loss/localization_loss': 0.009331094,\n",
      " 'Loss/regularization_loss': 0.03472756,\n",
      " 'Loss/total_loss': 0.9867302,\n",
      " 'learning_rate': 0.002312}\n",
      "I0623 10:24:50.842977 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.94267154,\n",
      " 'Loss/localization_loss': 0.009331094,\n",
      " 'Loss/regularization_loss': 0.03472756,\n",
      " 'Loss/total_loss': 0.9867302,\n",
      " 'learning_rate': 0.002312}\n",
      "INFO:tensorflow:Step 800 per-step time 0.146s\n",
      "I0623 10:25:05.445394 139760059615040 model_lib_v2.py:700] Step 800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.9456554,\n",
      " 'Loss/localization_loss': 0.0074530877,\n",
      " 'Loss/regularization_loss': 0.034774862,\n",
      " 'Loss/total_loss': 0.9878834,\n",
      " 'learning_rate': 0.002628}\n",
      "I0623 10:25:05.445699 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.9456554,\n",
      " 'Loss/localization_loss': 0.0074530877,\n",
      " 'Loss/regularization_loss': 0.034774862,\n",
      " 'Loss/total_loss': 0.9878834,\n",
      " 'learning_rate': 0.002628}\n",
      "INFO:tensorflow:Step 900 per-step time 0.146s\n",
      "I0623 10:25:20.010650 139760059615040 model_lib_v2.py:700] Step 900 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.88490164,\n",
      " 'Loss/localization_loss': 0.0062568383,\n",
      " 'Loss/regularization_loss': 0.03478584,\n",
      " 'Loss/total_loss': 0.9259443,\n",
      " 'learning_rate': 0.0029439998}\n",
      "I0623 10:25:20.010925 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.88490164,\n",
      " 'Loss/localization_loss': 0.0062568383,\n",
      " 'Loss/regularization_loss': 0.03478584,\n",
      " 'Loss/total_loss': 0.9259443,\n",
      " 'learning_rate': 0.0029439998}\n",
      "INFO:tensorflow:Step 1000 per-step time 0.146s\n",
      "I0623 10:25:34.659552 139760059615040 model_lib_v2.py:700] Step 1000 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.74676013,\n",
      " 'Loss/localization_loss': 0.005002709,\n",
      " 'Loss/regularization_loss': 0.034806564,\n",
      " 'Loss/total_loss': 0.78656936,\n",
      " 'learning_rate': 0.00326}\n",
      "I0623 10:25:34.659861 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.74676013,\n",
      " 'Loss/localization_loss': 0.005002709,\n",
      " 'Loss/regularization_loss': 0.034806564,\n",
      " 'Loss/total_loss': 0.78656936,\n",
      " 'learning_rate': 0.00326}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.153s\n",
      "I0623 10:25:49.966525 139760059615040 model_lib_v2.py:700] Step 1100 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7399205,\n",
      " 'Loss/localization_loss': 0.00306838,\n",
      " 'Loss/regularization_loss': 0.03481412,\n",
      " 'Loss/total_loss': 0.777803,\n",
      " 'learning_rate': 0.0035759998}\n",
      "I0623 10:25:49.966935 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7399205,\n",
      " 'Loss/localization_loss': 0.00306838,\n",
      " 'Loss/regularization_loss': 0.03481412,\n",
      " 'Loss/total_loss': 0.777803,\n",
      " 'learning_rate': 0.0035759998}\n",
      "INFO:tensorflow:Step 1200 per-step time 0.146s\n",
      "I0623 10:26:04.521788 139760059615040 model_lib_v2.py:700] Step 1200 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.61661136,\n",
      " 'Loss/localization_loss': 0.0041198595,\n",
      " 'Loss/regularization_loss': 0.03481734,\n",
      " 'Loss/total_loss': 0.6555486,\n",
      " 'learning_rate': 0.0038919998}\n",
      "I0623 10:26:04.522185 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.61661136,\n",
      " 'Loss/localization_loss': 0.0041198595,\n",
      " 'Loss/regularization_loss': 0.03481734,\n",
      " 'Loss/total_loss': 0.6555486,\n",
      " 'learning_rate': 0.0038919998}\n",
      "INFO:tensorflow:Step 1300 per-step time 0.146s\n",
      "I0623 10:26:19.078055 139760059615040 model_lib_v2.py:700] Step 1300 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42059404,\n",
      " 'Loss/localization_loss': 0.0050407704,\n",
      " 'Loss/regularization_loss': 0.03483483,\n",
      " 'Loss/total_loss': 0.46046963,\n",
      " 'learning_rate': 0.0042079994}\n",
      "I0623 10:26:19.078398 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42059404,\n",
      " 'Loss/localization_loss': 0.0050407704,\n",
      " 'Loss/regularization_loss': 0.03483483,\n",
      " 'Loss/total_loss': 0.46046963,\n",
      " 'learning_rate': 0.0042079994}\n",
      "INFO:tensorflow:Step 1400 per-step time 0.147s\n",
      "I0623 10:26:33.736477 139760059615040 model_lib_v2.py:700] Step 1400 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7901161,\n",
      " 'Loss/localization_loss': 0.0023376953,\n",
      " 'Loss/regularization_loss': 0.034868702,\n",
      " 'Loss/total_loss': 0.8273225,\n",
      " 'learning_rate': 0.0045239995}\n",
      "I0623 10:26:33.736820 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7901161,\n",
      " 'Loss/localization_loss': 0.0023376953,\n",
      " 'Loss/regularization_loss': 0.034868702,\n",
      " 'Loss/total_loss': 0.8273225,\n",
      " 'learning_rate': 0.0045239995}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.146s\n",
      "I0623 10:26:48.346000 139760059615040 model_lib_v2.py:700] Step 1500 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7138238,\n",
      " 'Loss/localization_loss': 0.0030673575,\n",
      " 'Loss/regularization_loss': 0.034887232,\n",
      " 'Loss/total_loss': 0.75177836,\n",
      " 'learning_rate': 0.0048399996}\n",
      "I0623 10:26:48.346278 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7138238,\n",
      " 'Loss/localization_loss': 0.0030673575,\n",
      " 'Loss/regularization_loss': 0.034887232,\n",
      " 'Loss/total_loss': 0.75177836,\n",
      " 'learning_rate': 0.0048399996}\n",
      "INFO:tensorflow:Step 1600 per-step time 0.147s\n",
      "I0623 10:27:02.997060 139760059615040 model_lib_v2.py:700] Step 1600 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5921781,\n",
      " 'Loss/localization_loss': 0.0055655716,\n",
      " 'Loss/regularization_loss': 0.03488775,\n",
      " 'Loss/total_loss': 0.6326314,\n",
      " 'learning_rate': 0.0051559997}\n",
      "I0623 10:27:02.997364 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5921781,\n",
      " 'Loss/localization_loss': 0.0055655716,\n",
      " 'Loss/regularization_loss': 0.03488775,\n",
      " 'Loss/total_loss': 0.6326314,\n",
      " 'learning_rate': 0.0051559997}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.146s\n",
      "I0623 10:27:17.579589 139760059615040 model_lib_v2.py:700] Step 1700 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5572705,\n",
      " 'Loss/localization_loss': 0.0016602913,\n",
      " 'Loss/regularization_loss': 0.034898836,\n",
      " 'Loss/total_loss': 0.59382963,\n",
      " 'learning_rate': 0.0054719993}\n",
      "I0623 10:27:17.580002 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5572705,\n",
      " 'Loss/localization_loss': 0.0016602913,\n",
      " 'Loss/regularization_loss': 0.034898836,\n",
      " 'Loss/total_loss': 0.59382963,\n",
      " 'learning_rate': 0.0054719993}\n",
      "INFO:tensorflow:Step 1800 per-step time 0.146s\n",
      "I0623 10:27:32.196918 139760059615040 model_lib_v2.py:700] Step 1800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.77176625,\n",
      " 'Loss/localization_loss': 0.0049213055,\n",
      " 'Loss/regularization_loss': 0.03489803,\n",
      " 'Loss/total_loss': 0.8115856,\n",
      " 'learning_rate': 0.0057879994}\n",
      "I0623 10:27:32.197315 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.77176625,\n",
      " 'Loss/localization_loss': 0.0049213055,\n",
      " 'Loss/regularization_loss': 0.03489803,\n",
      " 'Loss/total_loss': 0.8115856,\n",
      " 'learning_rate': 0.0057879994}\n",
      "INFO:tensorflow:Step 1900 per-step time 0.147s\n",
      "I0623 10:27:46.903682 139760059615040 model_lib_v2.py:700] Step 1900 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.47481844,\n",
      " 'Loss/localization_loss': 0.0011485886,\n",
      " 'Loss/regularization_loss': 0.03489537,\n",
      " 'Loss/total_loss': 0.51086235,\n",
      " 'learning_rate': 0.0061039994}\n",
      "I0623 10:27:46.903971 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.47481844,\n",
      " 'Loss/localization_loss': 0.0011485886,\n",
      " 'Loss/regularization_loss': 0.03489537,\n",
      " 'Loss/total_loss': 0.51086235,\n",
      " 'learning_rate': 0.0061039994}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.147s\n",
      "I0623 10:28:01.647090 139760059615040 model_lib_v2.py:700] Step 2000 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.43812734,\n",
      " 'Loss/localization_loss': 0.0016717333,\n",
      " 'Loss/regularization_loss': 0.034938984,\n",
      " 'Loss/total_loss': 0.47473806,\n",
      " 'learning_rate': 0.0064199995}\n",
      "I0623 10:28:01.647439 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.43812734,\n",
      " 'Loss/localization_loss': 0.0016717333,\n",
      " 'Loss/regularization_loss': 0.034938984,\n",
      " 'Loss/total_loss': 0.47473806,\n",
      " 'learning_rate': 0.0064199995}\n",
      "INFO:tensorflow:Step 2100 per-step time 0.154s\n",
      "I0623 10:28:17.077706 139760059615040 model_lib_v2.py:700] Step 2100 per-step time 0.154s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.58745205,\n",
      " 'Loss/localization_loss': 0.0012672516,\n",
      " 'Loss/regularization_loss': 0.03496412,\n",
      " 'Loss/total_loss': 0.62368345,\n",
      " 'learning_rate': 0.006735999}\n",
      "I0623 10:28:17.078059 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.58745205,\n",
      " 'Loss/localization_loss': 0.0012672516,\n",
      " 'Loss/regularization_loss': 0.03496412,\n",
      " 'Loss/total_loss': 0.62368345,\n",
      " 'learning_rate': 0.006735999}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.145s\n",
      "I0623 10:28:31.590153 139760059615040 model_lib_v2.py:700] Step 2200 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35593885,\n",
      " 'Loss/localization_loss': 0.001103155,\n",
      " 'Loss/regularization_loss': 0.03496134,\n",
      " 'Loss/total_loss': 0.39200336,\n",
      " 'learning_rate': 0.007051999}\n",
      "I0623 10:28:31.590430 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35593885,\n",
      " 'Loss/localization_loss': 0.001103155,\n",
      " 'Loss/regularization_loss': 0.03496134,\n",
      " 'Loss/total_loss': 0.39200336,\n",
      " 'learning_rate': 0.007051999}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.146s\n",
      "I0623 10:28:46.156420 139760059615040 model_lib_v2.py:700] Step 2300 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.9092693,\n",
      " 'Loss/localization_loss': 0.001596017,\n",
      " 'Loss/regularization_loss': 0.035047214,\n",
      " 'Loss/total_loss': 0.9459125,\n",
      " 'learning_rate': 0.0073679993}\n",
      "I0623 10:28:46.156817 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.9092693,\n",
      " 'Loss/localization_loss': 0.001596017,\n",
      " 'Loss/regularization_loss': 0.035047214,\n",
      " 'Loss/total_loss': 0.9459125,\n",
      " 'learning_rate': 0.0073679993}\n",
      "INFO:tensorflow:Step 2400 per-step time 0.146s\n",
      "I0623 10:29:00.735637 139760059615040 model_lib_v2.py:700] Step 2400 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5678069,\n",
      " 'Loss/localization_loss': 0.0006059086,\n",
      " 'Loss/regularization_loss': 0.03505504,\n",
      " 'Loss/total_loss': 0.6034678,\n",
      " 'learning_rate': 0.0076839994}\n",
      "I0623 10:29:00.735983 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5678069,\n",
      " 'Loss/localization_loss': 0.0006059086,\n",
      " 'Loss/regularization_loss': 0.03505504,\n",
      " 'Loss/total_loss': 0.6034678,\n",
      " 'learning_rate': 0.0076839994}\n",
      "INFO:tensorflow:Step 2500 per-step time 0.147s\n",
      "I0623 10:29:15.425292 139760059615040 model_lib_v2.py:700] Step 2500 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.66200656,\n",
      " 'Loss/localization_loss': 0.0019929365,\n",
      " 'Loss/regularization_loss': 0.035052326,\n",
      " 'Loss/total_loss': 0.6990518,\n",
      " 'learning_rate': 0.007999999}\n",
      "I0623 10:29:15.425640 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.66200656,\n",
      " 'Loss/localization_loss': 0.0019929365,\n",
      " 'Loss/regularization_loss': 0.035052326,\n",
      " 'Loss/total_loss': 0.6990518,\n",
      " 'learning_rate': 0.007999999}\n",
      "INFO:tensorflow:Step 2600 per-step time 0.146s\n",
      "I0623 10:29:30.043883 139760059615040 model_lib_v2.py:700] Step 2600 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38662893,\n",
      " 'Loss/localization_loss': 0.0017722822,\n",
      " 'Loss/regularization_loss': 0.03504884,\n",
      " 'Loss/total_loss': 0.42345005,\n",
      " 'learning_rate': 0.007999355}\n",
      "I0623 10:29:30.044251 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.38662893,\n",
      " 'Loss/localization_loss': 0.0017722822,\n",
      " 'Loss/regularization_loss': 0.03504884,\n",
      " 'Loss/total_loss': 0.42345005,\n",
      " 'learning_rate': 0.007999355}\n",
      "INFO:tensorflow:Step 2700 per-step time 0.146s\n",
      "I0623 10:29:44.669851 139760059615040 model_lib_v2.py:700] Step 2700 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.68347967,\n",
      " 'Loss/localization_loss': 0.0024590802,\n",
      " 'Loss/regularization_loss': 0.035059378,\n",
      " 'Loss/total_loss': 0.72099817,\n",
      " 'learning_rate': 0.007997422}\n",
      "I0623 10:29:44.670169 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.68347967,\n",
      " 'Loss/localization_loss': 0.0024590802,\n",
      " 'Loss/regularization_loss': 0.035059378,\n",
      " 'Loss/total_loss': 0.72099817,\n",
      " 'learning_rate': 0.007997422}\n",
      "INFO:tensorflow:Step 2800 per-step time 0.147s\n",
      "I0623 10:29:59.382521 139760059615040 model_lib_v2.py:700] Step 2800 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.51693285,\n",
      " 'Loss/localization_loss': 0.0015947872,\n",
      " 'Loss/regularization_loss': 0.035054367,\n",
      " 'Loss/total_loss': 0.55358195,\n",
      " 'learning_rate': 0.0079942}\n",
      "I0623 10:29:59.382868 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.51693285,\n",
      " 'Loss/localization_loss': 0.0015947872,\n",
      " 'Loss/regularization_loss': 0.035054367,\n",
      " 'Loss/total_loss': 0.55358195,\n",
      " 'learning_rate': 0.0079942}\n",
      "INFO:tensorflow:Step 2900 per-step time 0.148s\n",
      "I0623 10:30:14.166584 139760059615040 model_lib_v2.py:700] Step 2900 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6283243,\n",
      " 'Loss/localization_loss': 0.0010794376,\n",
      " 'Loss/regularization_loss': 0.035057798,\n",
      " 'Loss/total_loss': 0.6644615,\n",
      " 'learning_rate': 0.007989692}\n",
      "I0623 10:30:14.166842 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6283243,\n",
      " 'Loss/localization_loss': 0.0010794376,\n",
      " 'Loss/regularization_loss': 0.035057798,\n",
      " 'Loss/total_loss': 0.6644615,\n",
      " 'learning_rate': 0.007989692}\n",
      "INFO:tensorflow:Step 3000 per-step time 0.146s\n",
      "I0623 10:30:28.734630 139760059615040 model_lib_v2.py:700] Step 3000 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7677897,\n",
      " 'Loss/localization_loss': 0.0013879112,\n",
      " 'Loss/regularization_loss': 0.035066746,\n",
      " 'Loss/total_loss': 0.8042443,\n",
      " 'learning_rate': 0.007983897}\n",
      "I0623 10:30:28.734979 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7677897,\n",
      " 'Loss/localization_loss': 0.0013879112,\n",
      " 'Loss/regularization_loss': 0.035066746,\n",
      " 'Loss/total_loss': 0.8042443,\n",
      " 'learning_rate': 0.007983897}\n",
      "INFO:tensorflow:Step 3100 per-step time 0.153s\n",
      "I0623 10:30:44.080355 139760059615040 model_lib_v2.py:700] Step 3100 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.45610526,\n",
      " 'Loss/localization_loss': 0.0007847593,\n",
      " 'Loss/regularization_loss': 0.035059944,\n",
      " 'Loss/total_loss': 0.49194995,\n",
      " 'learning_rate': 0.007976819}\n",
      "I0623 10:30:44.080634 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.45610526,\n",
      " 'Loss/localization_loss': 0.0007847593,\n",
      " 'Loss/regularization_loss': 0.035059944,\n",
      " 'Loss/total_loss': 0.49194995,\n",
      " 'learning_rate': 0.007976819}\n",
      "INFO:tensorflow:Step 3200 per-step time 0.146s\n",
      "I0623 10:30:58.686062 139760059615040 model_lib_v2.py:700] Step 3200 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39965826,\n",
      " 'Loss/localization_loss': 0.0011294464,\n",
      " 'Loss/regularization_loss': 0.03505539,\n",
      " 'Loss/total_loss': 0.4358431,\n",
      " 'learning_rate': 0.007968458}\n",
      "I0623 10:30:58.686344 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39965826,\n",
      " 'Loss/localization_loss': 0.0011294464,\n",
      " 'Loss/regularization_loss': 0.03505539,\n",
      " 'Loss/total_loss': 0.4358431,\n",
      " 'learning_rate': 0.007968458}\n",
      "INFO:tensorflow:Step 3300 per-step time 0.147s\n",
      "I0623 10:31:13.411373 139760059615040 model_lib_v2.py:700] Step 3300 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4857874,\n",
      " 'Loss/localization_loss': 0.00085432106,\n",
      " 'Loss/regularization_loss': 0.035049044,\n",
      " 'Loss/total_loss': 0.5216907,\n",
      " 'learning_rate': 0.007958819}\n",
      "I0623 10:31:13.411739 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4857874,\n",
      " 'Loss/localization_loss': 0.00085432106,\n",
      " 'Loss/regularization_loss': 0.035049044,\n",
      " 'Loss/total_loss': 0.5216907,\n",
      " 'learning_rate': 0.007958819}\n",
      "INFO:tensorflow:Step 3400 per-step time 0.146s\n",
      "I0623 10:31:28.044316 139760059615040 model_lib_v2.py:700] Step 3400 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38573712,\n",
      " 'Loss/localization_loss': 0.000406208,\n",
      " 'Loss/regularization_loss': 0.03504454,\n",
      " 'Loss/total_loss': 0.42118788,\n",
      " 'learning_rate': 0.007947905}\n",
      "I0623 10:31:28.044663 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.38573712,\n",
      " 'Loss/localization_loss': 0.000406208,\n",
      " 'Loss/regularization_loss': 0.03504454,\n",
      " 'Loss/total_loss': 0.42118788,\n",
      " 'learning_rate': 0.007947905}\n",
      "INFO:tensorflow:Step 3500 per-step time 0.147s\n",
      "I0623 10:31:42.724021 139760059615040 model_lib_v2.py:700] Step 3500 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.50071347,\n",
      " 'Loss/localization_loss': 0.0006867313,\n",
      " 'Loss/regularization_loss': 0.03504451,\n",
      " 'Loss/total_loss': 0.5364447,\n",
      " 'learning_rate': 0.007935718}\n",
      "I0623 10:31:42.724427 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.50071347,\n",
      " 'Loss/localization_loss': 0.0006867313,\n",
      " 'Loss/regularization_loss': 0.03504451,\n",
      " 'Loss/total_loss': 0.5364447,\n",
      " 'learning_rate': 0.007935718}\n",
      "INFO:tensorflow:Step 3600 per-step time 0.147s\n",
      "I0623 10:31:57.444754 139760059615040 model_lib_v2.py:700] Step 3600 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3353935,\n",
      " 'Loss/localization_loss': 0.00029490347,\n",
      " 'Loss/regularization_loss': 0.03503817,\n",
      " 'Loss/total_loss': 0.3707266,\n",
      " 'learning_rate': 0.007922263}\n",
      "I0623 10:31:57.445104 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3353935,\n",
      " 'Loss/localization_loss': 0.00029490347,\n",
      " 'Loss/regularization_loss': 0.03503817,\n",
      " 'Loss/total_loss': 0.3707266,\n",
      " 'learning_rate': 0.007922263}\n",
      "INFO:tensorflow:Step 3700 per-step time 0.146s\n",
      "I0623 10:32:12.081628 139760059615040 model_lib_v2.py:700] Step 3700 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6880829,\n",
      " 'Loss/localization_loss': 0.00081290846,\n",
      " 'Loss/regularization_loss': 0.0350389,\n",
      " 'Loss/total_loss': 0.72393465,\n",
      " 'learning_rate': 0.007907543}\n",
      "I0623 10:32:12.081910 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6880829,\n",
      " 'Loss/localization_loss': 0.00081290846,\n",
      " 'Loss/regularization_loss': 0.0350389,\n",
      " 'Loss/total_loss': 0.72393465,\n",
      " 'learning_rate': 0.007907543}\n",
      "INFO:tensorflow:Step 3800 per-step time 0.147s\n",
      "I0623 10:32:26.753190 139760059615040 model_lib_v2.py:700] Step 3800 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.58819187,\n",
      " 'Loss/localization_loss': 0.0014054055,\n",
      " 'Loss/regularization_loss': 0.035032332,\n",
      " 'Loss/total_loss': 0.6246296,\n",
      " 'learning_rate': 0.007891565}\n",
      "I0623 10:32:26.753539 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.58819187,\n",
      " 'Loss/localization_loss': 0.0014054055,\n",
      " 'Loss/regularization_loss': 0.035032332,\n",
      " 'Loss/total_loss': 0.6246296,\n",
      " 'learning_rate': 0.007891565}\n",
      "INFO:tensorflow:Step 3900 per-step time 0.149s\n",
      "I0623 10:32:41.612008 139760059615040 model_lib_v2.py:700] Step 3900 per-step time 0.149s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3158934,\n",
      " 'Loss/localization_loss': 0.0005580283,\n",
      " 'Loss/regularization_loss': 0.035026655,\n",
      " 'Loss/total_loss': 0.3514781,\n",
      " 'learning_rate': 0.007874331}\n",
      "I0623 10:32:41.612417 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3158934,\n",
      " 'Loss/localization_loss': 0.0005580283,\n",
      " 'Loss/regularization_loss': 0.035026655,\n",
      " 'Loss/total_loss': 0.3514781,\n",
      " 'learning_rate': 0.007874331}\n",
      "INFO:tensorflow:Step 4000 per-step time 0.147s\n",
      "I0623 10:32:56.317457 139760059615040 model_lib_v2.py:700] Step 4000 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4970562,\n",
      " 'Loss/localization_loss': 0.0006393811,\n",
      " 'Loss/regularization_loss': 0.03504944,\n",
      " 'Loss/total_loss': 0.532745,\n",
      " 'learning_rate': 0.00785585}\n",
      "I0623 10:32:56.317813 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4970562,\n",
      " 'Loss/localization_loss': 0.0006393811,\n",
      " 'Loss/regularization_loss': 0.03504944,\n",
      " 'Loss/total_loss': 0.532745,\n",
      " 'learning_rate': 0.00785585}\n",
      "INFO:tensorflow:Step 4100 per-step time 0.154s\n",
      "I0623 10:33:11.722070 139760059615040 model_lib_v2.py:700] Step 4100 per-step time 0.154s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.0269519,\n",
      " 'Loss/localization_loss': 0.00044098444,\n",
      " 'Loss/regularization_loss': 0.03503987,\n",
      " 'Loss/total_loss': 1.0624328,\n",
      " 'learning_rate': 0.007836128}\n",
      "I0623 10:33:11.722334 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 1.0269519,\n",
      " 'Loss/localization_loss': 0.00044098444,\n",
      " 'Loss/regularization_loss': 0.03503987,\n",
      " 'Loss/total_loss': 1.0624328,\n",
      " 'learning_rate': 0.007836128}\n",
      "INFO:tensorflow:Step 4200 per-step time 0.147s\n",
      "I0623 10:33:26.385239 139760059615040 model_lib_v2.py:700] Step 4200 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5111756,\n",
      " 'Loss/localization_loss': 0.00052330445,\n",
      " 'Loss/regularization_loss': 0.035035446,\n",
      " 'Loss/total_loss': 0.54673433,\n",
      " 'learning_rate': 0.007815167}\n",
      "I0623 10:33:26.385536 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5111756,\n",
      " 'Loss/localization_loss': 0.00052330445,\n",
      " 'Loss/regularization_loss': 0.035035446,\n",
      " 'Loss/total_loss': 0.54673433,\n",
      " 'learning_rate': 0.007815167}\n",
      "INFO:tensorflow:Step 4300 per-step time 0.147s\n",
      "I0623 10:33:41.104552 139760059615040 model_lib_v2.py:700] Step 4300 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.63127774,\n",
      " 'Loss/localization_loss': 0.00065669307,\n",
      " 'Loss/regularization_loss': 0.03503428,\n",
      " 'Loss/total_loss': 0.6669687,\n",
      " 'learning_rate': 0.0077929776}\n",
      "I0623 10:33:41.104933 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.63127774,\n",
      " 'Loss/localization_loss': 0.00065669307,\n",
      " 'Loss/regularization_loss': 0.03503428,\n",
      " 'Loss/total_loss': 0.6669687,\n",
      " 'learning_rate': 0.0077929776}\n",
      "INFO:tensorflow:Step 4400 per-step time 0.146s\n",
      "I0623 10:33:55.727859 139760059615040 model_lib_v2.py:700] Step 4400 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5048791,\n",
      " 'Loss/localization_loss': 0.0020897626,\n",
      " 'Loss/regularization_loss': 0.035026934,\n",
      " 'Loss/total_loss': 0.54199576,\n",
      " 'learning_rate': 0.0077695656}\n",
      "I0623 10:33:55.728109 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5048791,\n",
      " 'Loss/localization_loss': 0.0020897626,\n",
      " 'Loss/regularization_loss': 0.035026934,\n",
      " 'Loss/total_loss': 0.54199576,\n",
      " 'learning_rate': 0.0077695656}\n",
      "INFO:tensorflow:Step 4500 per-step time 0.147s\n",
      "I0623 10:34:10.472157 139760059615040 model_lib_v2.py:700] Step 4500 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.46058804,\n",
      " 'Loss/localization_loss': 0.0002567074,\n",
      " 'Loss/regularization_loss': 0.03502371,\n",
      " 'Loss/total_loss': 0.49586844,\n",
      " 'learning_rate': 0.007744939}\n",
      "I0623 10:34:10.472501 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.46058804,\n",
      " 'Loss/localization_loss': 0.0002567074,\n",
      " 'Loss/regularization_loss': 0.03502371,\n",
      " 'Loss/total_loss': 0.49586844,\n",
      " 'learning_rate': 0.007744939}\n",
      "INFO:tensorflow:Step 4600 per-step time 0.148s\n",
      "I0623 10:34:25.316867 139760059615040 model_lib_v2.py:700] Step 4600 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36805153,\n",
      " 'Loss/localization_loss': 0.0005869916,\n",
      " 'Loss/regularization_loss': 0.03501618,\n",
      " 'Loss/total_loss': 0.40365466,\n",
      " 'learning_rate': 0.007719105}\n",
      "I0623 10:34:25.317247 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.36805153,\n",
      " 'Loss/localization_loss': 0.0005869916,\n",
      " 'Loss/regularization_loss': 0.03501618,\n",
      " 'Loss/total_loss': 0.40365466,\n",
      " 'learning_rate': 0.007719105}\n",
      "INFO:tensorflow:Step 4700 per-step time 0.147s\n",
      "I0623 10:34:40.032845 139760059615040 model_lib_v2.py:700] Step 4700 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.46329856,\n",
      " 'Loss/localization_loss': 0.0004154895,\n",
      " 'Loss/regularization_loss': 0.035014305,\n",
      " 'Loss/total_loss': 0.49872833,\n",
      " 'learning_rate': 0.0076920735}\n",
      "I0623 10:34:40.033194 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.46329856,\n",
      " 'Loss/localization_loss': 0.0004154895,\n",
      " 'Loss/regularization_loss': 0.035014305,\n",
      " 'Loss/total_loss': 0.49872833,\n",
      " 'learning_rate': 0.0076920735}\n",
      "INFO:tensorflow:Step 4800 per-step time 0.147s\n",
      "I0623 10:34:54.709658 139760059615040 model_lib_v2.py:700] Step 4800 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.51553774,\n",
      " 'Loss/localization_loss': 0.0003038919,\n",
      " 'Loss/regularization_loss': 0.035012808,\n",
      " 'Loss/total_loss': 0.55085444,\n",
      " 'learning_rate': 0.007663851}\n",
      "I0623 10:34:54.709930 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.51553774,\n",
      " 'Loss/localization_loss': 0.0003038919,\n",
      " 'Loss/regularization_loss': 0.035012808,\n",
      " 'Loss/total_loss': 0.55085444,\n",
      " 'learning_rate': 0.007663851}\n",
      "INFO:tensorflow:Step 4900 per-step time 0.147s\n",
      "I0623 10:35:09.374846 139760059615040 model_lib_v2.py:700] Step 4900 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40861434,\n",
      " 'Loss/localization_loss': 0.00064916105,\n",
      " 'Loss/regularization_loss': 0.03500745,\n",
      " 'Loss/total_loss': 0.4442709,\n",
      " 'learning_rate': 0.0076344484}\n",
      "I0623 10:35:09.375248 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.40861434,\n",
      " 'Loss/localization_loss': 0.00064916105,\n",
      " 'Loss/regularization_loss': 0.03500745,\n",
      " 'Loss/total_loss': 0.4442709,\n",
      " 'learning_rate': 0.0076344484}\n",
      "INFO:tensorflow:Step 5000 per-step time 0.147s\n",
      "I0623 10:35:24.056635 139760059615040 model_lib_v2.py:700] Step 5000 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6941087,\n",
      " 'Loss/localization_loss': 0.0009917205,\n",
      " 'Loss/regularization_loss': 0.035005316,\n",
      " 'Loss/total_loss': 0.73010576,\n",
      " 'learning_rate': 0.0076038744}\n",
      "I0623 10:35:24.056981 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6941087,\n",
      " 'Loss/localization_loss': 0.0009917205,\n",
      " 'Loss/regularization_loss': 0.035005316,\n",
      " 'Loss/total_loss': 0.73010576,\n",
      " 'learning_rate': 0.0076038744}\n",
      "INFO:tensorflow:Step 5100 per-step time 0.150s\n",
      "I0623 10:35:39.067505 139760059615040 model_lib_v2.py:700] Step 5100 per-step time 0.150s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6196288,\n",
      " 'Loss/localization_loss': 0.00092221494,\n",
      " 'Loss/regularization_loss': 0.034997873,\n",
      " 'Loss/total_loss': 0.6555488,\n",
      " 'learning_rate': 0.0075721396}\n",
      "I0623 10:35:39.067703 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6196288,\n",
      " 'Loss/localization_loss': 0.00092221494,\n",
      " 'Loss/regularization_loss': 0.034997873,\n",
      " 'Loss/total_loss': 0.6555488,\n",
      " 'learning_rate': 0.0075721396}\n",
      "INFO:tensorflow:Step 5200 per-step time 0.144s\n",
      "I0623 10:35:53.494633 139760059615040 model_lib_v2.py:700] Step 5200 per-step time 0.144s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4780715,\n",
      " 'Loss/localization_loss': 0.0008751158,\n",
      " 'Loss/regularization_loss': 0.034991257,\n",
      " 'Loss/total_loss': 0.5139379,\n",
      " 'learning_rate': 0.007539253}\n",
      "I0623 10:35:53.494818 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4780715,\n",
      " 'Loss/localization_loss': 0.0008751158,\n",
      " 'Loss/regularization_loss': 0.034991257,\n",
      " 'Loss/total_loss': 0.5139379,\n",
      " 'learning_rate': 0.007539253}\n",
      "INFO:tensorflow:Step 5300 per-step time 0.144s\n",
      "I0623 10:36:07.889454 139760059615040 model_lib_v2.py:700] Step 5300 per-step time 0.144s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.44403136,\n",
      " 'Loss/localization_loss': 0.0005817252,\n",
      " 'Loss/regularization_loss': 0.034983765,\n",
      " 'Loss/total_loss': 0.4795968,\n",
      " 'learning_rate': 0.0075052264}\n",
      "I0623 10:36:07.889638 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.44403136,\n",
      " 'Loss/localization_loss': 0.0005817252,\n",
      " 'Loss/regularization_loss': 0.034983765,\n",
      " 'Loss/total_loss': 0.4795968,\n",
      " 'learning_rate': 0.0075052264}\n",
      "INFO:tensorflow:Step 5400 per-step time 0.143s\n",
      "I0623 10:36:22.231785 139760059615040 model_lib_v2.py:700] Step 5400 per-step time 0.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6821995,\n",
      " 'Loss/localization_loss': 0.00036133343,\n",
      " 'Loss/regularization_loss': 0.034987364,\n",
      " 'Loss/total_loss': 0.71754813,\n",
      " 'learning_rate': 0.0074700695}\n",
      "I0623 10:36:22.231972 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6821995,\n",
      " 'Loss/localization_loss': 0.00036133343,\n",
      " 'Loss/regularization_loss': 0.034987364,\n",
      " 'Loss/total_loss': 0.71754813,\n",
      " 'learning_rate': 0.0074700695}\n",
      "INFO:tensorflow:Step 5500 per-step time 0.144s\n",
      "I0623 10:36:36.605593 139760059615040 model_lib_v2.py:700] Step 5500 per-step time 0.144s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39060292,\n",
      " 'Loss/localization_loss': 0.00050504145,\n",
      " 'Loss/regularization_loss': 0.03498011,\n",
      " 'Loss/total_loss': 0.42608806,\n",
      " 'learning_rate': 0.0074337944}\n",
      "I0623 10:36:36.605795 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39060292,\n",
      " 'Loss/localization_loss': 0.00050504145,\n",
      " 'Loss/regularization_loss': 0.03498011,\n",
      " 'Loss/total_loss': 0.42608806,\n",
      " 'learning_rate': 0.0074337944}\n",
      "INFO:tensorflow:Step 5600 per-step time 0.143s\n",
      "I0623 10:36:50.951472 139760059615040 model_lib_v2.py:700] Step 5600 per-step time 0.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 2.00937,\n",
      " 'Loss/localization_loss': 0.00020542792,\n",
      " 'Loss/regularization_loss': 0.03497998,\n",
      " 'Loss/total_loss': 2.0445557,\n",
      " 'learning_rate': 0.0073964135}\n",
      "I0623 10:36:50.951659 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 2.00937,\n",
      " 'Loss/localization_loss': 0.00020542792,\n",
      " 'Loss/regularization_loss': 0.03497998,\n",
      " 'Loss/total_loss': 2.0445557,\n",
      " 'learning_rate': 0.0073964135}\n",
      "INFO:tensorflow:Step 5700 per-step time 0.144s\n",
      "I0623 10:37:05.405044 139760059615040 model_lib_v2.py:700] Step 5700 per-step time 0.144s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39971882,\n",
      " 'Loss/localization_loss': 0.00026517978,\n",
      " 'Loss/regularization_loss': 0.034974877,\n",
      " 'Loss/total_loss': 0.43495888,\n",
      " 'learning_rate': 0.0073579373}\n",
      "I0623 10:37:05.405381 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39971882,\n",
      " 'Loss/localization_loss': 0.00026517978,\n",
      " 'Loss/regularization_loss': 0.034974877,\n",
      " 'Loss/total_loss': 0.43495888,\n",
      " 'learning_rate': 0.0073579373}\n",
      "INFO:tensorflow:Step 5800 per-step time 0.146s\n",
      "I0623 10:37:20.052240 139760059615040 model_lib_v2.py:700] Step 5800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35759276,\n",
      " 'Loss/localization_loss': 0.00023183628,\n",
      " 'Loss/regularization_loss': 0.034967627,\n",
      " 'Loss/total_loss': 0.39279222,\n",
      " 'learning_rate': 0.007318379}\n",
      "I0623 10:37:20.052520 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35759276,\n",
      " 'Loss/localization_loss': 0.00023183628,\n",
      " 'Loss/regularization_loss': 0.034967627,\n",
      " 'Loss/total_loss': 0.39279222,\n",
      " 'learning_rate': 0.007318379}\n",
      "INFO:tensorflow:Step 5900 per-step time 0.146s\n",
      "I0623 10:37:34.616764 139760059615040 model_lib_v2.py:700] Step 5900 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4557494,\n",
      " 'Loss/localization_loss': 0.0033598626,\n",
      " 'Loss/regularization_loss': 0.034966853,\n",
      " 'Loss/total_loss': 0.49407613,\n",
      " 'learning_rate': 0.0072777513}\n",
      "I0623 10:37:34.617172 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4557494,\n",
      " 'Loss/localization_loss': 0.0033598626,\n",
      " 'Loss/regularization_loss': 0.034966853,\n",
      " 'Loss/total_loss': 0.49407613,\n",
      " 'learning_rate': 0.0072777513}\n",
      "INFO:tensorflow:Step 6000 per-step time 0.145s\n",
      "I0623 10:37:49.160738 139760059615040 model_lib_v2.py:700] Step 6000 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.55305684,\n",
      " 'Loss/localization_loss': 0.00045861254,\n",
      " 'Loss/regularization_loss': 0.03496109,\n",
      " 'Loss/total_loss': 0.58847654,\n",
      " 'learning_rate': 0.007236067}\n",
      "I0623 10:37:49.161085 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.55305684,\n",
      " 'Loss/localization_loss': 0.00045861254,\n",
      " 'Loss/regularization_loss': 0.03496109,\n",
      " 'Loss/total_loss': 0.58847654,\n",
      " 'learning_rate': 0.007236067}\n",
      "INFO:tensorflow:Step 6100 per-step time 0.159s\n",
      "I0623 10:38:05.060883 139760059615040 model_lib_v2.py:700] Step 6100 per-step time 0.159s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.34766492,\n",
      " 'Loss/localization_loss': 0.00041228713,\n",
      " 'Loss/regularization_loss': 0.034955475,\n",
      " 'Loss/total_loss': 0.38303268,\n",
      " 'learning_rate': 0.007193341}\n",
      "I0623 10:38:05.061063 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.34766492,\n",
      " 'Loss/localization_loss': 0.00041228713,\n",
      " 'Loss/regularization_loss': 0.034955475,\n",
      " 'Loss/total_loss': 0.38303268,\n",
      " 'learning_rate': 0.007193341}\n",
      "INFO:tensorflow:Step 6200 per-step time 0.149s\n",
      "I0623 10:38:19.927861 139760059615040 model_lib_v2.py:700] Step 6200 per-step time 0.149s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5142987,\n",
      " 'Loss/localization_loss': 0.00039675267,\n",
      " 'Loss/regularization_loss': 0.03495486,\n",
      " 'Loss/total_loss': 0.5496503,\n",
      " 'learning_rate': 0.007149585}\n",
      "I0623 10:38:19.928110 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5142987,\n",
      " 'Loss/localization_loss': 0.00039675267,\n",
      " 'Loss/regularization_loss': 0.03495486,\n",
      " 'Loss/total_loss': 0.5496503,\n",
      " 'learning_rate': 0.007149585}\n",
      "INFO:tensorflow:Step 6300 per-step time 0.153s\n",
      "I0623 10:38:35.225299 139760059615040 model_lib_v2.py:700] Step 6300 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36696708,\n",
      " 'Loss/localization_loss': 0.00035400892,\n",
      " 'Loss/regularization_loss': 0.03495185,\n",
      " 'Loss/total_loss': 0.40227294,\n",
      " 'learning_rate': 0.007104814}\n",
      "I0623 10:38:35.225510 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.36696708,\n",
      " 'Loss/localization_loss': 0.00035400892,\n",
      " 'Loss/regularization_loss': 0.03495185,\n",
      " 'Loss/total_loss': 0.40227294,\n",
      " 'learning_rate': 0.007104814}\n",
      "INFO:tensorflow:Step 6400 per-step time 0.153s\n",
      "I0623 10:38:50.504281 139760059615040 model_lib_v2.py:700] Step 6400 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5253774,\n",
      " 'Loss/localization_loss': 0.000101189005,\n",
      " 'Loss/regularization_loss': 0.034948032,\n",
      " 'Loss/total_loss': 0.5604266,\n",
      " 'learning_rate': 0.0070590423}\n",
      "I0623 10:38:50.504731 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5253774,\n",
      " 'Loss/localization_loss': 0.000101189005,\n",
      " 'Loss/regularization_loss': 0.034948032,\n",
      " 'Loss/total_loss': 0.5604266,\n",
      " 'learning_rate': 0.0070590423}\n",
      "INFO:tensorflow:Step 6500 per-step time 0.152s\n",
      "I0623 10:39:05.753976 139760059615040 model_lib_v2.py:700] Step 6500 per-step time 0.152s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5253068,\n",
      " 'Loss/localization_loss': 0.0006894913,\n",
      " 'Loss/regularization_loss': 0.03494477,\n",
      " 'Loss/total_loss': 0.5609411,\n",
      " 'learning_rate': 0.0070122853}\n",
      "I0623 10:39:05.754205 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5253068,\n",
      " 'Loss/localization_loss': 0.0006894913,\n",
      " 'Loss/regularization_loss': 0.03494477,\n",
      " 'Loss/total_loss': 0.5609411,\n",
      " 'learning_rate': 0.0070122853}\n",
      "INFO:tensorflow:Step 6600 per-step time 0.153s\n",
      "I0623 10:39:21.083783 139760059615040 model_lib_v2.py:700] Step 6600 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.82474834,\n",
      " 'Loss/localization_loss': 0.00026090734,\n",
      " 'Loss/regularization_loss': 0.034938775,\n",
      " 'Loss/total_loss': 0.85994804,\n",
      " 'learning_rate': 0.0069645573}\n",
      "I0623 10:39:21.084006 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.82474834,\n",
      " 'Loss/localization_loss': 0.00026090734,\n",
      " 'Loss/regularization_loss': 0.034938775,\n",
      " 'Loss/total_loss': 0.85994804,\n",
      " 'learning_rate': 0.0069645573}\n",
      "INFO:tensorflow:Step 6700 per-step time 0.153s\n",
      "I0623 10:39:36.378544 139760059615040 model_lib_v2.py:700] Step 6700 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.37380105,\n",
      " 'Loss/localization_loss': 0.00027380092,\n",
      " 'Loss/regularization_loss': 0.03493317,\n",
      " 'Loss/total_loss': 0.40900806,\n",
      " 'learning_rate': 0.006915874}\n",
      "I0623 10:39:36.378876 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.37380105,\n",
      " 'Loss/localization_loss': 0.00027380092,\n",
      " 'Loss/regularization_loss': 0.03493317,\n",
      " 'Loss/total_loss': 0.40900806,\n",
      " 'learning_rate': 0.006915874}\n",
      "INFO:tensorflow:Step 6800 per-step time 0.154s\n",
      "I0623 10:39:51.781946 139760059615040 model_lib_v2.py:700] Step 6800 per-step time 0.154s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41176337,\n",
      " 'Loss/localization_loss': 0.00047074584,\n",
      " 'Loss/regularization_loss': 0.034926724,\n",
      " 'Loss/total_loss': 0.44716084,\n",
      " 'learning_rate': 0.006866251}\n",
      "I0623 10:39:51.782206 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.41176337,\n",
      " 'Loss/localization_loss': 0.00047074584,\n",
      " 'Loss/regularization_loss': 0.034926724,\n",
      " 'Loss/total_loss': 0.44716084,\n",
      " 'learning_rate': 0.006866251}\n",
      "INFO:tensorflow:Step 6900 per-step time 0.150s\n",
      "I0623 10:40:06.815572 139760059615040 model_lib_v2.py:700] Step 6900 per-step time 0.150s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6947522,\n",
      " 'Loss/localization_loss': 0.00039543008,\n",
      " 'Loss/regularization_loss': 0.034932267,\n",
      " 'Loss/total_loss': 0.7300799,\n",
      " 'learning_rate': 0.006815704}\n",
      "I0623 10:40:06.815917 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6947522,\n",
      " 'Loss/localization_loss': 0.00039543008,\n",
      " 'Loss/regularization_loss': 0.034932267,\n",
      " 'Loss/total_loss': 0.7300799,\n",
      " 'learning_rate': 0.006815704}\n",
      "INFO:tensorflow:Step 7000 per-step time 0.147s\n",
      "I0623 10:40:21.529664 139760059615040 model_lib_v2.py:700] Step 7000 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.52034235,\n",
      " 'Loss/localization_loss': 0.0008193299,\n",
      " 'Loss/regularization_loss': 0.0349252,\n",
      " 'Loss/total_loss': 0.5560869,\n",
      " 'learning_rate': 0.0067642503}\n",
      "I0623 10:40:21.529939 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.52034235,\n",
      " 'Loss/localization_loss': 0.0008193299,\n",
      " 'Loss/regularization_loss': 0.0349252,\n",
      " 'Loss/total_loss': 0.5560869,\n",
      " 'learning_rate': 0.0067642503}\n",
      "INFO:tensorflow:Step 7100 per-step time 0.153s\n",
      "I0623 10:40:36.799369 139760059615040 model_lib_v2.py:700] Step 7100 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.44440925,\n",
      " 'Loss/localization_loss': 0.001090765,\n",
      " 'Loss/regularization_loss': 0.034921344,\n",
      " 'Loss/total_loss': 0.48042136,\n",
      " 'learning_rate': 0.006711905}\n",
      "I0623 10:40:36.799721 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.44440925,\n",
      " 'Loss/localization_loss': 0.001090765,\n",
      " 'Loss/regularization_loss': 0.034921344,\n",
      " 'Loss/total_loss': 0.48042136,\n",
      " 'learning_rate': 0.006711905}\n",
      "INFO:tensorflow:Step 7200 per-step time 0.148s\n",
      "I0623 10:40:51.568411 139760059615040 model_lib_v2.py:700] Step 7200 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4272952,\n",
      " 'Loss/localization_loss': 0.00031071628,\n",
      " 'Loss/regularization_loss': 0.034916267,\n",
      " 'Loss/total_loss': 0.4625222,\n",
      " 'learning_rate': 0.0066586863}\n",
      "I0623 10:40:51.568688 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4272952,\n",
      " 'Loss/localization_loss': 0.00031071628,\n",
      " 'Loss/regularization_loss': 0.034916267,\n",
      " 'Loss/total_loss': 0.4625222,\n",
      " 'learning_rate': 0.0066586863}\n",
      "INFO:tensorflow:Step 7300 per-step time 0.147s\n",
      "I0623 10:41:06.314322 139760059615040 model_lib_v2.py:700] Step 7300 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.83890295,\n",
      " 'Loss/localization_loss': 0.00018593358,\n",
      " 'Loss/regularization_loss': 0.03491625,\n",
      " 'Loss/total_loss': 0.87400514,\n",
      " 'learning_rate': 0.0066046105}\n",
      "I0623 10:41:06.314700 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.83890295,\n",
      " 'Loss/localization_loss': 0.00018593358,\n",
      " 'Loss/regularization_loss': 0.03491625,\n",
      " 'Loss/total_loss': 0.87400514,\n",
      " 'learning_rate': 0.0066046105}\n",
      "INFO:tensorflow:Step 7400 per-step time 0.146s\n",
      "I0623 10:41:20.921010 139760059615040 model_lib_v2.py:700] Step 7400 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5028337,\n",
      " 'Loss/localization_loss': 0.0005852963,\n",
      " 'Loss/regularization_loss': 0.03491215,\n",
      " 'Loss/total_loss': 0.53833115,\n",
      " 'learning_rate': 0.0065496955}\n",
      "I0623 10:41:20.921282 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5028337,\n",
      " 'Loss/localization_loss': 0.0005852963,\n",
      " 'Loss/regularization_loss': 0.03491215,\n",
      " 'Loss/total_loss': 0.53833115,\n",
      " 'learning_rate': 0.0065496955}\n",
      "INFO:tensorflow:Step 7500 per-step time 0.146s\n",
      "I0623 10:41:35.510462 139760059615040 model_lib_v2.py:700] Step 7500 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5233712,\n",
      " 'Loss/localization_loss': 0.00046659732,\n",
      " 'Loss/regularization_loss': 0.034910332,\n",
      " 'Loss/total_loss': 0.5587482,\n",
      " 'learning_rate': 0.006493959}\n",
      "I0623 10:41:35.510864 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5233712,\n",
      " 'Loss/localization_loss': 0.00046659732,\n",
      " 'Loss/regularization_loss': 0.034910332,\n",
      " 'Loss/total_loss': 0.5587482,\n",
      " 'learning_rate': 0.006493959}\n",
      "INFO:tensorflow:Step 7600 per-step time 0.146s\n",
      "I0623 10:41:50.097828 139760059615040 model_lib_v2.py:700] Step 7600 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4746629,\n",
      " 'Loss/localization_loss': 0.00048699853,\n",
      " 'Loss/regularization_loss': 0.0349061,\n",
      " 'Loss/total_loss': 0.510056,\n",
      " 'learning_rate': 0.0064374185}\n",
      "I0623 10:41:50.098104 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4746629,\n",
      " 'Loss/localization_loss': 0.00048699853,\n",
      " 'Loss/regularization_loss': 0.0349061,\n",
      " 'Loss/total_loss': 0.510056,\n",
      " 'learning_rate': 0.0064374185}\n",
      "INFO:tensorflow:Step 7700 per-step time 0.147s\n",
      "I0623 10:42:04.784881 139760059615040 model_lib_v2.py:700] Step 7700 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3755019,\n",
      " 'Loss/localization_loss': 7.69928e-05,\n",
      " 'Loss/regularization_loss': 0.034904424,\n",
      " 'Loss/total_loss': 0.4104833,\n",
      " 'learning_rate': 0.0063800924}\n",
      "I0623 10:42:04.785224 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3755019,\n",
      " 'Loss/localization_loss': 7.69928e-05,\n",
      " 'Loss/regularization_loss': 0.034904424,\n",
      " 'Loss/total_loss': 0.4104833,\n",
      " 'learning_rate': 0.0063800924}\n",
      "INFO:tensorflow:Step 7800 per-step time 0.146s\n",
      "I0623 10:42:19.427603 139760059615040 model_lib_v2.py:700] Step 7800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3089373,\n",
      " 'Loss/localization_loss': 0.00035690685,\n",
      " 'Loss/regularization_loss': 0.034902263,\n",
      " 'Loss/total_loss': 0.3441965,\n",
      " 'learning_rate': 0.0063219992}\n",
      "I0623 10:42:19.427912 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3089373,\n",
      " 'Loss/localization_loss': 0.00035690685,\n",
      " 'Loss/regularization_loss': 0.034902263,\n",
      " 'Loss/total_loss': 0.3441965,\n",
      " 'learning_rate': 0.0063219992}\n",
      "INFO:tensorflow:Step 7900 per-step time 0.147s\n",
      "I0623 10:42:34.080268 139760059615040 model_lib_v2.py:700] Step 7900 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.66818416,\n",
      " 'Loss/localization_loss': 0.00043151283,\n",
      " 'Loss/regularization_loss': 0.034900352,\n",
      " 'Loss/total_loss': 0.703516,\n",
      " 'learning_rate': 0.0062631574}\n",
      "I0623 10:42:34.080625 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.66818416,\n",
      " 'Loss/localization_loss': 0.00043151283,\n",
      " 'Loss/regularization_loss': 0.034900352,\n",
      " 'Loss/total_loss': 0.703516,\n",
      " 'learning_rate': 0.0062631574}\n",
      "INFO:tensorflow:Step 8000 per-step time 0.148s\n",
      "I0623 10:42:48.828890 139760059615040 model_lib_v2.py:700] Step 8000 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5634232,\n",
      " 'Loss/localization_loss': 0.00039361208,\n",
      " 'Loss/regularization_loss': 0.034895476,\n",
      " 'Loss/total_loss': 0.5987123,\n",
      " 'learning_rate': 0.0062035876}\n",
      "I0623 10:42:48.829168 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5634232,\n",
      " 'Loss/localization_loss': 0.00039361208,\n",
      " 'Loss/regularization_loss': 0.034895476,\n",
      " 'Loss/total_loss': 0.5987123,\n",
      " 'learning_rate': 0.0062035876}\n",
      "INFO:tensorflow:Step 8100 per-step time 0.153s\n",
      "I0623 10:43:04.166484 139760059615040 model_lib_v2.py:700] Step 8100 per-step time 0.153s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42221996,\n",
      " 'Loss/localization_loss': 0.00026074675,\n",
      " 'Loss/regularization_loss': 0.03489634,\n",
      " 'Loss/total_loss': 0.45737708,\n",
      " 'learning_rate': 0.0061433064}\n",
      "I0623 10:43:04.166805 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42221996,\n",
      " 'Loss/localization_loss': 0.00026074675,\n",
      " 'Loss/regularization_loss': 0.03489634,\n",
      " 'Loss/total_loss': 0.45737708,\n",
      " 'learning_rate': 0.0061433064}\n",
      "INFO:tensorflow:Step 8200 per-step time 0.147s\n",
      "I0623 10:43:18.851490 139760059615040 model_lib_v2.py:700] Step 8200 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4632724,\n",
      " 'Loss/localization_loss': 0.00014675214,\n",
      " 'Loss/regularization_loss': 0.034890734,\n",
      " 'Loss/total_loss': 0.49830988,\n",
      " 'learning_rate': 0.006082335}\n",
      "I0623 10:43:18.851891 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4632724,\n",
      " 'Loss/localization_loss': 0.00014675214,\n",
      " 'Loss/regularization_loss': 0.034890734,\n",
      " 'Loss/total_loss': 0.49830988,\n",
      " 'learning_rate': 0.006082335}\n",
      "INFO:tensorflow:Step 8300 per-step time 0.146s\n",
      "I0623 10:43:33.470175 139760059615040 model_lib_v2.py:700] Step 8300 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6656582,\n",
      " 'Loss/localization_loss': 0.00061371934,\n",
      " 'Loss/regularization_loss': 0.03489282,\n",
      " 'Loss/total_loss': 0.7011647,\n",
      " 'learning_rate': 0.0060206926}\n",
      "I0623 10:43:33.470522 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6656582,\n",
      " 'Loss/localization_loss': 0.00061371934,\n",
      " 'Loss/regularization_loss': 0.03489282,\n",
      " 'Loss/total_loss': 0.7011647,\n",
      " 'learning_rate': 0.0060206926}\n",
      "INFO:tensorflow:Step 8400 per-step time 0.147s\n",
      "I0623 10:43:48.126725 139760059615040 model_lib_v2.py:700] Step 8400 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.47415748,\n",
      " 'Loss/localization_loss': 0.00014765025,\n",
      " 'Loss/regularization_loss': 0.034888964,\n",
      " 'Loss/total_loss': 0.5091941,\n",
      " 'learning_rate': 0.0059583993}\n",
      "I0623 10:43:48.127027 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.47415748,\n",
      " 'Loss/localization_loss': 0.00014765025,\n",
      " 'Loss/regularization_loss': 0.034888964,\n",
      " 'Loss/total_loss': 0.5091941,\n",
      " 'learning_rate': 0.0059583993}\n",
      "INFO:tensorflow:Step 8500 per-step time 0.146s\n",
      "I0623 10:44:02.678099 139760059615040 model_lib_v2.py:700] Step 8500 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.49180418,\n",
      " 'Loss/localization_loss': 0.0004273167,\n",
      " 'Loss/regularization_loss': 0.03488411,\n",
      " 'Loss/total_loss': 0.5271156,\n",
      " 'learning_rate': 0.005895474}\n",
      "I0623 10:44:02.678348 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.49180418,\n",
      " 'Loss/localization_loss': 0.0004273167,\n",
      " 'Loss/regularization_loss': 0.03488411,\n",
      " 'Loss/total_loss': 0.5271156,\n",
      " 'learning_rate': 0.005895474}\n",
      "INFO:tensorflow:Step 8600 per-step time 0.146s\n",
      "I0623 10:44:17.250932 139760059615040 model_lib_v2.py:700] Step 8600 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.34811696,\n",
      " 'Loss/localization_loss': 0.0004780732,\n",
      " 'Loss/regularization_loss': 0.034881037,\n",
      " 'Loss/total_loss': 0.38347608,\n",
      " 'learning_rate': 0.0058319387}\n",
      "I0623 10:44:17.251185 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.34811696,\n",
      " 'Loss/localization_loss': 0.0004780732,\n",
      " 'Loss/regularization_loss': 0.034881037,\n",
      " 'Loss/total_loss': 0.38347608,\n",
      " 'learning_rate': 0.0058319387}\n",
      "INFO:tensorflow:Step 8700 per-step time 0.147s\n",
      "I0623 10:44:31.987162 139760059615040 model_lib_v2.py:700] Step 8700 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3530652,\n",
      " 'Loss/localization_loss': 0.0006474181,\n",
      " 'Loss/regularization_loss': 0.034880005,\n",
      " 'Loss/total_loss': 0.3885926,\n",
      " 'learning_rate': 0.005767813}\n",
      "I0623 10:44:31.987521 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3530652,\n",
      " 'Loss/localization_loss': 0.0006474181,\n",
      " 'Loss/regularization_loss': 0.034880005,\n",
      " 'Loss/total_loss': 0.3885926,\n",
      " 'learning_rate': 0.005767813}\n",
      "INFO:tensorflow:Step 8800 per-step time 0.146s\n",
      "I0623 10:44:46.623811 139760059615040 model_lib_v2.py:700] Step 8800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7438749,\n",
      " 'Loss/localization_loss': 0.009622433,\n",
      " 'Loss/regularization_loss': 0.034881815,\n",
      " 'Loss/total_loss': 0.7883792,\n",
      " 'learning_rate': 0.0057031163}\n",
      "I0623 10:44:46.624185 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7438749,\n",
      " 'Loss/localization_loss': 0.009622433,\n",
      " 'Loss/regularization_loss': 0.034881815,\n",
      " 'Loss/total_loss': 0.7883792,\n",
      " 'learning_rate': 0.0057031163}\n",
      "INFO:tensorflow:Step 8900 per-step time 0.147s\n",
      "I0623 10:45:01.303179 139760059615040 model_lib_v2.py:700] Step 8900 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42661208,\n",
      " 'Loss/localization_loss': 0.00035760077,\n",
      " 'Loss/regularization_loss': 0.034876794,\n",
      " 'Loss/total_loss': 0.46184647,\n",
      " 'learning_rate': 0.0056378725}\n",
      "I0623 10:45:01.303535 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42661208,\n",
      " 'Loss/localization_loss': 0.00035760077,\n",
      " 'Loss/regularization_loss': 0.034876794,\n",
      " 'Loss/total_loss': 0.46184647,\n",
      " 'learning_rate': 0.0056378725}\n",
      "INFO:tensorflow:Step 9000 per-step time 0.147s\n",
      "I0623 10:45:15.955017 139760059615040 model_lib_v2.py:700] Step 9000 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3553245,\n",
      " 'Loss/localization_loss': 0.00026178808,\n",
      " 'Loss/regularization_loss': 0.034872424,\n",
      " 'Loss/total_loss': 0.3904587,\n",
      " 'learning_rate': 0.0055720992}\n",
      "I0623 10:45:15.955366 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3553245,\n",
      " 'Loss/localization_loss': 0.00026178808,\n",
      " 'Loss/regularization_loss': 0.034872424,\n",
      " 'Loss/total_loss': 0.3904587,\n",
      " 'learning_rate': 0.0055720992}\n",
      "INFO:tensorflow:Step 9100 per-step time 0.154s\n",
      "I0623 10:45:31.328705 139760059615040 model_lib_v2.py:700] Step 9100 per-step time 0.154s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.398414,\n",
      " 'Loss/localization_loss': 0.0005500122,\n",
      " 'Loss/regularization_loss': 0.034869634,\n",
      " 'Loss/total_loss': 0.43383366,\n",
      " 'learning_rate': 0.0055058207}\n",
      "I0623 10:45:31.329019 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.398414,\n",
      " 'Loss/localization_loss': 0.0005500122,\n",
      " 'Loss/regularization_loss': 0.034869634,\n",
      " 'Loss/total_loss': 0.43383366,\n",
      " 'learning_rate': 0.0055058207}\n",
      "INFO:tensorflow:Step 9200 per-step time 0.146s\n",
      "I0623 10:45:45.904275 139760059615040 model_lib_v2.py:700] Step 9200 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5145107,\n",
      " 'Loss/localization_loss': 0.00037658343,\n",
      " 'Loss/regularization_loss': 0.034869693,\n",
      " 'Loss/total_loss': 0.54975694,\n",
      " 'learning_rate': 0.0054390565}\n",
      "I0623 10:45:45.904627 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5145107,\n",
      " 'Loss/localization_loss': 0.00037658343,\n",
      " 'Loss/regularization_loss': 0.034869693,\n",
      " 'Loss/total_loss': 0.54975694,\n",
      " 'learning_rate': 0.0054390565}\n",
      "INFO:tensorflow:Step 9300 per-step time 0.148s\n",
      "I0623 10:46:00.742099 139760059615040 model_lib_v2.py:700] Step 9300 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.58061993,\n",
      " 'Loss/localization_loss': 0.00056258455,\n",
      " 'Loss/regularization_loss': 0.03486406,\n",
      " 'Loss/total_loss': 0.6160466,\n",
      " 'learning_rate': 0.005371828}\n",
      "I0623 10:46:00.742411 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.58061993,\n",
      " 'Loss/localization_loss': 0.00056258455,\n",
      " 'Loss/regularization_loss': 0.03486406,\n",
      " 'Loss/total_loss': 0.6160466,\n",
      " 'learning_rate': 0.005371828}\n",
      "INFO:tensorflow:Step 9400 per-step time 0.148s\n",
      "I0623 10:46:15.553596 139760059615040 model_lib_v2.py:700] Step 9400 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.54987454,\n",
      " 'Loss/localization_loss': 0.00025732076,\n",
      " 'Loss/regularization_loss': 0.03486084,\n",
      " 'Loss/total_loss': 0.58499265,\n",
      " 'learning_rate': 0.0053041577}\n",
      "I0623 10:46:15.553907 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.54987454,\n",
      " 'Loss/localization_loss': 0.00025732076,\n",
      " 'Loss/regularization_loss': 0.03486084,\n",
      " 'Loss/total_loss': 0.58499265,\n",
      " 'learning_rate': 0.0053041577}\n",
      "INFO:tensorflow:Step 9500 per-step time 0.147s\n",
      "I0623 10:46:30.222312 139760059615040 model_lib_v2.py:700] Step 9500 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35760498,\n",
      " 'Loss/localization_loss': 0.00011872151,\n",
      " 'Loss/regularization_loss': 0.03485532,\n",
      " 'Loss/total_loss': 0.39257905,\n",
      " 'learning_rate': 0.0052360673}\n",
      "I0623 10:46:30.222658 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35760498,\n",
      " 'Loss/localization_loss': 0.00011872151,\n",
      " 'Loss/regularization_loss': 0.03485532,\n",
      " 'Loss/total_loss': 0.39257905,\n",
      " 'learning_rate': 0.0052360673}\n",
      "INFO:tensorflow:Step 9600 per-step time 0.146s\n",
      "I0623 10:46:44.863001 139760059615040 model_lib_v2.py:700] Step 9600 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.8459615,\n",
      " 'Loss/localization_loss': 0.0003285945,\n",
      " 'Loss/regularization_loss': 0.03485888,\n",
      " 'Loss/total_loss': 0.88114893,\n",
      " 'learning_rate': 0.005167579}\n",
      "I0623 10:46:44.863338 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.8459615,\n",
      " 'Loss/localization_loss': 0.0003285945,\n",
      " 'Loss/regularization_loss': 0.03485888,\n",
      " 'Loss/total_loss': 0.88114893,\n",
      " 'learning_rate': 0.005167579}\n",
      "INFO:tensorflow:Step 9700 per-step time 0.146s\n",
      "I0623 10:46:59.480321 139760059615040 model_lib_v2.py:700] Step 9700 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3364103,\n",
      " 'Loss/localization_loss': 0.00035560623,\n",
      " 'Loss/regularization_loss': 0.03485681,\n",
      " 'Loss/total_loss': 0.3716227,\n",
      " 'learning_rate': 0.005098714}\n",
      "I0623 10:46:59.480680 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3364103,\n",
      " 'Loss/localization_loss': 0.00035560623,\n",
      " 'Loss/regularization_loss': 0.03485681,\n",
      " 'Loss/total_loss': 0.3716227,\n",
      " 'learning_rate': 0.005098714}\n",
      "INFO:tensorflow:Step 9800 per-step time 0.146s\n",
      "I0623 10:47:14.120139 139760059615040 model_lib_v2.py:700] Step 9800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5234047,\n",
      " 'Loss/localization_loss': 0.0003334164,\n",
      " 'Loss/regularization_loss': 0.03485388,\n",
      " 'Loss/total_loss': 0.558592,\n",
      " 'learning_rate': 0.0050294944}\n",
      "I0623 10:47:14.120378 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5234047,\n",
      " 'Loss/localization_loss': 0.0003334164,\n",
      " 'Loss/regularization_loss': 0.03485388,\n",
      " 'Loss/total_loss': 0.558592,\n",
      " 'learning_rate': 0.0050294944}\n",
      "INFO:tensorflow:Step 9900 per-step time 0.146s\n",
      "I0623 10:47:28.754719 139760059615040 model_lib_v2.py:700] Step 9900 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.51617,\n",
      " 'Loss/localization_loss': 0.000881916,\n",
      " 'Loss/regularization_loss': 0.034851227,\n",
      " 'Loss/total_loss': 0.5519032,\n",
      " 'learning_rate': 0.0049599432}\n",
      "I0623 10:47:28.755069 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.51617,\n",
      " 'Loss/localization_loss': 0.000881916,\n",
      " 'Loss/regularization_loss': 0.034851227,\n",
      " 'Loss/total_loss': 0.5519032,\n",
      " 'learning_rate': 0.0049599432}\n",
      "INFO:tensorflow:Step 10000 per-step time 0.145s\n",
      "I0623 10:47:43.293303 139760059615040 model_lib_v2.py:700] Step 10000 per-step time 0.145s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6948314,\n",
      " 'Loss/localization_loss': 0.00014880081,\n",
      " 'Loss/regularization_loss': 0.034846935,\n",
      " 'Loss/total_loss': 0.7298271,\n",
      " 'learning_rate': 0.004890083}\n",
      "I0623 10:47:43.293612 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6948314,\n",
      " 'Loss/localization_loss': 0.00014880081,\n",
      " 'Loss/regularization_loss': 0.034846935,\n",
      " 'Loss/total_loss': 0.7298271,\n",
      " 'learning_rate': 0.004890083}\n",
      "INFO:tensorflow:Step 10100 per-step time 0.154s\n",
      "I0623 10:47:58.661693 139760059615040 model_lib_v2.py:700] Step 10100 per-step time 0.154s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3429416,\n",
      " 'Loss/localization_loss': 0.00032785005,\n",
      " 'Loss/regularization_loss': 0.03484273,\n",
      " 'Loss/total_loss': 0.3781122,\n",
      " 'learning_rate': 0.004819936}\n",
      "I0623 10:47:58.662030 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3429416,\n",
      " 'Loss/localization_loss': 0.00032785005,\n",
      " 'Loss/regularization_loss': 0.03484273,\n",
      " 'Loss/total_loss': 0.3781122,\n",
      " 'learning_rate': 0.004819936}\n",
      "INFO:tensorflow:Step 10200 per-step time 0.146s\n",
      "I0623 10:48:13.250335 139760059615040 model_lib_v2.py:700] Step 10200 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6903473,\n",
      " 'Loss/localization_loss': 0.00032883795,\n",
      " 'Loss/regularization_loss': 0.03484322,\n",
      " 'Loss/total_loss': 0.72551936,\n",
      " 'learning_rate': 0.0047495253}\n",
      "I0623 10:48:13.250745 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6903473,\n",
      " 'Loss/localization_loss': 0.00032883795,\n",
      " 'Loss/regularization_loss': 0.03484322,\n",
      " 'Loss/total_loss': 0.72551936,\n",
      " 'learning_rate': 0.0047495253}\n",
      "INFO:tensorflow:Step 10300 per-step time 0.146s\n",
      "I0623 10:48:27.873729 139760059615040 model_lib_v2.py:700] Step 10300 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38934237,\n",
      " 'Loss/localization_loss': 0.00036839675,\n",
      " 'Loss/regularization_loss': 0.0348472,\n",
      " 'Loss/total_loss': 0.42455795,\n",
      " 'learning_rate': 0.004678872}\n",
      "I0623 10:48:27.874078 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.38934237,\n",
      " 'Loss/localization_loss': 0.00036839675,\n",
      " 'Loss/regularization_loss': 0.0348472,\n",
      " 'Loss/total_loss': 0.42455795,\n",
      " 'learning_rate': 0.004678872}\n",
      "INFO:tensorflow:Step 10400 per-step time 0.147s\n",
      "I0623 10:48:42.563757 139760059615040 model_lib_v2.py:700] Step 10400 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5235931,\n",
      " 'Loss/localization_loss': 0.00046400417,\n",
      " 'Loss/regularization_loss': 0.034851942,\n",
      " 'Loss/total_loss': 0.55890906,\n",
      " 'learning_rate': 0.0046080006}\n",
      "I0623 10:48:42.564221 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5235931,\n",
      " 'Loss/localization_loss': 0.00046400417,\n",
      " 'Loss/regularization_loss': 0.034851942,\n",
      " 'Loss/total_loss': 0.55890906,\n",
      " 'learning_rate': 0.0046080006}\n",
      "INFO:tensorflow:Step 10500 per-step time 0.147s\n",
      "I0623 10:48:57.273689 139760059615040 model_lib_v2.py:700] Step 10500 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35006303,\n",
      " 'Loss/localization_loss': 0.00010359478,\n",
      " 'Loss/regularization_loss': 0.034847338,\n",
      " 'Loss/total_loss': 0.385014,\n",
      " 'learning_rate': 0.0045369323}\n",
      "I0623 10:48:57.274044 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35006303,\n",
      " 'Loss/localization_loss': 0.00010359478,\n",
      " 'Loss/regularization_loss': 0.034847338,\n",
      " 'Loss/total_loss': 0.385014,\n",
      " 'learning_rate': 0.0045369323}\n",
      "INFO:tensorflow:Step 10600 per-step time 0.147s\n",
      "I0623 10:49:11.952145 139760059615040 model_lib_v2.py:700] Step 10600 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3002333,\n",
      " 'Loss/localization_loss': 9.714677e-05,\n",
      " 'Loss/regularization_loss': 0.034844503,\n",
      " 'Loss/total_loss': 0.33517495,\n",
      " 'learning_rate': 0.004465692}\n",
      "I0623 10:49:11.952538 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3002333,\n",
      " 'Loss/localization_loss': 9.714677e-05,\n",
      " 'Loss/regularization_loss': 0.034844503,\n",
      " 'Loss/total_loss': 0.33517495,\n",
      " 'learning_rate': 0.004465692}\n",
      "INFO:tensorflow:Step 10700 per-step time 0.147s\n",
      "I0623 10:49:26.621504 139760059615040 model_lib_v2.py:700] Step 10700 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.54183733,\n",
      " 'Loss/localization_loss': 0.0003380559,\n",
      " 'Loss/regularization_loss': 0.03484274,\n",
      " 'Loss/total_loss': 0.57701814,\n",
      " 'learning_rate': 0.0043943017}\n",
      "I0623 10:49:26.621811 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.54183733,\n",
      " 'Loss/localization_loss': 0.0003380559,\n",
      " 'Loss/regularization_loss': 0.03484274,\n",
      " 'Loss/total_loss': 0.57701814,\n",
      " 'learning_rate': 0.0043943017}\n",
      "INFO:tensorflow:Step 10800 per-step time 0.146s\n",
      "I0623 10:49:41.189546 139760059615040 model_lib_v2.py:700] Step 10800 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36182654,\n",
      " 'Loss/localization_loss': 6.659946e-05,\n",
      " 'Loss/regularization_loss': 0.034840778,\n",
      " 'Loss/total_loss': 0.3967339,\n",
      " 'learning_rate': 0.004322783}\n",
      "I0623 10:49:41.189819 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.36182654,\n",
      " 'Loss/localization_loss': 6.659946e-05,\n",
      " 'Loss/regularization_loss': 0.034840778,\n",
      " 'Loss/total_loss': 0.3967339,\n",
      " 'learning_rate': 0.004322783}\n",
      "INFO:tensorflow:Step 10900 per-step time 0.146s\n",
      "I0623 10:49:55.801483 139760059615040 model_lib_v2.py:700] Step 10900 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5451959,\n",
      " 'Loss/localization_loss': 0.00029174186,\n",
      " 'Loss/regularization_loss': 0.03483812,\n",
      " 'Loss/total_loss': 0.5803257,\n",
      " 'learning_rate': 0.0042511616}\n",
      "I0623 10:49:55.801836 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5451959,\n",
      " 'Loss/localization_loss': 0.00029174186,\n",
      " 'Loss/regularization_loss': 0.03483812,\n",
      " 'Loss/total_loss': 0.5803257,\n",
      " 'learning_rate': 0.0042511616}\n",
      "INFO:tensorflow:Step 11000 per-step time 0.147s\n",
      "I0623 10:50:10.464222 139760059615040 model_lib_v2.py:700] Step 11000 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.37968802,\n",
      " 'Loss/localization_loss': 0.00028981434,\n",
      " 'Loss/regularization_loss': 0.034832936,\n",
      " 'Loss/total_loss': 0.41481075,\n",
      " 'learning_rate': 0.004179458}\n",
      "I0623 10:50:10.464633 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.37968802,\n",
      " 'Loss/localization_loss': 0.00028981434,\n",
      " 'Loss/regularization_loss': 0.034832936,\n",
      " 'Loss/total_loss': 0.41481075,\n",
      " 'learning_rate': 0.004179458}\n",
      "INFO:tensorflow:Step 11100 per-step time 0.155s\n",
      "I0623 10:50:25.970339 139760059615040 model_lib_v2.py:700] Step 11100 per-step time 0.155s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.37498444,\n",
      " 'Loss/localization_loss': 0.0010316616,\n",
      " 'Loss/regularization_loss': 0.03482993,\n",
      " 'Loss/total_loss': 0.41084605,\n",
      " 'learning_rate': 0.0041076983}\n",
      "I0623 10:50:25.970628 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.37498444,\n",
      " 'Loss/localization_loss': 0.0010316616,\n",
      " 'Loss/regularization_loss': 0.03482993,\n",
      " 'Loss/total_loss': 0.41084605,\n",
      " 'learning_rate': 0.0041076983}\n",
      "INFO:tensorflow:Step 11200 per-step time 0.147s\n",
      "I0623 10:50:40.634767 139760059615040 model_lib_v2.py:700] Step 11200 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 1.6149902,\n",
      " 'Loss/localization_loss': 6.020962e-05,\n",
      " 'Loss/regularization_loss': 0.034826703,\n",
      " 'Loss/total_loss': 1.6498772,\n",
      " 'learning_rate': 0.004035903}\n",
      "I0623 10:50:40.635134 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 1.6149902,\n",
      " 'Loss/localization_loss': 6.020962e-05,\n",
      " 'Loss/regularization_loss': 0.034826703,\n",
      " 'Loss/total_loss': 1.6498772,\n",
      " 'learning_rate': 0.004035903}\n",
      "INFO:tensorflow:Step 11300 per-step time 0.146s\n",
      "I0623 10:50:55.197719 139760059615040 model_lib_v2.py:700] Step 11300 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39497638,\n",
      " 'Loss/localization_loss': 0.0003136032,\n",
      " 'Loss/regularization_loss': 0.034823723,\n",
      " 'Loss/total_loss': 0.43011367,\n",
      " 'learning_rate': 0.003964096}\n",
      "I0623 10:50:55.197991 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39497638,\n",
      " 'Loss/localization_loss': 0.0003136032,\n",
      " 'Loss/regularization_loss': 0.034823723,\n",
      " 'Loss/total_loss': 0.43011367,\n",
      " 'learning_rate': 0.003964096}\n",
      "INFO:tensorflow:Step 11400 per-step time 0.147s\n",
      "I0623 10:51:09.880286 139760059615040 model_lib_v2.py:700] Step 11400 per-step time 0.147s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5031138,\n",
      " 'Loss/localization_loss': 0.00021463443,\n",
      " 'Loss/regularization_loss': 0.034824263,\n",
      " 'Loss/total_loss': 0.5381527,\n",
      " 'learning_rate': 0.0038923009}\n",
      "I0623 10:51:09.880633 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5031138,\n",
      " 'Loss/localization_loss': 0.00021463443,\n",
      " 'Loss/regularization_loss': 0.034824263,\n",
      " 'Loss/total_loss': 0.5381527,\n",
      " 'learning_rate': 0.0038923009}\n",
      "INFO:tensorflow:Step 11500 per-step time 0.148s\n",
      "I0623 10:51:24.651265 139760059615040 model_lib_v2.py:700] Step 11500 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35069087,\n",
      " 'Loss/localization_loss': 0.00027205952,\n",
      " 'Loss/regularization_loss': 0.034820296,\n",
      " 'Loss/total_loss': 0.38578323,\n",
      " 'learning_rate': 0.0038205402}\n",
      "I0623 10:51:24.651546 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35069087,\n",
      " 'Loss/localization_loss': 0.00027205952,\n",
      " 'Loss/regularization_loss': 0.034820296,\n",
      " 'Loss/total_loss': 0.38578323,\n",
      " 'learning_rate': 0.0038205402}\n",
      "INFO:tensorflow:Step 11600 per-step time 0.146s\n",
      "I0623 10:51:39.246532 139760059615040 model_lib_v2.py:700] Step 11600 per-step time 0.146s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.49113852,\n",
      " 'Loss/localization_loss': 0.00073052885,\n",
      " 'Loss/regularization_loss': 0.034820337,\n",
      " 'Loss/total_loss': 0.5266894,\n",
      " 'learning_rate': 0.0037488374}\n",
      "I0623 10:51:39.246880 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.49113852,\n",
      " 'Loss/localization_loss': 0.00073052885,\n",
      " 'Loss/regularization_loss': 0.034820337,\n",
      " 'Loss/total_loss': 0.5266894,\n",
      " 'learning_rate': 0.0037488374}\n",
      "INFO:tensorflow:Step 11700 per-step time 0.143s\n",
      "I0623 10:51:53.522335 139760059615040 model_lib_v2.py:700] Step 11700 per-step time 0.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5412279,\n",
      " 'Loss/localization_loss': 0.0008764969,\n",
      " 'Loss/regularization_loss': 0.03481747,\n",
      " 'Loss/total_loss': 0.5769218,\n",
      " 'learning_rate': 0.0036772161}\n",
      "I0623 10:51:53.522514 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5412279,\n",
      " 'Loss/localization_loss': 0.0008764969,\n",
      " 'Loss/regularization_loss': 0.03481747,\n",
      " 'Loss/total_loss': 0.5769218,\n",
      " 'learning_rate': 0.0036772161}\n",
      "INFO:tensorflow:Step 11800 per-step time 0.141s\n",
      "I0623 10:52:07.653594 139760059615040 model_lib_v2.py:700] Step 11800 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.6028881,\n",
      " 'Loss/localization_loss': 0.00048212166,\n",
      " 'Loss/regularization_loss': 0.03481587,\n",
      " 'Loss/total_loss': 0.63818604,\n",
      " 'learning_rate': 0.0036056975}\n",
      "I0623 10:52:07.653771 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.6028881,\n",
      " 'Loss/localization_loss': 0.00048212166,\n",
      " 'Loss/regularization_loss': 0.03481587,\n",
      " 'Loss/total_loss': 0.63818604,\n",
      " 'learning_rate': 0.0036056975}\n",
      "INFO:tensorflow:Step 11900 per-step time 0.142s\n",
      "I0623 10:52:21.877297 139760059615040 model_lib_v2.py:700] Step 11900 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3195297,\n",
      " 'Loss/localization_loss': 0.00021708952,\n",
      " 'Loss/regularization_loss': 0.034813166,\n",
      " 'Loss/total_loss': 0.35455996,\n",
      " 'learning_rate': 0.003534307}\n",
      "I0623 10:52:21.877477 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3195297,\n",
      " 'Loss/localization_loss': 0.00021708952,\n",
      " 'Loss/regularization_loss': 0.034813166,\n",
      " 'Loss/total_loss': 0.35455996,\n",
      " 'learning_rate': 0.003534307}\n",
      "INFO:tensorflow:Step 12000 per-step time 0.141s\n",
      "I0623 10:52:36.005155 139760059615040 model_lib_v2.py:700] Step 12000 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27422068,\n",
      " 'Loss/localization_loss': 0.00016322105,\n",
      " 'Loss/regularization_loss': 0.03481134,\n",
      " 'Loss/total_loss': 0.30919522,\n",
      " 'learning_rate': 0.0034630669}\n",
      "I0623 10:52:36.005331 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.27422068,\n",
      " 'Loss/localization_loss': 0.00016322105,\n",
      " 'Loss/regularization_loss': 0.03481134,\n",
      " 'Loss/total_loss': 0.30919522,\n",
      " 'learning_rate': 0.0034630669}\n",
      "INFO:tensorflow:Step 12100 per-step time 0.148s\n",
      "I0623 10:52:50.841150 139760059615040 model_lib_v2.py:700] Step 12100 per-step time 0.148s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33038583,\n",
      " 'Loss/localization_loss': 0.00023177879,\n",
      " 'Loss/regularization_loss': 0.03481039,\n",
      " 'Loss/total_loss': 0.365428,\n",
      " 'learning_rate': 0.0033919986}\n",
      "I0623 10:52:50.841336 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.33038583,\n",
      " 'Loss/localization_loss': 0.00023177879,\n",
      " 'Loss/regularization_loss': 0.03481039,\n",
      " 'Loss/total_loss': 0.365428,\n",
      " 'learning_rate': 0.0033919986}\n",
      "INFO:tensorflow:Step 12200 per-step time 0.141s\n",
      "I0623 10:53:04.905691 139760059615040 model_lib_v2.py:700] Step 12200 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.43412006,\n",
      " 'Loss/localization_loss': 0.00046192913,\n",
      " 'Loss/regularization_loss': 0.034808263,\n",
      " 'Loss/total_loss': 0.46939027,\n",
      " 'learning_rate': 0.0033211275}\n",
      "I0623 10:53:04.905873 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.43412006,\n",
      " 'Loss/localization_loss': 0.00046192913,\n",
      " 'Loss/regularization_loss': 0.034808263,\n",
      " 'Loss/total_loss': 0.46939027,\n",
      " 'learning_rate': 0.0033211275}\n",
      "INFO:tensorflow:Step 12300 per-step time 0.141s\n",
      "I0623 10:53:19.055569 139760059615040 model_lib_v2.py:700] Step 12300 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3243704,\n",
      " 'Loss/localization_loss': 0.00047297502,\n",
      " 'Loss/regularization_loss': 0.034805454,\n",
      " 'Loss/total_loss': 0.35964882,\n",
      " 'learning_rate': 0.0032504739}\n",
      "I0623 10:53:19.055743 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3243704,\n",
      " 'Loss/localization_loss': 0.00047297502,\n",
      " 'Loss/regularization_loss': 0.034805454,\n",
      " 'Loss/total_loss': 0.35964882,\n",
      " 'learning_rate': 0.0032504739}\n",
      "INFO:tensorflow:Step 12400 per-step time 0.142s\n",
      "I0623 10:53:33.302484 139760059615040 model_lib_v2.py:700] Step 12400 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.48768285,\n",
      " 'Loss/localization_loss': 0.00028465048,\n",
      " 'Loss/regularization_loss': 0.034803696,\n",
      " 'Loss/total_loss': 0.5227712,\n",
      " 'learning_rate': 0.003180063}\n",
      "I0623 10:53:33.302664 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.48768285,\n",
      " 'Loss/localization_loss': 0.00028465048,\n",
      " 'Loss/regularization_loss': 0.034803696,\n",
      " 'Loss/total_loss': 0.5227712,\n",
      " 'learning_rate': 0.003180063}\n",
      "INFO:tensorflow:Step 12500 per-step time 0.143s\n",
      "I0623 10:53:47.623914 139760059615040 model_lib_v2.py:700] Step 12500 per-step time 0.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7623789,\n",
      " 'Loss/localization_loss': 5.4241515e-05,\n",
      " 'Loss/regularization_loss': 0.03480193,\n",
      " 'Loss/total_loss': 0.7972351,\n",
      " 'learning_rate': 0.0031099159}\n",
      "I0623 10:53:47.624098 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7623789,\n",
      " 'Loss/localization_loss': 5.4241515e-05,\n",
      " 'Loss/regularization_loss': 0.03480193,\n",
      " 'Loss/total_loss': 0.7972351,\n",
      " 'learning_rate': 0.0031099159}\n",
      "INFO:tensorflow:Step 12600 per-step time 0.143s\n",
      "I0623 10:54:01.942867 139760059615040 model_lib_v2.py:700] Step 12600 per-step time 0.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42713767,\n",
      " 'Loss/localization_loss': 0.0005152496,\n",
      " 'Loss/regularization_loss': 0.03479989,\n",
      " 'Loss/total_loss': 0.4624528,\n",
      " 'learning_rate': 0.0030400555}\n",
      "I0623 10:54:01.943045 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42713767,\n",
      " 'Loss/localization_loss': 0.0005152496,\n",
      " 'Loss/regularization_loss': 0.03479989,\n",
      " 'Loss/total_loss': 0.4624528,\n",
      " 'learning_rate': 0.0030400555}\n",
      "INFO:tensorflow:Step 12700 per-step time 0.141s\n",
      "I0623 10:54:16.092277 139760059615040 model_lib_v2.py:700] Step 12700 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.7222102,\n",
      " 'Loss/localization_loss': 0.0006025159,\n",
      " 'Loss/regularization_loss': 0.03479689,\n",
      " 'Loss/total_loss': 0.7576096,\n",
      " 'learning_rate': 0.0029705048}\n",
      "I0623 10:54:16.092455 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.7222102,\n",
      " 'Loss/localization_loss': 0.0006025159,\n",
      " 'Loss/regularization_loss': 0.03479689,\n",
      " 'Loss/total_loss': 0.7576096,\n",
      " 'learning_rate': 0.0029705048}\n",
      "INFO:tensorflow:Step 12800 per-step time 0.143s\n",
      "I0623 10:54:30.347554 139760059615040 model_lib_v2.py:700] Step 12800 per-step time 0.143s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3695272,\n",
      " 'Loss/localization_loss': 0.00028675998,\n",
      " 'Loss/regularization_loss': 0.034795515,\n",
      " 'Loss/total_loss': 0.40460947,\n",
      " 'learning_rate': 0.0029012854}\n",
      "I0623 10:54:30.347734 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3695272,\n",
      " 'Loss/localization_loss': 0.00028675998,\n",
      " 'Loss/regularization_loss': 0.034795515,\n",
      " 'Loss/total_loss': 0.40460947,\n",
      " 'learning_rate': 0.0029012854}\n",
      "INFO:tensorflow:Step 12900 per-step time 0.141s\n",
      "I0623 10:54:44.472885 139760059615040 model_lib_v2.py:700] Step 12900 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23088525,\n",
      " 'Loss/localization_loss': 0.00039604437,\n",
      " 'Loss/regularization_loss': 0.034793325,\n",
      " 'Loss/total_loss': 0.2660746,\n",
      " 'learning_rate': 0.0028324206}\n",
      "I0623 10:54:44.473064 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.23088525,\n",
      " 'Loss/localization_loss': 0.00039604437,\n",
      " 'Loss/regularization_loss': 0.034793325,\n",
      " 'Loss/total_loss': 0.2660746,\n",
      " 'learning_rate': 0.0028324206}\n",
      "INFO:tensorflow:Step 13000 per-step time 0.141s\n",
      "I0623 10:54:58.593913 139760059615040 model_lib_v2.py:700] Step 13000 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5190234,\n",
      " 'Loss/localization_loss': 0.00022704163,\n",
      " 'Loss/regularization_loss': 0.03479426,\n",
      " 'Loss/total_loss': 0.5540447,\n",
      " 'learning_rate': 0.002763932}\n",
      "I0623 10:54:58.594097 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5190234,\n",
      " 'Loss/localization_loss': 0.00022704163,\n",
      " 'Loss/regularization_loss': 0.03479426,\n",
      " 'Loss/total_loss': 0.5540447,\n",
      " 'learning_rate': 0.002763932}\n",
      "INFO:tensorflow:Step 13100 per-step time 0.149s\n",
      "I0623 10:55:13.484895 139760059615040 model_lib_v2.py:700] Step 13100 per-step time 0.149s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39013374,\n",
      " 'Loss/localization_loss': 0.00025915654,\n",
      " 'Loss/regularization_loss': 0.03479185,\n",
      " 'Loss/total_loss': 0.42518473,\n",
      " 'learning_rate': 0.002695841}\n",
      "I0623 10:55:13.485079 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39013374,\n",
      " 'Loss/localization_loss': 0.00025915654,\n",
      " 'Loss/regularization_loss': 0.03479185,\n",
      " 'Loss/total_loss': 0.42518473,\n",
      " 'learning_rate': 0.002695841}\n",
      "INFO:tensorflow:Step 13200 per-step time 0.141s\n",
      "I0623 10:55:27.581319 139760059615040 model_lib_v2.py:700] Step 13200 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33554077,\n",
      " 'Loss/localization_loss': 0.00047221896,\n",
      " 'Loss/regularization_loss': 0.034789756,\n",
      " 'Loss/total_loss': 0.37080273,\n",
      " 'learning_rate': 0.0026281711}\n",
      "I0623 10:55:27.581497 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.33554077,\n",
      " 'Loss/localization_loss': 0.00047221896,\n",
      " 'Loss/regularization_loss': 0.034789756,\n",
      " 'Loss/total_loss': 0.37080273,\n",
      " 'learning_rate': 0.0026281711}\n",
      "INFO:tensorflow:Step 13300 per-step time 0.140s\n",
      "I0623 10:55:41.613114 139760059615040 model_lib_v2.py:700] Step 13300 per-step time 0.140s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.43628788,\n",
      " 'Loss/localization_loss': 0.00048203766,\n",
      " 'Loss/regularization_loss': 0.034788065,\n",
      " 'Loss/total_loss': 0.47155797,\n",
      " 'learning_rate': 0.0025609424}\n",
      "I0623 10:55:41.613290 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.43628788,\n",
      " 'Loss/localization_loss': 0.00048203766,\n",
      " 'Loss/regularization_loss': 0.034788065,\n",
      " 'Loss/total_loss': 0.47155797,\n",
      " 'learning_rate': 0.0025609424}\n",
      "INFO:tensorflow:Step 13400 per-step time 0.142s\n",
      "I0623 10:55:55.803468 139760059615040 model_lib_v2.py:700] Step 13400 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2561229,\n",
      " 'Loss/localization_loss': 0.00033083395,\n",
      " 'Loss/regularization_loss': 0.034785368,\n",
      " 'Loss/total_loss': 0.29123908,\n",
      " 'learning_rate': 0.0024941792}\n",
      "I0623 10:55:55.803650 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.2561229,\n",
      " 'Loss/localization_loss': 0.00033083395,\n",
      " 'Loss/regularization_loss': 0.034785368,\n",
      " 'Loss/total_loss': 0.29123908,\n",
      " 'learning_rate': 0.0024941792}\n",
      "INFO:tensorflow:Step 13500 per-step time 0.141s\n",
      "I0623 10:56:09.878811 139760059615040 model_lib_v2.py:700] Step 13500 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.44137523,\n",
      " 'Loss/localization_loss': 0.00025109737,\n",
      " 'Loss/regularization_loss': 0.034783915,\n",
      " 'Loss/total_loss': 0.4764102,\n",
      " 'learning_rate': 0.0024279}\n",
      "I0623 10:56:09.879046 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.44137523,\n",
      " 'Loss/localization_loss': 0.00025109737,\n",
      " 'Loss/regularization_loss': 0.034783915,\n",
      " 'Loss/total_loss': 0.4764102,\n",
      " 'learning_rate': 0.0024279}\n",
      "INFO:tensorflow:Step 13600 per-step time 0.141s\n",
      "I0623 10:56:23.979795 139760059615040 model_lib_v2.py:700] Step 13600 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.45325407,\n",
      " 'Loss/localization_loss': 0.0005073849,\n",
      " 'Loss/regularization_loss': 0.03478379,\n",
      " 'Loss/total_loss': 0.48854524,\n",
      " 'learning_rate': 0.0023621272}\n",
      "I0623 10:56:23.979982 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.45325407,\n",
      " 'Loss/localization_loss': 0.0005073849,\n",
      " 'Loss/regularization_loss': 0.03478379,\n",
      " 'Loss/total_loss': 0.48854524,\n",
      " 'learning_rate': 0.0023621272}\n",
      "INFO:tensorflow:Step 13700 per-step time 0.142s\n",
      "I0623 10:56:38.187296 139760059615040 model_lib_v2.py:700] Step 13700 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5372791,\n",
      " 'Loss/localization_loss': 0.00017715502,\n",
      " 'Loss/regularization_loss': 0.034783714,\n",
      " 'Loss/total_loss': 0.57224,\n",
      " 'learning_rate': 0.0022968824}\n",
      "I0623 10:56:38.187524 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5372791,\n",
      " 'Loss/localization_loss': 0.00017715502,\n",
      " 'Loss/regularization_loss': 0.034783714,\n",
      " 'Loss/total_loss': 0.57224,\n",
      " 'learning_rate': 0.0022968824}\n",
      "INFO:tensorflow:Step 13800 per-step time 0.142s\n",
      "I0623 10:56:52.430287 139760059615040 model_lib_v2.py:700] Step 13800 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42786682,\n",
      " 'Loss/localization_loss': 0.0002616823,\n",
      " 'Loss/regularization_loss': 0.034781814,\n",
      " 'Loss/total_loss': 0.4629103,\n",
      " 'learning_rate': 0.0022321877}\n",
      "I0623 10:56:52.430472 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42786682,\n",
      " 'Loss/localization_loss': 0.0002616823,\n",
      " 'Loss/regularization_loss': 0.034781814,\n",
      " 'Loss/total_loss': 0.4629103,\n",
      " 'learning_rate': 0.0022321877}\n",
      "INFO:tensorflow:Step 13900 per-step time 0.142s\n",
      "I0623 10:57:06.582273 139760059615040 model_lib_v2.py:700] Step 13900 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4483698,\n",
      " 'Loss/localization_loss': 0.00043926024,\n",
      " 'Loss/regularization_loss': 0.03477974,\n",
      " 'Loss/total_loss': 0.4835888,\n",
      " 'learning_rate': 0.0021680607}\n",
      "I0623 10:57:06.582461 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4483698,\n",
      " 'Loss/localization_loss': 0.00043926024,\n",
      " 'Loss/regularization_loss': 0.03477974,\n",
      " 'Loss/total_loss': 0.4835888,\n",
      " 'learning_rate': 0.0021680607}\n",
      "INFO:tensorflow:Step 14000 per-step time 0.157s\n",
      "I0623 10:57:22.300833 139760059615040 model_lib_v2.py:700] Step 14000 per-step time 0.157s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32193816,\n",
      " 'Loss/localization_loss': 7.477131e-05,\n",
      " 'Loss/regularization_loss': 0.034780614,\n",
      " 'Loss/total_loss': 0.35679352,\n",
      " 'learning_rate': 0.002104525}\n",
      "I0623 10:57:22.301466 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.32193816,\n",
      " 'Loss/localization_loss': 7.477131e-05,\n",
      " 'Loss/regularization_loss': 0.034780614,\n",
      " 'Loss/total_loss': 0.35679352,\n",
      " 'learning_rate': 0.002104525}\n",
      "INFO:tensorflow:Step 14100 per-step time 0.201s\n",
      "I0623 10:57:42.436170 139760059615040 model_lib_v2.py:700] Step 14100 per-step time 0.201s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5226451,\n",
      " 'Loss/localization_loss': 0.00027723055,\n",
      " 'Loss/regularization_loss': 0.034778643,\n",
      " 'Loss/total_loss': 0.55770105,\n",
      " 'learning_rate': 0.0020416}\n",
      "I0623 10:57:42.436982 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5226451,\n",
      " 'Loss/localization_loss': 0.00027723055,\n",
      " 'Loss/regularization_loss': 0.034778643,\n",
      " 'Loss/total_loss': 0.55770105,\n",
      " 'learning_rate': 0.0020416}\n",
      "INFO:tensorflow:Step 14200 per-step time 0.189s\n",
      "I0623 10:58:01.289282 139760059615040 model_lib_v2.py:700] Step 14200 per-step time 0.189s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.45729458,\n",
      " 'Loss/localization_loss': 0.00032553996,\n",
      " 'Loss/regularization_loss': 0.03478024,\n",
      " 'Loss/total_loss': 0.4924004,\n",
      " 'learning_rate': 0.001979306}\n",
      "I0623 10:58:01.289562 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.45729458,\n",
      " 'Loss/localization_loss': 0.00032553996,\n",
      " 'Loss/regularization_loss': 0.03478024,\n",
      " 'Loss/total_loss': 0.4924004,\n",
      " 'learning_rate': 0.001979306}\n",
      "INFO:tensorflow:Step 14300 per-step time 0.189s\n",
      "I0623 10:58:20.162208 139760059615040 model_lib_v2.py:700] Step 14300 per-step time 0.189s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2735225,\n",
      " 'Loss/localization_loss': 0.00046414486,\n",
      " 'Loss/regularization_loss': 0.034777552,\n",
      " 'Loss/total_loss': 0.30876416,\n",
      " 'learning_rate': 0.0019176644}\n",
      "I0623 10:58:20.162591 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.2735225,\n",
      " 'Loss/localization_loss': 0.00046414486,\n",
      " 'Loss/regularization_loss': 0.034777552,\n",
      " 'Loss/total_loss': 0.30876416,\n",
      " 'learning_rate': 0.0019176644}\n",
      "INFO:tensorflow:Step 14400 per-step time 0.189s\n",
      "I0623 10:58:39.041329 139760059615040 model_lib_v2.py:700] Step 14400 per-step time 0.189s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41979834,\n",
      " 'Loss/localization_loss': 0.0002767361,\n",
      " 'Loss/regularization_loss': 0.034776334,\n",
      " 'Loss/total_loss': 0.45485142,\n",
      " 'learning_rate': 0.001856693}\n",
      "I0623 10:58:39.041624 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.41979834,\n",
      " 'Loss/localization_loss': 0.0002767361,\n",
      " 'Loss/regularization_loss': 0.034776334,\n",
      " 'Loss/total_loss': 0.45485142,\n",
      " 'learning_rate': 0.001856693}\n",
      "INFO:tensorflow:Step 14500 per-step time 0.188s\n",
      "I0623 10:58:57.819637 139760059615040 model_lib_v2.py:700] Step 14500 per-step time 0.188s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3975766,\n",
      " 'Loss/localization_loss': 0.00029934986,\n",
      " 'Loss/regularization_loss': 0.03477499,\n",
      " 'Loss/total_loss': 0.43265092,\n",
      " 'learning_rate': 0.0017964114}\n",
      "I0623 10:58:57.819841 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3975766,\n",
      " 'Loss/localization_loss': 0.00029934986,\n",
      " 'Loss/regularization_loss': 0.03477499,\n",
      " 'Loss/total_loss': 0.43265092,\n",
      " 'learning_rate': 0.0017964114}\n",
      "INFO:tensorflow:Step 14600 per-step time 0.191s\n",
      "I0623 10:59:16.898354 139760059615040 model_lib_v2.py:700] Step 14600 per-step time 0.191s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.34246016,\n",
      " 'Loss/localization_loss': 0.0006154941,\n",
      " 'Loss/regularization_loss': 0.0347728,\n",
      " 'Loss/total_loss': 0.37784842,\n",
      " 'learning_rate': 0.0017368406}\n",
      "I0623 10:59:16.898667 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.34246016,\n",
      " 'Loss/localization_loss': 0.0006154941,\n",
      " 'Loss/regularization_loss': 0.0347728,\n",
      " 'Loss/total_loss': 0.37784842,\n",
      " 'learning_rate': 0.0017368406}\n",
      "INFO:tensorflow:Step 14700 per-step time 0.191s\n",
      "I0623 10:59:36.047776 139760059615040 model_lib_v2.py:700] Step 14700 per-step time 0.191s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.261125,\n",
      " 'Loss/localization_loss': 0.00041881728,\n",
      " 'Loss/regularization_loss': 0.03477245,\n",
      " 'Loss/total_loss': 0.29631627,\n",
      " 'learning_rate': 0.0016780001}\n",
      "I0623 10:59:36.048022 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.261125,\n",
      " 'Loss/localization_loss': 0.00041881728,\n",
      " 'Loss/regularization_loss': 0.03477245,\n",
      " 'Loss/total_loss': 0.29631627,\n",
      " 'learning_rate': 0.0016780001}\n",
      "INFO:tensorflow:Step 14800 per-step time 0.190s\n",
      "I0623 10:59:55.054898 139760059615040 model_lib_v2.py:700] Step 14800 per-step time 0.190s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35749912,\n",
      " 'Loss/localization_loss': 0.000365878,\n",
      " 'Loss/regularization_loss': 0.034773596,\n",
      " 'Loss/total_loss': 0.3926386,\n",
      " 'learning_rate': 0.0016199072}\n",
      "I0623 10:59:55.055161 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35749912,\n",
      " 'Loss/localization_loss': 0.000365878,\n",
      " 'Loss/regularization_loss': 0.034773596,\n",
      " 'Loss/total_loss': 0.3926386,\n",
      " 'learning_rate': 0.0016199072}\n",
      "INFO:tensorflow:Step 14900 per-step time 0.190s\n",
      "I0623 11:00:14.083550 139760059615040 model_lib_v2.py:700] Step 14900 per-step time 0.190s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3621707,\n",
      " 'Loss/localization_loss': 0.00034522422,\n",
      " 'Loss/regularization_loss': 0.03477121,\n",
      " 'Loss/total_loss': 0.3972871,\n",
      " 'learning_rate': 0.0015625812}\n",
      "I0623 11:00:14.083887 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3621707,\n",
      " 'Loss/localization_loss': 0.00034522422,\n",
      " 'Loss/regularization_loss': 0.03477121,\n",
      " 'Loss/total_loss': 0.3972871,\n",
      " 'learning_rate': 0.0015625812}\n",
      "INFO:tensorflow:Step 15000 per-step time 0.190s\n",
      "I0623 11:00:33.091923 139760059615040 model_lib_v2.py:700] Step 15000 per-step time 0.190s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35484383,\n",
      " 'Loss/localization_loss': 0.00034822588,\n",
      " 'Loss/regularization_loss': 0.034770932,\n",
      " 'Loss/total_loss': 0.38996297,\n",
      " 'learning_rate': 0.00150604}\n",
      "I0623 11:00:33.092208 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35484383,\n",
      " 'Loss/localization_loss': 0.00034822588,\n",
      " 'Loss/regularization_loss': 0.034770932,\n",
      " 'Loss/total_loss': 0.38996297,\n",
      " 'learning_rate': 0.00150604}\n",
      "INFO:tensorflow:Step 15100 per-step time 0.206s\n",
      "I0623 11:00:53.682565 139760059615040 model_lib_v2.py:700] Step 15100 per-step time 0.206s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.43257117,\n",
      " 'Loss/localization_loss': 0.00030679608,\n",
      " 'Loss/regularization_loss': 0.034770753,\n",
      " 'Loss/total_loss': 0.46764868,\n",
      " 'learning_rate': 0.0014503032}\n",
      "I0623 11:00:53.682818 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.43257117,\n",
      " 'Loss/localization_loss': 0.00030679608,\n",
      " 'Loss/regularization_loss': 0.034770753,\n",
      " 'Loss/total_loss': 0.46764868,\n",
      " 'learning_rate': 0.0014503032}\n",
      "INFO:tensorflow:Step 15200 per-step time 0.190s\n",
      "I0623 11:01:12.729357 139760059615040 model_lib_v2.py:700] Step 15200 per-step time 0.190s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35635778,\n",
      " 'Loss/localization_loss': 0.00033513145,\n",
      " 'Loss/regularization_loss': 0.03476962,\n",
      " 'Loss/total_loss': 0.39146256,\n",
      " 'learning_rate': 0.0013953887}\n",
      "I0623 11:01:12.730030 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35635778,\n",
      " 'Loss/localization_loss': 0.00033513145,\n",
      " 'Loss/regularization_loss': 0.03476962,\n",
      " 'Loss/total_loss': 0.39146256,\n",
      " 'learning_rate': 0.0013953887}\n",
      "INFO:tensorflow:Step 15300 per-step time 0.180s\n",
      "I0623 11:01:30.745347 139760059615040 model_lib_v2.py:700] Step 15300 per-step time 0.180s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3298127,\n",
      " 'Loss/localization_loss': 0.00028383767,\n",
      " 'Loss/regularization_loss': 0.034769636,\n",
      " 'Loss/total_loss': 0.36486614,\n",
      " 'learning_rate': 0.001341313}\n",
      "I0623 11:01:30.745530 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3298127,\n",
      " 'Loss/localization_loss': 0.00028383767,\n",
      " 'Loss/regularization_loss': 0.034769636,\n",
      " 'Loss/total_loss': 0.36486614,\n",
      " 'learning_rate': 0.001341313}\n",
      "INFO:tensorflow:Step 15400 per-step time 0.141s\n",
      "I0623 11:01:44.842547 139760059615040 model_lib_v2.py:700] Step 15400 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3164228,\n",
      " 'Loss/localization_loss': 0.00045648395,\n",
      " 'Loss/regularization_loss': 0.03476863,\n",
      " 'Loss/total_loss': 0.3516479,\n",
      " 'learning_rate': 0.0012880942}\n",
      "I0623 11:01:44.842786 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3164228,\n",
      " 'Loss/localization_loss': 0.00045648395,\n",
      " 'Loss/regularization_loss': 0.03476863,\n",
      " 'Loss/total_loss': 0.3516479,\n",
      " 'learning_rate': 0.0012880942}\n",
      "INFO:tensorflow:Step 15500 per-step time 0.142s\n",
      "I0623 11:01:59.016496 139760059615040 model_lib_v2.py:700] Step 15500 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.29819447,\n",
      " 'Loss/localization_loss': 0.00038910212,\n",
      " 'Loss/regularization_loss': 0.03476877,\n",
      " 'Loss/total_loss': 0.33335233,\n",
      " 'learning_rate': 0.0012357484}\n",
      "I0623 11:01:59.016742 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.29819447,\n",
      " 'Loss/localization_loss': 0.00038910212,\n",
      " 'Loss/regularization_loss': 0.03476877,\n",
      " 'Loss/total_loss': 0.33335233,\n",
      " 'learning_rate': 0.0012357484}\n",
      "INFO:tensorflow:Step 15600 per-step time 0.142s\n",
      "I0623 11:02:13.188838 139760059615040 model_lib_v2.py:700] Step 15600 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5198184,\n",
      " 'Loss/localization_loss': 0.00086486,\n",
      " 'Loss/regularization_loss': 0.03476864,\n",
      " 'Loss/total_loss': 0.55545187,\n",
      " 'learning_rate': 0.001184295}\n",
      "I0623 11:02:13.189023 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5198184,\n",
      " 'Loss/localization_loss': 0.00086486,\n",
      " 'Loss/regularization_loss': 0.03476864,\n",
      " 'Loss/total_loss': 0.55545187,\n",
      " 'learning_rate': 0.001184295}\n",
      "INFO:tensorflow:Step 15700 per-step time 0.141s\n",
      "I0623 11:02:27.239929 139760059615040 model_lib_v2.py:700] Step 15700 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.55698645,\n",
      " 'Loss/localization_loss': 0.0004414858,\n",
      " 'Loss/regularization_loss': 0.034771044,\n",
      " 'Loss/total_loss': 0.59219897,\n",
      " 'learning_rate': 0.0011337484}\n",
      "I0623 11:02:27.240109 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.55698645,\n",
      " 'Loss/localization_loss': 0.0004414858,\n",
      " 'Loss/regularization_loss': 0.034771044,\n",
      " 'Loss/total_loss': 0.59219897,\n",
      " 'learning_rate': 0.0011337484}\n",
      "INFO:tensorflow:Step 15800 per-step time 0.142s\n",
      "I0623 11:02:41.401372 139760059615040 model_lib_v2.py:700] Step 15800 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.38475597,\n",
      " 'Loss/localization_loss': 0.0004325817,\n",
      " 'Loss/regularization_loss': 0.03476912,\n",
      " 'Loss/total_loss': 0.41995764,\n",
      " 'learning_rate': 0.0010841255}\n",
      "I0623 11:02:41.401556 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.38475597,\n",
      " 'Loss/localization_loss': 0.0004325817,\n",
      " 'Loss/regularization_loss': 0.03476912,\n",
      " 'Loss/total_loss': 0.41995764,\n",
      " 'learning_rate': 0.0010841255}\n",
      "INFO:tensorflow:Step 15900 per-step time 0.142s\n",
      "I0623 11:02:55.587455 139760059615040 model_lib_v2.py:700] Step 15900 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41546044,\n",
      " 'Loss/localization_loss': 0.0007892619,\n",
      " 'Loss/regularization_loss': 0.034767557,\n",
      " 'Loss/total_loss': 0.45101726,\n",
      " 'learning_rate': 0.001035442}\n",
      "I0623 11:02:55.587639 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.41546044,\n",
      " 'Loss/localization_loss': 0.0007892619,\n",
      " 'Loss/regularization_loss': 0.034767557,\n",
      " 'Loss/total_loss': 0.45101726,\n",
      " 'learning_rate': 0.001035442}\n",
      "INFO:tensorflow:Step 16000 per-step time 0.141s\n",
      "I0623 11:03:09.698731 139760059615040 model_lib_v2.py:700] Step 16000 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.55654913,\n",
      " 'Loss/localization_loss': 0.00055705383,\n",
      " 'Loss/regularization_loss': 0.0347669,\n",
      " 'Loss/total_loss': 0.59187305,\n",
      " 'learning_rate': 0.0009877135}\n",
      "I0623 11:03:09.698916 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.55654913,\n",
      " 'Loss/localization_loss': 0.00055705383,\n",
      " 'Loss/regularization_loss': 0.0347669,\n",
      " 'Loss/total_loss': 0.59187305,\n",
      " 'learning_rate': 0.0009877135}\n",
      "INFO:tensorflow:Step 16100 per-step time 0.151s\n",
      "I0623 11:03:24.749547 139760059615040 model_lib_v2.py:700] Step 16100 per-step time 0.151s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42426574,\n",
      " 'Loss/localization_loss': 0.00056421605,\n",
      " 'Loss/regularization_loss': 0.034765415,\n",
      " 'Loss/total_loss': 0.45959538,\n",
      " 'learning_rate': 0.00094095676}\n",
      "I0623 11:03:24.749736 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42426574,\n",
      " 'Loss/localization_loss': 0.00056421605,\n",
      " 'Loss/regularization_loss': 0.034765415,\n",
      " 'Loss/total_loss': 0.45959538,\n",
      " 'learning_rate': 0.00094095676}\n",
      "INFO:tensorflow:Step 16200 per-step time 0.141s\n",
      "I0623 11:03:38.823384 139760059615040 model_lib_v2.py:700] Step 16200 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31696022,\n",
      " 'Loss/localization_loss': 0.00070109067,\n",
      " 'Loss/regularization_loss': 0.03476384,\n",
      " 'Loss/total_loss': 0.35242516,\n",
      " 'learning_rate': 0.0008951854}\n",
      "I0623 11:03:38.823569 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.31696022,\n",
      " 'Loss/localization_loss': 0.00070109067,\n",
      " 'Loss/regularization_loss': 0.03476384,\n",
      " 'Loss/total_loss': 0.35242516,\n",
      " 'learning_rate': 0.0008951854}\n",
      "INFO:tensorflow:Step 16300 per-step time 0.141s\n",
      "I0623 11:03:52.904390 139760059615040 model_lib_v2.py:700] Step 16300 per-step time 0.141s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4589144,\n",
      " 'Loss/localization_loss': 0.00031032576,\n",
      " 'Loss/regularization_loss': 0.03476325,\n",
      " 'Loss/total_loss': 0.49398795,\n",
      " 'learning_rate': 0.00085041445}\n",
      "I0623 11:03:52.904574 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4589144,\n",
      " 'Loss/localization_loss': 0.00031032576,\n",
      " 'Loss/regularization_loss': 0.03476325,\n",
      " 'Loss/total_loss': 0.49398795,\n",
      " 'learning_rate': 0.00085041445}\n",
      "INFO:tensorflow:Step 16400 per-step time 0.142s\n",
      "I0623 11:04:07.101137 139760059615040 model_lib_v2.py:700] Step 16400 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.34126222,\n",
      " 'Loss/localization_loss': 0.00036843444,\n",
      " 'Loss/regularization_loss': 0.034762718,\n",
      " 'Loss/total_loss': 0.37639335,\n",
      " 'learning_rate': 0.0008066587}\n",
      "I0623 11:04:07.101316 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.34126222,\n",
      " 'Loss/localization_loss': 0.00036843444,\n",
      " 'Loss/regularization_loss': 0.034762718,\n",
      " 'Loss/total_loss': 0.37639335,\n",
      " 'learning_rate': 0.0008066587}\n",
      "INFO:tensorflow:Step 16500 per-step time 0.142s\n",
      "I0623 11:04:21.257856 139760059615040 model_lib_v2.py:700] Step 16500 per-step time 0.142s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23490076,\n",
      " 'Loss/localization_loss': 0.0004733061,\n",
      " 'Loss/regularization_loss': 0.03476113,\n",
      " 'Loss/total_loss': 0.2701352,\n",
      " 'learning_rate': 0.0007639317}\n",
      "I0623 11:04:21.258031 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.23490076,\n",
      " 'Loss/localization_loss': 0.0004733061,\n",
      " 'Loss/regularization_loss': 0.03476113,\n",
      " 'Loss/total_loss': 0.2701352,\n",
      " 'learning_rate': 0.0007639317}\n",
      "INFO:tensorflow:Step 16600 per-step time 0.144s\n",
      "I0623 11:04:35.686846 139760059615040 model_lib_v2.py:700] Step 16600 per-step time 0.144s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30976433,\n",
      " 'Loss/localization_loss': 0.00033171725,\n",
      " 'Loss/regularization_loss': 0.03476037,\n",
      " 'Loss/total_loss': 0.34485644,\n",
      " 'learning_rate': 0.00072224805}\n",
      "I0623 11:04:35.687211 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.30976433,\n",
      " 'Loss/localization_loss': 0.00033171725,\n",
      " 'Loss/regularization_loss': 0.03476037,\n",
      " 'Loss/total_loss': 0.34485644,\n",
      " 'learning_rate': 0.00072224805}\n",
      "INFO:tensorflow:Step 16700 per-step time 0.187s\n",
      "I0623 11:04:54.413018 139760059615040 model_lib_v2.py:700] Step 16700 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4127735,\n",
      " 'Loss/localization_loss': 0.0005543266,\n",
      " 'Loss/regularization_loss': 0.034760535,\n",
      " 'Loss/total_loss': 0.44808838,\n",
      " 'learning_rate': 0.0006816203}\n",
      "I0623 11:04:54.413543 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4127735,\n",
      " 'Loss/localization_loss': 0.0005543266,\n",
      " 'Loss/regularization_loss': 0.034760535,\n",
      " 'Loss/total_loss': 0.44808838,\n",
      " 'learning_rate': 0.0006816203}\n",
      "INFO:tensorflow:Step 16800 per-step time 0.189s\n",
      "I0623 11:05:13.297927 139760059615040 model_lib_v2.py:700] Step 16800 per-step time 0.189s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.29389334,\n",
      " 'Loss/localization_loss': 0.00045278948,\n",
      " 'Loss/regularization_loss': 0.034759626,\n",
      " 'Loss/total_loss': 0.32910576,\n",
      " 'learning_rate': 0.00064206216}\n",
      "I0623 11:05:13.298165 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.29389334,\n",
      " 'Loss/localization_loss': 0.00045278948,\n",
      " 'Loss/regularization_loss': 0.034759626,\n",
      " 'Loss/total_loss': 0.32910576,\n",
      " 'learning_rate': 0.00064206216}\n",
      "INFO:tensorflow:Step 16900 per-step time 0.188s\n",
      "I0623 11:05:32.078880 139760059615040 model_lib_v2.py:700] Step 16900 per-step time 0.188s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.35733637,\n",
      " 'Loss/localization_loss': 0.00031914643,\n",
      " 'Loss/regularization_loss': 0.034759223,\n",
      " 'Loss/total_loss': 0.39241475,\n",
      " 'learning_rate': 0.0006035866}\n",
      "I0623 11:05:32.079499 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.35733637,\n",
      " 'Loss/localization_loss': 0.00031914643,\n",
      " 'Loss/regularization_loss': 0.034759223,\n",
      " 'Loss/total_loss': 0.39241475,\n",
      " 'learning_rate': 0.0006035866}\n",
      "INFO:tensorflow:Step 17000 per-step time 0.186s\n",
      "I0623 11:05:50.645756 139760059615040 model_lib_v2.py:700] Step 17000 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40709457,\n",
      " 'Loss/localization_loss': 0.00032409292,\n",
      " 'Loss/regularization_loss': 0.034759145,\n",
      " 'Loss/total_loss': 0.4421778,\n",
      " 'learning_rate': 0.0005662045}\n",
      "I0623 11:05:50.646146 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.40709457,\n",
      " 'Loss/localization_loss': 0.00032409292,\n",
      " 'Loss/regularization_loss': 0.034759145,\n",
      " 'Loss/total_loss': 0.4421778,\n",
      " 'learning_rate': 0.0005662045}\n",
      "INFO:tensorflow:Step 17100 per-step time 0.201s\n",
      "I0623 11:06:10.732012 139760059615040 model_lib_v2.py:700] Step 17100 per-step time 0.201s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39098978,\n",
      " 'Loss/localization_loss': 0.00028509749,\n",
      " 'Loss/regularization_loss': 0.034758613,\n",
      " 'Loss/total_loss': 0.42603347,\n",
      " 'learning_rate': 0.0005299296}\n",
      "I0623 11:06:10.732260 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39098978,\n",
      " 'Loss/localization_loss': 0.00028509749,\n",
      " 'Loss/regularization_loss': 0.034758613,\n",
      " 'Loss/total_loss': 0.42603347,\n",
      " 'learning_rate': 0.0005299296}\n",
      "INFO:tensorflow:Step 17200 per-step time 0.187s\n",
      "I0623 11:06:29.475442 139760059615040 model_lib_v2.py:700] Step 17200 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.52912426,\n",
      " 'Loss/localization_loss': 0.00044613652,\n",
      " 'Loss/regularization_loss': 0.034758575,\n",
      " 'Loss/total_loss': 0.56432897,\n",
      " 'learning_rate': 0.00049477286}\n",
      "I0623 11:06:29.475965 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.52912426,\n",
      " 'Loss/localization_loss': 0.00044613652,\n",
      " 'Loss/regularization_loss': 0.034758575,\n",
      " 'Loss/total_loss': 0.56432897,\n",
      " 'learning_rate': 0.00049477286}\n",
      "INFO:tensorflow:Step 17300 per-step time 0.185s\n",
      "I0623 11:06:47.976272 139760059615040 model_lib_v2.py:700] Step 17300 per-step time 0.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40293878,\n",
      " 'Loss/localization_loss': 0.0006689681,\n",
      " 'Loss/regularization_loss': 0.034757532,\n",
      " 'Loss/total_loss': 0.43836528,\n",
      " 'learning_rate': 0.00046074603}\n",
      "I0623 11:06:47.976472 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.40293878,\n",
      " 'Loss/localization_loss': 0.0006689681,\n",
      " 'Loss/regularization_loss': 0.034757532,\n",
      " 'Loss/total_loss': 0.43836528,\n",
      " 'learning_rate': 0.00046074603}\n",
      "INFO:tensorflow:Step 17400 per-step time 0.186s\n",
      "I0623 11:07:06.553445 139760059615040 model_lib_v2.py:700] Step 17400 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.44980174,\n",
      " 'Loss/localization_loss': 0.0005166469,\n",
      " 'Loss/regularization_loss': 0.034756873,\n",
      " 'Loss/total_loss': 0.4850753,\n",
      " 'learning_rate': 0.00042785998}\n",
      "I0623 11:07:06.553862 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.44980174,\n",
      " 'Loss/localization_loss': 0.0005166469,\n",
      " 'Loss/regularization_loss': 0.034756873,\n",
      " 'Loss/total_loss': 0.4850753,\n",
      " 'learning_rate': 0.00042785998}\n",
      "INFO:tensorflow:Step 17500 per-step time 0.186s\n",
      "I0623 11:07:25.182126 139760059615040 model_lib_v2.py:700] Step 17500 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40055493,\n",
      " 'Loss/localization_loss': 0.00020538404,\n",
      " 'Loss/regularization_loss': 0.03475681,\n",
      " 'Loss/total_loss': 0.43551713,\n",
      " 'learning_rate': 0.0003961241}\n",
      "I0623 11:07:25.182681 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.40055493,\n",
      " 'Loss/localization_loss': 0.00020538404,\n",
      " 'Loss/regularization_loss': 0.03475681,\n",
      " 'Loss/total_loss': 0.43551713,\n",
      " 'learning_rate': 0.0003961241}\n",
      "INFO:tensorflow:Step 17600 per-step time 0.186s\n",
      "I0623 11:07:43.761561 139760059615040 model_lib_v2.py:700] Step 17600 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.32072306,\n",
      " 'Loss/localization_loss': 0.00031769197,\n",
      " 'Loss/regularization_loss': 0.034756135,\n",
      " 'Loss/total_loss': 0.35579687,\n",
      " 'learning_rate': 0.00036555025}\n",
      "I0623 11:07:43.761835 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.32072306,\n",
      " 'Loss/localization_loss': 0.00031769197,\n",
      " 'Loss/regularization_loss': 0.034756135,\n",
      " 'Loss/total_loss': 0.35579687,\n",
      " 'learning_rate': 0.00036555025}\n",
      "INFO:tensorflow:Step 17700 per-step time 0.186s\n",
      "I0623 11:08:02.351617 139760059615040 model_lib_v2.py:700] Step 17700 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.39427394,\n",
      " 'Loss/localization_loss': 0.00055097765,\n",
      " 'Loss/regularization_loss': 0.034755826,\n",
      " 'Loss/total_loss': 0.42958075,\n",
      " 'learning_rate': 0.00033614776}\n",
      "I0623 11:08:02.352311 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.39427394,\n",
      " 'Loss/localization_loss': 0.00055097765,\n",
      " 'Loss/regularization_loss': 0.034755826,\n",
      " 'Loss/total_loss': 0.42958075,\n",
      " 'learning_rate': 0.00033614776}\n",
      "INFO:tensorflow:Step 17800 per-step time 0.185s\n",
      "I0623 11:08:20.890838 139760059615040 model_lib_v2.py:700] Step 17800 per-step time 0.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2570399,\n",
      " 'Loss/localization_loss': 0.00022496423,\n",
      " 'Loss/regularization_loss': 0.034755137,\n",
      " 'Loss/total_loss': 0.29202,\n",
      " 'learning_rate': 0.00030792615}\n",
      "I0623 11:08:20.891419 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.2570399,\n",
      " 'Loss/localization_loss': 0.00022496423,\n",
      " 'Loss/regularization_loss': 0.034755137,\n",
      " 'Loss/total_loss': 0.29202,\n",
      " 'learning_rate': 0.00030792615}\n",
      "INFO:tensorflow:Step 17900 per-step time 0.187s\n",
      "I0623 11:08:39.541504 139760059615040 model_lib_v2.py:700] Step 17900 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.50254416,\n",
      " 'Loss/localization_loss': 0.00038643085,\n",
      " 'Loss/regularization_loss': 0.034755412,\n",
      " 'Loss/total_loss': 0.537686,\n",
      " 'learning_rate': 0.00028089402}\n",
      "I0623 11:08:39.542289 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.50254416,\n",
      " 'Loss/localization_loss': 0.00038643085,\n",
      " 'Loss/regularization_loss': 0.034755412,\n",
      " 'Loss/total_loss': 0.537686,\n",
      " 'learning_rate': 0.00028089402}\n",
      "INFO:tensorflow:Step 18000 per-step time 0.186s\n",
      "I0623 11:08:58.157281 139760059615040 model_lib_v2.py:700] Step 18000 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3740642,\n",
      " 'Loss/localization_loss': 0.00017735684,\n",
      " 'Loss/regularization_loss': 0.03475485,\n",
      " 'Loss/total_loss': 0.4089964,\n",
      " 'learning_rate': 0.00025506018}\n",
      "I0623 11:08:58.158122 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3740642,\n",
      " 'Loss/localization_loss': 0.00017735684,\n",
      " 'Loss/regularization_loss': 0.03475485,\n",
      " 'Loss/total_loss': 0.4089964,\n",
      " 'learning_rate': 0.00025506018}\n",
      "INFO:tensorflow:Step 18100 per-step time 0.202s\n",
      "I0623 11:09:18.362768 139760059615040 model_lib_v2.py:700] Step 18100 per-step time 0.202s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5822629,\n",
      " 'Loss/localization_loss': 0.0001960904,\n",
      " 'Loss/regularization_loss': 0.034754205,\n",
      " 'Loss/total_loss': 0.61721313,\n",
      " 'learning_rate': 0.00023043345}\n",
      "I0623 11:09:18.362970 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5822629,\n",
      " 'Loss/localization_loss': 0.0001960904,\n",
      " 'Loss/regularization_loss': 0.034754205,\n",
      " 'Loss/total_loss': 0.61721313,\n",
      " 'learning_rate': 0.00023043345}\n",
      "INFO:tensorflow:Step 18200 per-step time 0.186s\n",
      "I0623 11:09:36.947788 139760059615040 model_lib_v2.py:700] Step 18200 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.26229256,\n",
      " 'Loss/localization_loss': 0.00013969987,\n",
      " 'Loss/regularization_loss': 0.034754448,\n",
      " 'Loss/total_loss': 0.2971867,\n",
      " 'learning_rate': 0.0002070217}\n",
      "I0623 11:09:36.948641 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.26229256,\n",
      " 'Loss/localization_loss': 0.00013969987,\n",
      " 'Loss/regularization_loss': 0.034754448,\n",
      " 'Loss/total_loss': 0.2971867,\n",
      " 'learning_rate': 0.0002070217}\n",
      "INFO:tensorflow:Step 18300 per-step time 0.187s\n",
      "I0623 11:09:55.624844 139760059615040 model_lib_v2.py:700] Step 18300 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.31031197,\n",
      " 'Loss/localization_loss': 0.00017101434,\n",
      " 'Loss/regularization_loss': 0.034754124,\n",
      " 'Loss/total_loss': 0.34523714,\n",
      " 'learning_rate': 0.00018483232}\n",
      "I0623 11:09:55.625133 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.31031197,\n",
      " 'Loss/localization_loss': 0.00017101434,\n",
      " 'Loss/regularization_loss': 0.034754124,\n",
      " 'Loss/total_loss': 0.34523714,\n",
      " 'learning_rate': 0.00018483232}\n",
      "INFO:tensorflow:Step 18400 per-step time 0.186s\n",
      "I0623 11:10:14.227678 139760059615040 model_lib_v2.py:700] Step 18400 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30389214,\n",
      " 'Loss/localization_loss': 0.00013965988,\n",
      " 'Loss/regularization_loss': 0.034753773,\n",
      " 'Loss/total_loss': 0.33878553,\n",
      " 'learning_rate': 0.00016387246}\n",
      "I0623 11:10:14.228610 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.30389214,\n",
      " 'Loss/localization_loss': 0.00013965988,\n",
      " 'Loss/regularization_loss': 0.034753773,\n",
      " 'Loss/total_loss': 0.33878553,\n",
      " 'learning_rate': 0.00016387246}\n",
      "INFO:tensorflow:Step 18500 per-step time 0.185s\n",
      "I0623 11:10:32.754157 139760059615040 model_lib_v2.py:700] Step 18500 per-step time 0.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.36692148,\n",
      " 'Loss/localization_loss': 0.00027916336,\n",
      " 'Loss/regularization_loss': 0.03475349,\n",
      " 'Loss/total_loss': 0.40195417,\n",
      " 'learning_rate': 0.00014414833}\n",
      "I0623 11:10:32.754370 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.36692148,\n",
      " 'Loss/localization_loss': 0.00027916336,\n",
      " 'Loss/regularization_loss': 0.03475349,\n",
      " 'Loss/total_loss': 0.40195417,\n",
      " 'learning_rate': 0.00014414833}\n",
      "INFO:tensorflow:Step 18600 per-step time 0.186s\n",
      "I0623 11:10:51.343834 139760059615040 model_lib_v2.py:700] Step 18600 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.42971843,\n",
      " 'Loss/localization_loss': 0.00027652158,\n",
      " 'Loss/regularization_loss': 0.03475335,\n",
      " 'Loss/total_loss': 0.46474826,\n",
      " 'learning_rate': 0.00012566708}\n",
      "I0623 11:10:51.344161 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.42971843,\n",
      " 'Loss/localization_loss': 0.00027652158,\n",
      " 'Loss/regularization_loss': 0.03475335,\n",
      " 'Loss/total_loss': 0.46474826,\n",
      " 'learning_rate': 0.00012566708}\n",
      "INFO:tensorflow:Step 18700 per-step time 0.186s\n",
      "I0623 11:11:09.964000 139760059615040 model_lib_v2.py:700] Step 18700 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.5988669,\n",
      " 'Loss/localization_loss': 0.00031838263,\n",
      " 'Loss/regularization_loss': 0.03475316,\n",
      " 'Loss/total_loss': 0.63393843,\n",
      " 'learning_rate': 0.00010843467}\n",
      "I0623 11:11:09.964250 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.5988669,\n",
      " 'Loss/localization_loss': 0.00031838263,\n",
      " 'Loss/regularization_loss': 0.03475316,\n",
      " 'Loss/total_loss': 0.63393843,\n",
      " 'learning_rate': 0.00010843467}\n",
      "INFO:tensorflow:Step 18800 per-step time 0.186s\n",
      "I0623 11:11:28.519437 139760059615040 model_lib_v2.py:700] Step 18800 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30978775,\n",
      " 'Loss/localization_loss': 0.0003160637,\n",
      " 'Loss/regularization_loss': 0.034753054,\n",
      " 'Loss/total_loss': 0.34485686,\n",
      " 'learning_rate': 9.2456095e-05}\n",
      "I0623 11:11:28.520312 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.30978775,\n",
      " 'Loss/localization_loss': 0.0003160637,\n",
      " 'Loss/regularization_loss': 0.034753054,\n",
      " 'Loss/total_loss': 0.34485686,\n",
      " 'learning_rate': 9.2456095e-05}\n",
      "INFO:tensorflow:Step 18900 per-step time 0.187s\n",
      "I0623 11:11:47.260886 139760059615040 model_lib_v2.py:700] Step 18900 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30858758,\n",
      " 'Loss/localization_loss': 0.0002881228,\n",
      " 'Loss/regularization_loss': 0.034753002,\n",
      " 'Loss/total_loss': 0.3436287,\n",
      " 'learning_rate': 7.773685e-05}\n",
      "I0623 11:11:47.261491 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.30858758,\n",
      " 'Loss/localization_loss': 0.0002881228,\n",
      " 'Loss/regularization_loss': 0.034753002,\n",
      " 'Loss/total_loss': 0.3436287,\n",
      " 'learning_rate': 7.773685e-05}\n",
      "INFO:tensorflow:Step 19000 per-step time 0.187s\n",
      "I0623 11:12:05.928572 139760059615040 model_lib_v2.py:700] Step 19000 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.40199086,\n",
      " 'Loss/localization_loss': 0.00044117653,\n",
      " 'Loss/regularization_loss': 0.0347529,\n",
      " 'Loss/total_loss': 0.43718496,\n",
      " 'learning_rate': 6.4281456e-05}\n",
      "I0623 11:12:05.928804 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.40199086,\n",
      " 'Loss/localization_loss': 0.00044117653,\n",
      " 'Loss/regularization_loss': 0.0347529,\n",
      " 'Loss/total_loss': 0.43718496,\n",
      " 'learning_rate': 6.4281456e-05}\n",
      "INFO:tensorflow:Step 19100 per-step time 0.201s\n",
      "I0623 11:12:26.069435 139760059615040 model_lib_v2.py:700] Step 19100 per-step time 0.201s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.33741587,\n",
      " 'Loss/localization_loss': 0.0004274023,\n",
      " 'Loss/regularization_loss': 0.0347529,\n",
      " 'Loss/total_loss': 0.37259617,\n",
      " 'learning_rate': 5.2094456e-05}\n",
      "I0623 11:12:26.069653 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.33741587,\n",
      " 'Loss/localization_loss': 0.0004274023,\n",
      " 'Loss/regularization_loss': 0.0347529,\n",
      " 'Loss/total_loss': 0.37259617,\n",
      " 'learning_rate': 5.2094456e-05}\n",
      "INFO:tensorflow:Step 19200 per-step time 0.186s\n",
      "I0623 11:12:44.696800 139760059615040 model_lib_v2.py:700] Step 19200 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.41523173,\n",
      " 'Loss/localization_loss': 0.00026770876,\n",
      " 'Loss/regularization_loss': 0.034752894,\n",
      " 'Loss/total_loss': 0.45025235,\n",
      " 'learning_rate': 4.118013e-05}\n",
      "I0623 11:12:44.697011 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.41523173,\n",
      " 'Loss/localization_loss': 0.00026770876,\n",
      " 'Loss/regularization_loss': 0.034752894,\n",
      " 'Loss/total_loss': 0.45025235,\n",
      " 'learning_rate': 4.118013e-05}\n",
      "INFO:tensorflow:Step 19300 per-step time 0.186s\n",
      "I0623 11:13:03.259299 139760059615040 model_lib_v2.py:700] Step 19300 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21074352,\n",
      " 'Loss/localization_loss': 0.00034331673,\n",
      " 'Loss/regularization_loss': 0.034752797,\n",
      " 'Loss/total_loss': 0.24583963,\n",
      " 'learning_rate': 3.1541105e-05}\n",
      "I0623 11:13:03.259531 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.21074352,\n",
      " 'Loss/localization_loss': 0.00034331673,\n",
      " 'Loss/regularization_loss': 0.034752797,\n",
      " 'Loss/total_loss': 0.24583963,\n",
      " 'learning_rate': 3.1541105e-05}\n",
      "INFO:tensorflow:Step 19400 per-step time 0.186s\n",
      "I0623 11:13:21.888171 139760059615040 model_lib_v2.py:700] Step 19400 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.29649416,\n",
      " 'Loss/localization_loss': 0.00027083827,\n",
      " 'Loss/regularization_loss': 0.034752768,\n",
      " 'Loss/total_loss': 0.33151776,\n",
      " 'learning_rate': 2.31812e-05}\n",
      "I0623 11:13:21.888831 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.29649416,\n",
      " 'Loss/localization_loss': 0.00027083827,\n",
      " 'Loss/regularization_loss': 0.034752768,\n",
      " 'Loss/total_loss': 0.33151776,\n",
      " 'learning_rate': 2.31812e-05}\n",
      "INFO:tensorflow:Step 19500 per-step time 0.186s\n",
      "I0623 11:13:40.460501 139760059615040 model_lib_v2.py:700] Step 19500 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3475998,\n",
      " 'Loss/localization_loss': 0.00047432852,\n",
      " 'Loss/regularization_loss': 0.03475276,\n",
      " 'Loss/total_loss': 0.38282692,\n",
      " 'learning_rate': 1.610279e-05}\n",
      "I0623 11:13:40.461096 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.3475998,\n",
      " 'Loss/localization_loss': 0.00047432852,\n",
      " 'Loss/regularization_loss': 0.03475276,\n",
      " 'Loss/total_loss': 0.38282692,\n",
      " 'learning_rate': 1.610279e-05}\n",
      "INFO:tensorflow:Step 19600 per-step time 0.186s\n",
      "I0623 11:13:59.038568 139760059615040 model_lib_v2.py:700] Step 19600 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.71715486,\n",
      " 'Loss/localization_loss': 0.0006317022,\n",
      " 'Loss/regularization_loss': 0.03475271,\n",
      " 'Loss/total_loss': 0.7525393,\n",
      " 'learning_rate': 1.0308265e-05}\n",
      "I0623 11:13:59.039224 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.71715486,\n",
      " 'Loss/localization_loss': 0.0006317022,\n",
      " 'Loss/regularization_loss': 0.03475271,\n",
      " 'Loss/total_loss': 0.7525393,\n",
      " 'learning_rate': 1.0308265e-05}\n",
      "INFO:tensorflow:Step 19700 per-step time 0.187s\n",
      "I0623 11:14:17.775975 139760059615040 model_lib_v2.py:700] Step 19700 per-step time 0.187s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.53852874,\n",
      " 'Loss/localization_loss': 0.00046926516,\n",
      " 'Loss/regularization_loss': 0.0347527,\n",
      " 'Loss/total_loss': 0.57375073,\n",
      " 'learning_rate': 5.7995317e-06}\n",
      "I0623 11:14:17.776476 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.53852874,\n",
      " 'Loss/localization_loss': 0.00046926516,\n",
      " 'Loss/regularization_loss': 0.0347527,\n",
      " 'Loss/total_loss': 0.57375073,\n",
      " 'learning_rate': 5.7995317e-06}\n",
      "INFO:tensorflow:Step 19800 per-step time 0.186s\n",
      "I0623 11:14:36.399723 139760059615040 model_lib_v2.py:700] Step 19800 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2210946,\n",
      " 'Loss/localization_loss': 0.00046509784,\n",
      " 'Loss/regularization_loss': 0.03475269,\n",
      " 'Loss/total_loss': 0.25631237,\n",
      " 'learning_rate': 2.5777815e-06}\n",
      "I0623 11:14:36.400246 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.2210946,\n",
      " 'Loss/localization_loss': 0.00046509784,\n",
      " 'Loss/regularization_loss': 0.03475269,\n",
      " 'Loss/total_loss': 0.25631237,\n",
      " 'learning_rate': 2.5777815e-06}\n",
      "INFO:tensorflow:Step 19900 per-step time 0.185s\n",
      "I0623 11:14:54.892455 139760059615040 model_lib_v2.py:700] Step 19900 per-step time 0.185s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23118827,\n",
      " 'Loss/localization_loss': 0.00018970962,\n",
      " 'Loss/regularization_loss': 0.034752686,\n",
      " 'Loss/total_loss': 0.26613066,\n",
      " 'learning_rate': 6.444454e-07}\n",
      "I0623 11:14:54.892650 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.23118827,\n",
      " 'Loss/localization_loss': 0.00018970962,\n",
      " 'Loss/regularization_loss': 0.034752686,\n",
      " 'Loss/total_loss': 0.26613066,\n",
      " 'learning_rate': 6.444454e-07}\n",
      "INFO:tensorflow:Step 20000 per-step time 0.186s\n",
      "I0623 11:15:13.519686 139760059615040 model_lib_v2.py:700] Step 20000 per-step time 0.186s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.4426077,\n",
      " 'Loss/localization_loss': 0.000102994614,\n",
      " 'Loss/regularization_loss': 0.034752686,\n",
      " 'Loss/total_loss': 0.47746336,\n",
      " 'learning_rate': 0.0}\n",
      "I0623 11:15:13.520250 139760059615040 model_lib_v2.py:701] {'Loss/classification_loss': 0.4426077,\n",
      " 'Loss/localization_loss': 0.000102994614,\n",
      " 'Loss/regularization_loss': 0.034752686,\n",
      " 'Loss/total_loss': 0.47746336,\n",
      " 'learning_rate': 0.0}\n"
     ]
    }
   ],
   "source": [
    "!python model_main_tf2.py --model_dir=models/my_efficientdet_d2_coco17_tpu-32 --pipeline_config_path=models/my_efficientdet_d2_coco17_tpu-32/pipeline.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!cp models/research/object_detection/exporter_main_v2.py /tf/Kostya_working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Annotations\r\n",
      " JPEG\r\n",
      " Models_config_files\r\n",
      " Models_outputs\r\n",
      " Reserves\r\n",
      " efficientdet_d2_coco17_tpu-32.tar.gz\r\n",
      " exported-models\r\n",
      " exporter_main_v2.py\r\n",
      " model_main_tf2.py\r\n",
      " models\r\n",
      " pre-trained-models\r\n",
      " readme.txt\r\n",
      "'siim-covid-19-v-2-6-(Kostya_version).ipynb'\r\n",
      " siim_covid-19_TFRecords_and_Keras.ipynb\r\n",
      " ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\r\n",
      " tfrecord_train.tfrec\r\n",
      " tfrecord_validation.tfrec\r\n",
      " train_df.csv\r\n",
      " val_df.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir models/my_ssd_resnet50_v1_fpn/ --output_directory exported-models/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-23 11:15:30.424867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 11:15:33.466294: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-23 11:15:33.539736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.540170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 11:15:33.540300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.540843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 11:15:33.540917: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 11:15:33.547028: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-23 11:15:33.547117: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-23 11:15:33.548178: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-23 11:15:33.548437: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-23 11:15:33.549420: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-06-23 11:15:33.550336: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-23 11:15:33.550726: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-23 11:15:33.550848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.551356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.551835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.552497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.553033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-06-23 11:15:33.553837: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-23 11:15:33.827977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.828510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 11:15:33.828631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.828959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \n",
      "pciBusID: 0000:02:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5\n",
      "coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s\n",
      "2021-06-23 11:15:33.829013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.829457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.829998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.830402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:33.830811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\n",
      "2021-06-23 11:15:33.830918: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-23 11:15:35.256022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-23 11:15:35.256058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \n",
      "2021-06-23 11:15:35.256063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N \n",
      "2021-06-23 11:15:35.256067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N \n",
      "2021-06-23 11:15:35.256363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:35.256966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:35.257476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:35.257894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:35.258211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:35.258621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9653 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2021-06-23 11:15:35.258901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-23 11:15:35.259314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 9615 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "I0623 11:15:35.405145 139966340122432 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I0623 11:15:35.405756 139966340122432 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
      "I0623 11:15:35.405815 139966340122432 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
      "I0623 11:15:35.418114 139966340122432 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 11:15:35.471105 139966340122432 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0623 11:15:35.471229 139966340122432 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 11:15:35.685290 139966340122432 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0623 11:15:35.685468 139966340122432 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 11:15:36.084845 139966340122432 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0623 11:15:36.085227 139966340122432 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 11:15:36.407241 139966340122432 efficientnet_model.py:147] round_filter input=40 output=48\n",
      "I0623 11:15:36.407380 139966340122432 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0623 11:15:36.919105 139966340122432 efficientnet_model.py:147] round_filter input=80 output=88\n",
      "I0623 11:15:36.919436 139966340122432 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0623 11:15:37.424188 139966340122432 efficientnet_model.py:147] round_filter input=112 output=120\n",
      "I0623 11:15:37.424301 139966340122432 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0623 11:15:38.214435 139966340122432 efficientnet_model.py:147] round_filter input=192 output=208\n",
      "I0623 11:15:38.214556 139966340122432 efficientnet_model.py:147] round_filter input=320 output=352\n",
      "I0623 11:15:38.481499 139966340122432 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
      "I0623 11:15:38.516724 139966340122432 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0623 11:15:44.771229 139966340122432 deprecation.py:601] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f4b5c271ba8>, because it is not built.\n",
      "W0623 11:16:15.010388 139966340122432 save_impl.py:77] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f4b5c271ba8>, because it is not built.\n",
      "2021-06-23 11:17:07.119103: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0623 11:17:35.486675 139966340122432 save.py:243] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 1075). These functions will not be directly callable after loading.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0623 11:17:44.085191 139966340122432 save.py:1240] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: exported-models/my_model/saved_model/assets\n",
      "I0623 11:17:44.973694 139966340122432 builder_impl.py:775] Assets written to: exported-models/my_model/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to exported-models/my_model/pipeline.config\n",
      "I0623 11:17:46.653776 139966340122432 config_util.py:254] Writing pipeline config file to exported-models/my_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "# Takes ~1'20\"\n",
    "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path models/my_efficientdet_d2_coco17_tpu-32/pipeline.config --trained_checkpoint_dir models/my_efficientdet_d2_coco17_tpu-32/ --output_directory exported-models/my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untar test set archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /tf/data/JPEG\n",
    "# !mkdir test\n",
    "# !tar xvf test.tar.gz -C test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1263"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('/tf/data/JPEG/test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test_df from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = []\n",
    "for filename in os.listdir('/tf/data/JPEG/test'):\n",
    "    test_filenames.append(filename)\n",
    "\n",
    "test_df = pd.DataFrame(test_filenames, columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37c6c0aee54b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91558723b2cd.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e49489fcf5c0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1b66ff8f4eb.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16972e92e827.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>4040afec3ee4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>620191dbdfa4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>503a6e0884c6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3dcdfc352a06.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3fe73d3b28b9.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1263 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id\n",
       "0     37c6c0aee54b.jpg\n",
       "1     91558723b2cd.jpg\n",
       "2     e49489fcf5c0.jpg\n",
       "3     f1b66ff8f4eb.jpg\n",
       "4     16972e92e827.jpg\n",
       "...                ...\n",
       "1258  4040afec3ee4.jpg\n",
       "1259  620191dbdfa4.jpg\n",
       "1260  503a6e0884c6.jpg\n",
       "1261  3dcdfc352a06.jpg\n",
       "1262  3fe73d3b28b9.jpg\n",
       "\n",
       "[1263 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00188a671292_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004bd59708be_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00508faccd39_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>006486aa80b2_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00655178fdfc_study</td>\n",
       "      <td>negative 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id    PredictionString\n",
       "0  00188a671292_study  negative 1 0 0 1 1\n",
       "1  004bd59708be_study  negative 1 0 0 1 1\n",
       "2  00508faccd39_study  negative 1 0 0 1 1\n",
       "3  006486aa80b2_study  negative 1 0 0 1 1\n",
       "4  00655178fdfc_study  negative 1 0 0 1 1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.loc[sample_submission['id'] == '006486aa80b2_study'].index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look up unique suffixes in sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_suffixes_in_images(df):\n",
    "    suffixes = set()\n",
    "    for index, row in df.iterrows():\n",
    "        suffixes.add(row['id'][-6:])\n",
    "    return suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_image', '_study'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_suffixes_in_images(sample_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_123339) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_139800) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_83000) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_170945) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_168357) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_128901) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_EfficientDet-D2_layer_call_and_return_conditional_losses_134238) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_call_func_23673) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_bifpn_layer_call_and_return_conditional_losses_76025) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "WARNING:absl:Importing a function (__inference_call_func_108942) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Took 19.97804045677185 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "PATH_TO_SAVED_MODEL = \"exported-models/my_model/saved_model\"\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load saved model and build the detection function\n",
    "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/Kostya_working_dir\n"
     ]
    }
   ],
   "source": [
    "%cd /tf/Kostya_working_dir/\n",
    "PATH_TO_LABELS = 'Annotations/label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function is only for testing purposes - it loads just a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/tf/data/JPEG/test/'\n",
    "\n",
    "def download_images():\n",
    "    filenames = ['ebaebf6b1e02.jpg', 'e7b2a9418b98.jpg', '127c2b32dd5d.jpg', 'ccc5b63ca96d.jpg', \n",
    "                 '83594e6ad0ba.jpg', 'cb75251076c7.jpg']\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "        image_path = base_path + filename\n",
    "        image_path = pathlib.Path(image_path)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths\n",
    "\n",
    "IMAGE_PATHS = download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a number of random files in test set\n",
    "\n",
    "import random\n",
    "\n",
    "def pick_n_random_files(n):\n",
    "    filenames = random.sample(os.listdir(base_path), n)\n",
    "    image_paths = []\n",
    "    for filename in filenames:\n",
    "        image_path = base_path + filename\n",
    "        image_path = pathlib.Path(image_path)\n",
    "        image_paths.append(str(image_path))\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path).convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes ~40 sec\n",
    "\n",
    "#from collections import defaultdict\n",
    "%matplotlib inline\n",
    "\n",
    "test_images_predict_dict = {}\n",
    "# print(IMAGE_PATHS)\n",
    "for image in os.listdir(base_path):\n",
    "\n",
    "#IMAGE_PATHS = pick_n_random_files(10)\n",
    "#for image in IMAGE_PATHS:\n",
    "    #print('Running inference for {}... '.format(image), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(base_path + image)\n",
    "    # print(image)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    # print(input_tensor.shape)\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    #print(detections)\n",
    "    \n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    # Try to scale bboxes\n",
    "    \n",
    "    detections['detection_boxes'] = 255 * detections['detection_boxes']\n",
    "    \n",
    "    # print(f\"Number of detection_classes is {len(detections['detection_classes'])}\")\n",
    "    # print(f\"Number of detection_scores is {len(detections['detection_scores'])}\")\n",
    "    # print(f\"Number of detection_boxes is {len(detections['detection_boxes'])}\")\n",
    "    \n",
    "    test_images_predict_dict[image] = {}\n",
    "    test_images_predict_dict[image]['class'] = []\n",
    "    test_images_predict_dict[image]['bbox'] = []\n",
    "    \n",
    "    for ind, score in enumerate(detections['detection_scores']):\n",
    "        if score > 0.5:\n",
    "            test_images_predict_dict[image]['class'].append(detections['detection_classes'][ind])\n",
    "            test_images_predict_dict[image]['bbox'].append(detections['detection_boxes'][ind])\n",
    "    \n",
    "    # print(test_images_predict_dict)\n",
    "    \n",
    "    # Visualizing the image with detections\n",
    "#     image_np_with_detections = image_np.copy()\n",
    "#     #print(image_np_with_detections)\n",
    "#     vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#           image_np_with_detections,\n",
    "#           detections['detection_boxes'],\n",
    "#           detections['detection_classes'],\n",
    "#           detections['detection_scores'],\n",
    "#           category_index,\n",
    "#           use_normalized_coordinates=False,\n",
    "#           max_boxes_to_draw=2,\n",
    "#           min_score_thresh = 0.50,\n",
    "#           agnostic_mode=False)\n",
    "\n",
    "#     plt.figure(figsize=(6, 6))\n",
    "#     plt.imshow(image_np_with_detections)\n",
    "#     plt.show()\n",
    "#     print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Takes ~40 sec\n",
    "%matplotlib inline\n",
    "\n",
    "# test_images_predict_dict = {}\n",
    "\n",
    "# print(IMAGE_PATHS)\n",
    "#for image in os.listdir(base_path):\n",
    "\n",
    "#IMAGE_PATHS = pick_n_random_files(10)\n",
    "for image in range(1): #IMAGE_PATHS:\n",
    "    #print('Running inference for {}... '.format(image), end='')\n",
    "\n",
    "    image_np = load_image_into_numpy_array(base_path + '37c6c0aee54b.jpg')\n",
    "    # print(image)\n",
    "\n",
    "    # Things to try:\n",
    "    # Flip horizontally\n",
    "    # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    # image_np = np.tile(\n",
    "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    # print(input_tensor.shape)\n",
    "\n",
    "    # input_tensor = np.expand_dims(image_np, 0)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                   for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "    #print(detections)\n",
    "    \n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "    \n",
    "    # Try to scale bboxes\n",
    "    \n",
    "    detections['detection_boxes'] = 255 * detections['detection_boxes']\n",
    "    \n",
    "    # print(f\"Number of detection_classes is {len(detections['detection_classes'])}\")\n",
    "    # print(f\"Number of detection_scores is {len(detections['detection_scores'])}\")\n",
    "    # print(f\"Number of detection_boxes is {len(detections['detection_boxes'])}\")\n",
    "    \n",
    "#     test_images_predict_dict[image] = {}\n",
    "#     test_images_predict_dict[image]['class'] = []\n",
    "#     test_images_predict_dict[image]['bbox'] = []\n",
    "    \n",
    "#     for ind, score in enumerate(detections['detection_scores']):\n",
    "#         if score > 0.5:\n",
    "#             test_images_predict_dict[image]['class'].append(detections['detection_classes'][ind])\n",
    "#             test_images_predict_dict[image]['bbox'].append(detections['detection_boxes'][ind])\n",
    "    \n",
    "    # print(test_images_predict_dict)\n",
    "    \n",
    "    # Visualizing the image with detections\n",
    "    image_np_with_detections = image_np.copy()\n",
    "    #print(image_np_with_detections)\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'],\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=False,\n",
    "          max_boxes_to_draw=2,\n",
    "          min_score_thresh = 0.50,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image_np_with_detections)\n",
    "    plt.show()\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df = pd.DataFrame(test_images_predict_dict).T\n",
    "#test_images_df = pd.DataFrame(test_images_predict_dict.items(), columns=['id', 'class', 'bbox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df = test_images_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df.rename(columns={\"index\": \"id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1263</td>\n",
       "      <td>1263</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1263</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e5e44940be7a.jpg</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1210</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id class  bbox\n",
       "count               1263  1263  1263\n",
       "unique              1263     4    54\n",
       "top     e5e44940be7a.jpg    []    []\n",
       "freq                   1  1210  1210"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91558723b2cd.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 246.06796, 248.22679]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>720a67515500.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 7.5915747, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9e78e0ae2f3e.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 18.857765, 239.58313, 255.0], [0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10d3c965a5b4.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 35.523148, 221.22017, 255.0], [33.11927...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ebaebf6b1e02.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[0.0, 13.189882, 246.47168, 255.0], [0.0, 13....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>6ca497c845ef.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 0.4563707, 255.0, 255.0], [0.0, 0.0, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ad3e33d5f844.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[5.5265985, 35.726185, 230.86525, 255.0], [31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>ae357fad39c2.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 28.312304, 226.5756, 255.0], [60.306892...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>8d6d32d0822e.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 1.4055825, 249.17264, 253.6497]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>ac238e67fdc5.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 33.64458, 228.86078, 255.0], [26.09985,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2bc3736cc7bf.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 253.58665, 252.8739]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>97de5453f769.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 254.90259, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>a840d15a7cdc.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 3.242989, 249.55368, 254.37878]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>fc45a3b144a7.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.6637484, 36.30939, 233.15717, 255.0], [30....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>a4c570b129c3.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 7.4318843, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>5db9599cf9f7.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 255.0, 254.8215]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>318a1ecb6fc7.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 254.90259, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1c5aa8c405c7.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[0.0, 10.732007, 243.8896, 255.0], [0.0, 10.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>ae9c9f0b03da.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[0.0, 5.762087, 255.0, 255.0], [0.0, 7.903781...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>59a0fc64bd20.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 3.179031, 251.27336, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>7571cda597cb.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 11.35905, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>127c2b32dd5d.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 10.289354, 249.02213, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>949b8bf1079a.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 4.592806, 248.29305, 255.0], [0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>59911e31f963.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.5641177, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>ccc5b63ca96d.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 55.454582, 241.115, 255.0], [31.533474,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1a330ec81ee3.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 9.221148, 249.25656, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>5e8ac1fe2b82.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[3.3318436, 0.0, 255.0, 253.02089]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>7c95cf673952.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[2.5393429, 0.0, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>25d33047633c.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[0.0, 8.270773, 248.90196, 255.0], [0.0, 10.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>e19d8286b13b.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 6.9180226, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>daf0bd7ba1b4.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 2.6962745, 254.25435, 252.0217]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>262f3525e16a.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 255.0, 253.01952]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>3d56a237b6be.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[1.4148693, 1.5670055, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>609361f18122.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 248.97086, 252.07054]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>83594e6ad0ba.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[4.706572, 32.988476, 231.08046, 255.0], [26....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>cb75251076c7.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.34239963, 0.44203028, 248.81807, 245.16158]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>f02e557a36dc.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 3.179031, 251.27336, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>da3860170bad.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 254.89415, 254.22377]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>e831bebfa015.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 255.0, 253.66725]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>3b4ab121cbd4.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[0.0, 6.9599423, 250.08867, 255.0], [0.0, 9.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>f31bb833e467.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[5.3853827, 4.3198056, 251.66417, 255.0], [0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>a84c79aac3c0.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 31.280218, 228.51591, 255.0], [54.34721...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>2083ae742497.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 252.86975, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>e134e2ffdfaf.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 26.517994, 230.44904, 255.0], [0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1dfed0992998.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[3.0580912, 7.078929, 223.68605, 231.22269]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>d3d02532e1cf.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.5129573, 7.5791416, 249.55354, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>8c6d6a69d5dd.jpg</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[[0.0, 6.9599423, 250.08867, 255.0], [0.0, 9.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>a706ebbc447a.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 11.353327, 251.66359, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>b246eb99760f.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 255.0, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>6cc1a9065abb.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.0, 0.0, 252.86421, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>6707b082f3c9.jpg</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[[0.45534477, 0.0, 254.5484, 255.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>d91b58caa74d.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[0.0, 29.514467, 228.84785, 255.0], [65.02685...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1b282faf0f42.jpg</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[[2.7739348, 25.388437, 240.12714, 255.0], [0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   class  \\\n",
       "1     91558723b2cd.jpg     [2]   \n",
       "17    720a67515500.jpg     [2]   \n",
       "19    9e78e0ae2f3e.jpg  [2, 2]   \n",
       "25    10d3c965a5b4.jpg  [2, 2]   \n",
       "58    ebaebf6b1e02.jpg  [2, 3]   \n",
       "67    6ca497c845ef.jpg  [2, 2]   \n",
       "69    ad3e33d5f844.jpg  [2, 2]   \n",
       "134   ae357fad39c2.jpg  [2, 2]   \n",
       "147   8d6d32d0822e.jpg     [2]   \n",
       "155   ac238e67fdc5.jpg  [2, 2]   \n",
       "193   2bc3736cc7bf.jpg     [2]   \n",
       "241   97de5453f769.jpg     [2]   \n",
       "253   a840d15a7cdc.jpg     [2]   \n",
       "270   fc45a3b144a7.jpg  [2, 2]   \n",
       "345   a4c570b129c3.jpg     [2]   \n",
       "353   5db9599cf9f7.jpg     [2]   \n",
       "405   318a1ecb6fc7.jpg     [2]   \n",
       "409   1c5aa8c405c7.jpg  [2, 3]   \n",
       "420   ae9c9f0b03da.jpg  [2, 3]   \n",
       "427   59a0fc64bd20.jpg     [2]   \n",
       "441   7571cda597cb.jpg     [2]   \n",
       "521   127c2b32dd5d.jpg     [2]   \n",
       "587   949b8bf1079a.jpg  [2, 2]   \n",
       "597   59911e31f963.jpg     [2]   \n",
       "598   ccc5b63ca96d.jpg  [2, 2]   \n",
       "629   1a330ec81ee3.jpg     [2]   \n",
       "643   5e8ac1fe2b82.jpg     [2]   \n",
       "644   7c95cf673952.jpg     [2]   \n",
       "701   25d33047633c.jpg  [2, 3]   \n",
       "734   e19d8286b13b.jpg     [2]   \n",
       "736   daf0bd7ba1b4.jpg     [2]   \n",
       "759   262f3525e16a.jpg     [2]   \n",
       "783   3d56a237b6be.jpg     [2]   \n",
       "789   609361f18122.jpg     [2]   \n",
       "815   83594e6ad0ba.jpg  [2, 2]   \n",
       "822   cb75251076c7.jpg     [2]   \n",
       "831   f02e557a36dc.jpg     [2]   \n",
       "839   da3860170bad.jpg     [2]   \n",
       "856   e831bebfa015.jpg     [2]   \n",
       "870   3b4ab121cbd4.jpg  [2, 3]   \n",
       "896   f31bb833e467.jpg  [2, 3]   \n",
       "944   a84c79aac3c0.jpg  [2, 2]   \n",
       "973   2083ae742497.jpg     [2]   \n",
       "1087  e134e2ffdfaf.jpg  [2, 2]   \n",
       "1095  1dfed0992998.jpg     [2]   \n",
       "1117  d3d02532e1cf.jpg     [2]   \n",
       "1119  8c6d6a69d5dd.jpg  [2, 3]   \n",
       "1178  a706ebbc447a.jpg     [2]   \n",
       "1181  b246eb99760f.jpg     [2]   \n",
       "1206  6cc1a9065abb.jpg     [2]   \n",
       "1209  6707b082f3c9.jpg     [2]   \n",
       "1223  d91b58caa74d.jpg  [2, 2]   \n",
       "1225  1b282faf0f42.jpg  [2, 2]   \n",
       "\n",
       "                                                   bbox  \n",
       "1                    [[0.0, 0.0, 246.06796, 248.22679]]  \n",
       "17                     [[0.0, 7.5915747, 255.0, 255.0]]  \n",
       "19    [[0.0, 18.857765, 239.58313, 255.0], [0.0, 0.0...  \n",
       "25    [[0.0, 35.523148, 221.22017, 255.0], [33.11927...  \n",
       "58    [[0.0, 13.189882, 246.47168, 255.0], [0.0, 13....  \n",
       "67    [[0.0, 0.4563707, 255.0, 255.0], [0.0, 0.0, 16...  \n",
       "69    [[5.5265985, 35.726185, 230.86525, 255.0], [31...  \n",
       "134   [[0.0, 28.312304, 226.5756, 255.0], [60.306892...  \n",
       "147             [[0.0, 1.4055825, 249.17264, 253.6497]]  \n",
       "155   [[0.0, 33.64458, 228.86078, 255.0], [26.09985,...  \n",
       "193                   [[0.0, 0.0, 253.58665, 252.8739]]  \n",
       "241                      [[0.0, 0.0, 254.90259, 255.0]]  \n",
       "253             [[0.0, 3.242989, 249.55368, 254.37878]]  \n",
       "270   [[0.6637484, 36.30939, 233.15717, 255.0], [30....  \n",
       "345                    [[0.0, 7.4318843, 255.0, 255.0]]  \n",
       "353                       [[0.0, 0.0, 255.0, 254.8215]]  \n",
       "405                      [[0.0, 0.0, 254.90259, 255.0]]  \n",
       "409   [[0.0, 10.732007, 243.8896, 255.0], [0.0, 10.7...  \n",
       "420   [[0.0, 5.762087, 255.0, 255.0], [0.0, 7.903781...  \n",
       "427                 [[0.0, 3.179031, 251.27336, 255.0]]  \n",
       "441                     [[0.0, 11.35905, 255.0, 255.0]]  \n",
       "521                [[0.0, 10.289354, 249.02213, 255.0]]  \n",
       "587   [[0.0, 4.592806, 248.29305, 255.0], [0.0, 0.0,...  \n",
       "597                    [[0.0, 0.5641177, 255.0, 255.0]]  \n",
       "598   [[0.0, 55.454582, 241.115, 255.0], [31.533474,...  \n",
       "629                 [[0.0, 9.221148, 249.25656, 255.0]]  \n",
       "643                [[3.3318436, 0.0, 255.0, 253.02089]]  \n",
       "644                    [[2.5393429, 0.0, 255.0, 255.0]]  \n",
       "701   [[0.0, 8.270773, 248.90196, 255.0], [0.0, 10.6...  \n",
       "734                    [[0.0, 6.9180226, 255.0, 255.0]]  \n",
       "736             [[0.0, 2.6962745, 254.25435, 252.0217]]  \n",
       "759                      [[0.0, 0.0, 255.0, 253.01952]]  \n",
       "783              [[1.4148693, 1.5670055, 255.0, 255.0]]  \n",
       "789                  [[0.0, 0.0, 248.97086, 252.07054]]  \n",
       "815   [[4.706572, 32.988476, 231.08046, 255.0], [26....  \n",
       "822    [[0.34239963, 0.44203028, 248.81807, 245.16158]]  \n",
       "831                 [[0.0, 3.179031, 251.27336, 255.0]]  \n",
       "839                  [[0.0, 0.0, 254.89415, 254.22377]]  \n",
       "856                      [[0.0, 0.0, 255.0, 253.66725]]  \n",
       "870   [[0.0, 6.9599423, 250.08867, 255.0], [0.0, 9.7...  \n",
       "896   [[5.3853827, 4.3198056, 251.66417, 255.0], [0....  \n",
       "944   [[0.0, 31.280218, 228.51591, 255.0], [54.34721...  \n",
       "973                      [[0.0, 0.0, 252.86975, 255.0]]  \n",
       "1087  [[0.0, 26.517994, 230.44904, 255.0], [0.0, 0.0...  \n",
       "1095      [[3.0580912, 7.078929, 223.68605, 231.22269]]  \n",
       "1117         [[0.5129573, 7.5791416, 249.55354, 255.0]]  \n",
       "1119  [[0.0, 6.9599423, 250.08867, 255.0], [0.0, 9.7...  \n",
       "1178               [[0.0, 11.353327, 251.66359, 255.0]]  \n",
       "1181                         [[0.0, 0.0, 255.0, 255.0]]  \n",
       "1206                     [[0.0, 0.0, 252.86421, 255.0]]  \n",
       "1209               [[0.45534477, 0.0, 254.5484, 255.0]]  \n",
       "1223  [[0.0, 29.514467, 228.84785, 255.0], [65.02685...  \n",
       "1225  [[2.7739348, 25.388437, 240.12714, 255.0], [0....  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df[test_images_df['class'].map(lambda d: len(d)) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df.to_csv('test_images_raw_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dict = {1: 'negative', 2: 'typical', 3: 'indeterminate', 4: 'atypical'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df['PredictionString'] = ''\n",
    "\n",
    "for ind, row in test_images_df.iterrows():\n",
    "    row['id'] = row['id'].replace('.jpg', '')\n",
    "    \n",
    "    pred_list = []\n",
    "    if row['class']:\n",
    "        # pred_string = ''\n",
    "        # for elem in row['class']:\n",
    "        # print(row['class'][0])\n",
    "        pred_list.append(classes_dict[row['class'][0]])\n",
    "        for box in row['bbox']:\n",
    "            #print(box)\n",
    "            pred_list.extend(map(str, map(int, box)))\n",
    "            #print(pred_list)\n",
    "            pred_string = ' '.join(pred_list)\n",
    "            #print(pred_string)\n",
    "    else:\n",
    "        pred_string = 'none 1 0 0 1 1'\n",
    "    row['PredictionString'] = pred_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df.drop(columns=['class', 'bbox'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37c6c0aee54b</td>\n",
       "      <td>typical 0 0 245 252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91558723b2cd</td>\n",
       "      <td>typical 0 0 246 248 0 0 242 234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e49489fcf5c0</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1b66ff8f4eb</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16972e92e827</td>\n",
       "      <td>negative 1 3 254 254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>4040afec3ee4</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>620191dbdfa4</td>\n",
       "      <td>negative 1 1 255 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>503a6e0884c6</td>\n",
       "      <td>negative 0 0 255 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>3dcdfc352a06</td>\n",
       "      <td>negative 0 3 255 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3fe73d3b28b9</td>\n",
       "      <td>negative 0 0 251 254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                 PredictionString\n",
       "0     37c6c0aee54b              typical 0 0 245 252\n",
       "1     91558723b2cd  typical 0 0 246 248 0 0 242 234\n",
       "2     e49489fcf5c0                   none 1 0 0 1 1\n",
       "3     f1b66ff8f4eb                   none 1 0 0 1 1\n",
       "4     16972e92e827             negative 1 3 254 254\n",
       "...            ...                              ...\n",
       "1258  4040afec3ee4                   none 1 0 0 1 1\n",
       "1259  620191dbdfa4             negative 1 1 255 255\n",
       "1260  503a6e0884c6             negative 0 0 255 255\n",
       "1261  3dcdfc352a06             negative 0 3 255 255\n",
       "1262  3fe73d3b28b9             negative 0 0 251 254\n",
       "\n",
       "[1263 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       10d3c965a5b4\n",
       "PredictionString    typical 0 35 221 255 33 0 243 192\n",
       "Name: 25, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_df.iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_df.to_csv('predictions_2_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write all jpg's into a single 'dataset' numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-16T14:47:29.919547Z",
     "iopub.status.idle": "2021-06-16T14:47:29.920339Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = np.ndarray(shape=(len(train_image), 1, 256, 256), dtype=np.float32)\n",
    "\n",
    "# for dirname, _, filenames in os.walk('../input/siim-covid19-resized-to-256px-jpg/train'):\n",
    "#     i = 0\n",
    "#     for filename in filenames:\n",
    "#         path = os.path.join(dirname, filename)\n",
    "#         img= Image.open(path)  \n",
    "#         np_arr_image = np.array(img)\n",
    "#         dataset[i] = np_arr_image\n",
    "#         i += 1\n",
    "        \n",
    "#         if i % 500 == 0:\n",
    "#             print(f\"{i} images added to dataset\")\n",
    "#     print(\"All images added to dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-06-16T14:47:29.921620Z",
     "iopub.status.idle": "2021-06-16T14:47:29.922390Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
